\chapter{Extended options for the latent field}
<<echo=FALSE>>=
library(INLA)
@
\section{Values}

In the definition of a model component in a formula
<<eval=FALSE>>=
... + f(idx, model="rw2")
@
%%
then \tv{f} defines a \tv{RW2} model, say, and implicitely through the
variable \tv{idx} for which \emph{locations} the RW2 model should be
defined at, like
<<eval=FALSE>>=
sort(unique(idx))
@
%%
for a numerical \tv{idx}. Usually, this is what we want, but not
always. It does not happen often, but in some cases we need use the
argument \tv{values}, which defines the location for which the model
should be defined at, and we need to define this explicitely.
\footnote{Note that some models, like \tv{besag} for example, you
    cannot change the locations as for this model is defined through a
    \tv{graph} which defines the locations as
    $1, 2, \ldots, $\tv{graph->n}.}

All this is easier to explain all this through an example. We have
three points,
\begin{center}
<<dev='pdf', out.height='8cm', out.width='8cm'>>=
x = c(1, 2, 4)
y = c(2, 1, 10)
plot(x, y, pch=19, bty="l")
@
\end{center}
and we want to fit a spline through these points. We can then do
\begin{center}
<<dev='pdf', out.height='8cm', out.width='8cm'>>=
r = inla(y ~ -1 + f(x, model="rw2", constr=FALSE),
         data = data.frame(y, x),
         control.family = list(
             hyper = list(prec = list(initial=12, fixed=TRUE))))
plot(r$summary.random$x$ID, r$summary.random$x$mean, pch=19, bty="l")
lines( r$summary.random$x$ID, r$summary.random$x$mean)
@
\end{center}
which seems just like drawing a straight line between the observation,
and is indeed true. This is not what we wanted!
The reason is that \tv{x} defines the locations of
the spline, which is just at the locations \tv{x}. We want the spline to
be define also inbetween and even (maybe) outside this regions. For
this we need to pass a properly defined \tv{values} argument.
\begin{center}
<<dev='pdf', out.height='8cm', out.width='8cm'>>=
v = seq(0, 6, by = 0.2)
r = inla(y ~ -1 + f(x, model="rw2", constr=FALSE, values = v),
         data = list(y=y, x=x, v=v),
         control.family = list(
             hyper = list(prec = list(initial=12, fixed=TRUE))))
plot(r$summary.random$x$ID, r$summary.random$x$mean, pch=19, bty="l")
lines( r$summary.random$x$ID, r$summary.random$x$mean)
@
\end{center}
Note that \tv{x} must be a subset of \tv{v}, otherwise an error will
occure
<<errors=TRUE>>=
v = 10:20
r = inla(y ~ -1 + f(x, model="rw2", constr=FALSE, values = v),
         data = list(y=y, x=x, v=v))
@
%%
The argument \tv{values} also allow us to produce credibility bounds
wherever we want, like
\begin{center}
<<dev='pdf', out.height='8cm', out.width='8cm'>>=
plot(r$summary.random$x$ID, r$summary.random$x$mean, pch=19, bty="l",
     ylim = c(-5, 45))
lines( r$summary.random$x$ID, r$summary.random$x$mean, lwd=2)
lines( r$summary.random$x$ID, r$summary.random$x$"0.025quant", lty=2, lwd=2)
lines( r$summary.random$x$ID, r$summary.random$x$"0.975quant", lty=3, lwd=2)
@
\end{center}


\section{Replicate}

Replicate is a really useful feature, which allow you to create
conditional independent replications of a model component. Let
$\mm{x}|\mm{\theta}$ be a model component which can be defined through
\tv{f(idx, model=...)}, say. Then the option \tv{replicate} will
redefine \tv{f(...)} to contain conditional independent replications
$\mm{x}_1|\mm{\theta}$, $\mm{x}_2|\mm{\theta}$, etc, from the same
model component with the same hyperparameters $\mm{\theta}$. In order
to tell which element of the model component going into the linear
predictor, we need to use a two-dimensional indexing: the index
\tv{idx}, and the replication \tv{r}. We do this as
\begin{quote}
    \tv{f(idx, model=..., replicate = r)}
\end{quote}
The replicate index \tv{r} are integers
$1, 2, \ldots, \text{\tv{nrep}}$, which gives a model component with
\tv{nrep} replications. In cases where \tv{nrep} is not \tv{max(r)},
you can define it as \tv{f(..., nrep=nrep)}.

A simple example, doing the obvious, is to redo the model \tv{iid}.
The \tv{iid} model is just independent zero-mean Gaussians with some
precision $\tau$.
<<echo=TRUE>>=
n = 10
y = rnorm(n)
r = inla(y ~ -1 + f(idx, model="iid"),
         data = data.frame(y, idx = 1:n),
         control.family = list(hyper = list(prec = list(initial = 12,
                                                        fixed=TRUE))))
print(r$summary.hyperpar)
print(r$mlik)
@
We can reinterpret this model, as a one-dimensional zero-mean
Gaussian, which is then replicated $n$ times. In this case, \tv{idx}
is just $1$, as we have moved the indexing into the replicate argument.
<<echo=TRUE>>=
r = inla(y ~ -1 + f(idx, model="iid", replicate = r),
         data = data.frame(y, idx = rep(1,n), r = 1:n),
         control.family = list(hyper = list(prec = list(initial = 12,
                                                        fixed=TRUE))))
print(r$summary.hyperpar)
print(r$mlik)
@
%%
We can also do $n/2$ replicates of size 2 (assuming $n=\Sexpr{n}$ is a
multiple of 2)
<<echo=TRUE>>=
r = inla(y ~ -1 + f(idx, model="iid", replicate = r),
         data = data.frame(y, idx = rep(1:2,n/2), r = rep(1:(n/2), each=2)),
         control.family = list(hyper = list(prec = list(initial = 12,
                                                        fixed=TRUE))))
print(r$summary.hyperpar)
print(r$mlik)
@
All these results are the same (except, maybe, in the last digits due to the
parallelisation, which cannot control at that level).

All \tv{f()}-models can be replicated. Any constraint, either through
\tv{constr=TRUE} or \tv{extraconstr}, will be also be replicated into
the same constraint on each replication.

The results of the analysis are stored $\mm{x}_1, \mm{x}_2, \ldots$.
In the last example, then its stored in this order
<<echo=T>>=
index = cbind(idx = rep(1:2,n/2), r = rep(1:(n/2), each=2))
@
There is a function which compute the index for where a particular
combination is stored, \tv{inla.idx}, so we can can request the index for
\tv{idx=2,r=3}, as
<<echo=TRUE>>=
inla.idx(idx = 2,  n = 2, replicate = 3, nrep = n/2)
@
when we know the size of the model (2 in this case) and the number of
replications, which agree with the \tv{index} above
<<echo=TRUE>>=
which(apply(index, 1,
            function(v) {
                v = as.list(v)
                return (v$idx == 2 && v$r == 3)
            }))
@

If you do not make use of all the replicates, they are still there in
the model. If we add the option
<<echo=TRUE>>=
nrep=1000
@
%%
but only use the first \Sexpr{n} then the length is \Sexpr{nrep} and
not \Sexpr{n}
<<echo=TRUE>>=
r = inla(y ~ -1 + f(idx, model="iid", replicate = r, nrep = nrep),
         data = data.frame(y, idx = rep(1,n), r = 1:n),
         control.family = list(hyper = list(prec = list(initial = 12,
                                                        fixed=TRUE))))
print(length(r$marginals.random$idx))
@
%%
A common mistake is to replicate over \tv{year} instead of
\tv{year.shifted = year-min(year)+1}.


Typical applications using this feature is where we replicate over
regions, subjects, persons or time.




\section{Group}

The grouping option has a similar concept as the replicate option
presented in the previous section. Now, however we assume a dependence
structure for the replicates, for example rw1, rw2, ar1, besag or
exchangeable.

The option is implemented as a Kronecker product.
Let $\tilde{\bm{x}} = (x_{11}, \ldots, x_{n1}, \ldots,
x_{1R}, \ldots, x_{nR})^\top$ be a random vector with zero-mean, say, ``precision''
matrix $\mathbf{Q} = \mathbf{Q}_1\otimes \mathbf{Q}_2$ and density
\begin{equation*} \pi(\tilde{\bm{x}}) \propto
(|{\mathbf{Q_1}\otimes\mathbf{Q_2}}|^\star)^{1/2}
\exp\left(-\frac{1}{2} \tilde{\bm{x}}^\top\{{\mathbf{Q}_1\otimes
\mathbf{Q}_2}\}\tilde{\bm{x}}\right)
\end{equation*}
where $Q_{ij} = 0$ $\longleftrightarrow$ $x_i \bot x_j|\bm{x}_{-ij}$.
We call $\tilde{\bm{x}}$ a Gaussian Kronecker product Markov random field.
Here,  $\mathbf{Q}_1$ and $\mathbf{Q}_2$ are two lower-dimensional
precision matrices, which can be either regular or singular. The
Kronecker product $\otimes$ defines the interaction of  $\mathbf{Q}_1$ and $\mathbf{Q}_2$.

As an example consider $R$ random walks of second order with
$\mm{\alpha}_i = (\alpha_{i,1}, \ldots, \alpha_{i,R})^T$ and where
$\tilde{\mm{\alpha}} = (\alpha_{1,1}, \ldots, \alpha_{I,1}, \ldots,
\alpha_{1,R}, \ldots, \alpha_{I,R})^T$ denotes the stacked
vector. Then, the joint distribution is given by:
	\begin{align*}
		f(\tilde{\mm{\alpha}}|\mm{\Sigma}, \kappa) &\propto
		%   |\kappa\mm{\Sigma}^{-1}|^{(I-2)/2} \exp\Biggl( -\frac{1}{2}
		%   \sum_{i=3}^I \left ( \mm{\alpha}_i - 2\mm{\alpha}_{i-1} + \mm{\alpha}_{i-2} \right)^T \cdot \\
		%   & \qquad \qquad \kappa\mm{\Sigma}^{-1}
		% \left ( \mm{\alpha}_i - 2\mm{\alpha}_{i-1} + \mm{\alpha}_{i-2}\right)
		%   \Biggr)\\
		%   &=
			|\kappa\mm{\Sigma}^{-1}|^{(I-2)/2}
			\exp\left( -\frac{1}{2} \tilde{\mm{\alpha}}^T
				\left\{{\mm{\Sigma}^{-1} \otimes \mm{Q}} \right \}
				\tilde{\mm{\alpha}} \right),
	\end{align*}
with
		\begin{equation*}
			\mm{Q} = \kappa \left(
				\begin{array}{rrrrrrr}
					1 & -2 & 1 &&&&\\
					-2& 5 & -4 & 1&&&\\
					1& -4 & 6& -4 &1 &&\\
					&\ddots&\ddots&\ddots&\ddots&\ddots&\\
					&&1& -4& 6& -4 &1\\
					&&&1&  -4 & 5 & -2\\
					&&&&1&-2&1
				\end{array}
				\right)
		\end{equation*}
and where $\mm{\Sigma}$ represents the correlation structure, for
example an exchangeable correlation structure of for example a spatial
neighbourhood structure as given by the Besag model. Of note, there is
only one precision parameter in the model and one correlation
parameter $\rho$. Furthermore, grouping $a$ with $b$ should lead to
the same result as grouping $b$ with $a$. That means correlating an
RW2 over space using a Besag dependence structure, is the same as
correlating a Besag model in time using a RW2 dependence structure.

\section{Linear combinations}

\section{Copy}

\section{Running \tv{inla()} remotely}

A really useful feature is the option to run \tv{inla()} remotely on a
different machine. This means the {\tt R} session still runs locally
on your machine but the INLA computations are done on a remote
server.
If you have access to a computational server
somewhere of \tv{Linux} or \tv{MaxOSX} type, you can make use of this.

After a the setup, we can do like this
<<echo=TRUE, eval=FALSE>>=
n = 1000
x = runif(n)
y = x + rnorm(n)
r = inla(y ~ 1 + x,  data = data.frame(y, x), inla.call = "remote")
@
which will run the computations on a different server. The name of the
server is defined in the file \tv{$\sim$/.inlarc}, which for me, reads
\begin{verbatim}
### The name of the remote host.
RemoteHost="inla.math.ntnu.no"

### The username on the remote host
RemoteUser="hrue"

### Full path to the inla-program on the remote host
RemoteINLA="/usr/local/bin/inla"

### Arguments to ssh. Usually no need to change this
sshArguments="-x -o BatchMode=yes -o TCPKeepAlive=yes -e none"

### Port number
Port=22
\end{verbatim}
All these options are the default values, so you can also comment them
out using a '\#' or just leave them out. The options means, that I run
on the host \tv{inla.math.ntnu.no} using the account with usename
\tv{hrue} and the path to the \tv{inla}-binary is
\tv{/usr/local/bin/inla}. The easy way to install the
\tv{inla}-binary, is to have \tv{R} and \tv{R-INLA} installed and use
the \tv{inla}-binary in the \tv{R-INLA} package. You can find its path
by
<<echo=FALSE>>=
inla.setOption(inla.call=NULL)
@
<<echo=TRUE>>=
inla.getOption("inla.call")
@

The \tv{remote}-feature is made possible by using \tv{ssh} tools and
friends, which explains why you need to install \tv{Cygwin} on Windows
to make it work. The setup is easy enough but you need to doit correct
and every little detail is important; if in doubt seek help, upfont,
from a computer-wizard, and follow closely the details on this issue
in the \tv{FAQ} section on \tv{www.r-inla.org}.

There is more. You do not have to wait and sit for the job to be done.
You can submit the job or many, close the wifi-connection and shutdown
your laptop, and check and fetch the results when you get home. For
this use the argument \tv{inla.call="submit"} instead, and follow the
guidelines in the manual page \tv{?inla.qget}. You can check the
status of a job, fetch results, stop them, and clean up temporary
files, using \tv{inla.qstat}, \tv{inla.qget}, \tv{inla.qdel},
\tv{inla.qnuke}, respectively. This is a really useful feature
especially running larger models. Here is an example:\\

% <<echo=TRUE>>=
% n = 1000
% x = runif(n)
% y = x + rnorm(n)
% # submit the job to the remote server
% result = inla(y ~ 1 + x,  data = data.frame(y, x), inla.call = "submit")

% # check the status of the job
% inla.qstat()

% # if you are still in the R-session you can get the results using
% result= inla.qget(result, remove=FALSE)
% # after logging out the object result is not known anymore,
% # so you need to know the job id which you would like to get
% result= inla.qget(inla.qstat()[[1]]$id, remove=FALSE)
% summary(result)
% # if you have all results remove all jobs from the remote server
% inla.qnuke()
% @


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{n} \hlkwb{=} \hlnum{1000}
\hlstd{x} \hlkwb{=} \hlkwd{runif}\hlstd{(n)}
\hlstd{y} \hlkwb{=} \hlstd{x} \hlopt{+} \hlkwd{rnorm}\hlstd{(n)}
\hlcom{# submit the job to the remote server}
\hlstd{result} \hlkwb{=} \hlkwd{inla}\hlstd{(y} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{x,}  \hlkwc{data} \hlstd{=} \hlkwd{data.frame}\hlstd{(y, x),} \hlkwc{inla.call} \hlstd{=} \hlstr{"submit"}\hlstd{)}

\hlcom{# check the status of the job}
\hlkwd{inla.qstat}\hlstd{()}
\end{alltt}
\begin{verbatim}
## Job: 1   Id: Wed-Sep-28-12-48-03-2016---898959884   Size: 1Mb   Status: Finished
\end{verbatim}
\begin{alltt}
\hlcom{# if you are still in the R-session you can get the results using}
\hlstd{result}\hlkwb{=} \hlkwd{inla.qget}\hlstd{(result,} \hlkwc{remove}\hlstd{=}\hlnum{FALSE}\hlstd{)}
\hlcom{# after logging out the object result is not known anymore,}
\hlcom{# so you need to know the job id which you would like to get}
\hlstd{result}\hlkwb{=} \hlkwd{inla.qget}\hlstd{(}\hlkwd{inla.qstat}\hlstd{()[[}\hlnum{1}\hlstd{]]}\hlopt{$}\hlstd{id,} \hlkwc{remove}\hlstd{=}\hlnum{FALSE}\hlstd{)}
\hlkwd{summary}\hlstd{(result)}
\end{alltt}
\begin{verbatim}
##
## Call:
## NULL
##
## Fixed effects:
##                mean     sd 0.025quant 0.5quant 0.975quant    mode kld
## (Intercept) -0.0986 0.0630    -0.2223  -0.0986     0.0251 -0.0986   0
## x            1.1351 0.1107     0.9177   1.1351     1.3524  1.1351   0
##
## The model has no random effects
##
## Model hyperparameters:
##                                         mean     sd 0.025quant 0.5quant
## Precision for the Gaussian observations 1.02 0.0421     0.9408     1.02
##                                         0.975quant  mode
## Precision for the Gaussian observations      1.104 1.018
##
## Expected number of effective parameters(std dev): 2.017(8e-04)
## Number of equivalent replicates : 495.79
##
## Marginal log-Likelihood:  -1429.27
\end{verbatim}
\begin{alltt}
\hlcom{# if you have all results remove all jobs from the remote server}
\hlkwd{inla.qnuke}\hlstd{()}
\end{alltt}
\end{kframe}
\end{knitrout}