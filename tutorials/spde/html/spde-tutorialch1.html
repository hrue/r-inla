<?xml version="1.0" encoding="iso-8859-1" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title>1 Introduction</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" /> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)" /> 
<!-- xhtml,html,frames,2 --> 
<meta name="src" content="spde-tutorial.tex" /> 
<meta name="date" content="2017-01-22 14:18:00" /> 
<link rel="stylesheet" type="text/css" href="spde-tutorial.css" /> 
</head><body 
>
   <!--l. 2--><div class="crosslinks"><p class="noindent">[<a 
href="spde-tutorialch2.html" >next</a>] [<a 
href="spde-tutorialli1.html" >prev</a>] [<a 
href="spde-tutorialli1.html#tailspde-tutorialli1.html" >prev-tail</a>] [<a 
href="#tailspde-tutorialch1.html">tail</a>] [<a 
href="spde-tutorial3.html#spde-tutorialch1.html" >up</a>] </p></div>
   <h2 class="chapterHead"><span class="titlemark">Chapter&#x00A0;1</span><br /><a 
 id="x5-40001"></a>Introduction</h2>
<!--l. 4--><p class="noindent" >A point-referenced dataset is made up of any data measured at known locations. These locations
may be in any coordinate reference system, most often the longitude and latitude coordinates.
Point-referenced data are very common in many areas of science. This type of data appears in
mining, climate modeling, ecology, agriculture and other areas. If we want to model the data
while incorporating the information about where the data are from, we need a model for point
referenced data.
</p><!--l. 16--><p class="indent" >   It is possible to build a regression model using each coordinate as a covariate. But
in some cases it is necessary to include a very complicated function based on the
coordinates to get an adequate description of the mean. For example, we may need complex
non-linear function or a non-parametric function. This type of model only incorporates a
trend on the mean based on the coordinates. Also, this type of model is a fixed effect
model.
</p><!--l. 27--><p class="indent" >   Instead, it is more natural for a model to measure the first law of geography in a simple way.
This law says: &#8220;Everything is related to everything else, but near things are more
related than distant things&#8221;, <span class="cite">[<a 
href="spde-tutorialli2.html#Xtobler:1970">Tobler, 1970</a>]</span>. So, we need a model that incorporates the
property that an observation is more correlated with an observation collected at a
neighboring location than with another that is collected at more distant location.
One option to model this dependence is to use a spatially-structured random effect.
This type of model incorporates spatial dependency, rather than simply the spatial
trend. However, it is possible to include both terms in a model. Spatial dependency
can be accounted for within more general models using spatially structured random
effects.
</p><!--l. 45--><p class="indent" >   In spatial statistics, different models are used to incorporate spatial dependency depending
on whether the locations are areas (states, cities, etc.) or whether the locations are points. In the
latter case, the locations can be fixed or random. Models of point-referenced data that include a
spatially-structured random effect are commonly called geostatistical models. Geostatistics is the
specific area of spatial statistics that these models. See <span class="cite">[<a 
href="spde-tutorialli2.html#Xcressie:1993">Cressie, 1993</a>]</span> for a good introduction to
spatial statistics.
</p>
   <h3 class="sectionHead"><span class="titlemark">1.1   </span> <a 
 id="x5-50001.1"></a>The Gaussian random field</h3>
<!--l. 58--><p class="noindent" >To introduce some notation, let <span 
class="cmmi-10x-x-109">s </span>be any location in the study area and let <span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>be the random
effect at that location. <span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>is a stochastic process, with <span 
class="cmmi-10x-x-109">s </span><span 
class="cmsy-10x-x-109">&#x2208;</span> <span 
class="cmmib-10x-x-109">D</span>, were <span 
class="cmmib-10x-x-109">D</span> is the domain of the
study area and <span 
class="cmmib-10x-x-109">D</span> <span 
class="cmsy-10x-x-109">&#x2208;&#x211C;</span><sup><span 
class="cmmi-8">d</span></sup>. Suppose, for example, that <span 
class="cmmib-10x-x-109">D</span> is a specific country and we
have data measured at geographical locations, over <span 
class="cmmi-10x-x-109">d </span><span 
class="cmr-10x-x-109">= 2 </span>dimensions, within this
country.
</p><!--l. 67--><p class="indent" >   Suppose we assume that we have a realization of <span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">)</span>, <span 
class="cmmi-10x-x-109">i </span><span 
class="cmr-10x-x-109">= 1</span><span 
class="cmmi-10x-x-109">,</span><span 
class="cmr-10x-x-109">2</span><span 
class="cmmi-10x-x-109">,...,n</span>, a realization of <span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>in
<span 
class="cmmi-10x-x-109">n </span>locations. It is commonlly assumed that <span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>has a multivariate Gaussian distribution. Also, if
we assume that <span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>is continuous over space, we have a continuously indexed Gaussian field
(GF). This implies that it is possible to collect these data at any location within the study
region. To complete the specification of the distribution of <span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">)</span>, is necessary to define its mean
and covariance.
</p><!--l. 78--><p class="indent" >   A very simple option is to define a correlation function based only on euclidean distance
between locations. This assumes that if we have two pairs of points separated by the same
distance <span 
class="cmmi-10x-x-109">h</span>, both pairs have same correlation. It is intuitive to choose any function decreasing
with <span 
class="cmmi-10x-x-109">h</span>. There is some work about the GF and correlation functions in <span class="cite">[<a 
href="spde-tutorialli2.html#Xabrahamsen:1997">Abrahamsen,
1997</a>]</span>.
</p><!--l. 89--><p class="indent" >   A very popular correlation function is the Matérn correlation function, which depends on a
scale parameter <span 
class="cmmi-10x-x-109">&#x03BA; &#x003E; </span><span 
class="cmr-10x-x-109">0 </span>and a smoothness parameter <span 
class="cmmi-10x-x-109">&#x03BD; &#x003E; </span><span 
class="cmr-10x-x-109">0</span>. Considering two locations <span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub> and <span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">j</span></sub>,
the stationary and isotropic Matérn correlation function is:
                                                                                 
                                                                                 
</p>
   <table 
class="equation"><tr><td><a 
 id="x5-5001r1"></a>
   <center class="math-display" >
<img 
src="spde-tutorial0x.png" alt="Cor  (X (s ),X (s )) = 21--&#x03BD;(&#x03BA; &#x2225; s - s &#x2225;)&#x03BD;K  (&#x03BA; &#x2225; s - s &#x2225;)
    M     i     j     &#x0393; (&#x03BD;)    i   j     &#x03BD;     i    j
" class="math-display"  /></center></td><td class="equation-label">(1.1)</td></tr></table>
<!--l. 100--><p class="nopar" >
where <span 
class="cmsy-10x-x-109">&#x2225; </span><span 
class="cmmi-10x-x-109">. </span><span 
class="cmsy-10x-x-109">&#x2225; </span>denotes the euclidean distance and <span 
class="cmmi-10x-x-109">K</span><sub><span 
class="cmmi-8">&#x03BD;</span></sub> is the modified Bessel function of the second
order. The Matérn covariance function is <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub><span 
class="cmmi-10x-x-109">Cor</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">)</span><span 
class="cmmi-10x-x-109">,X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">j</span></sub><span 
class="cmr-10x-x-109">))</span>, where <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub> is the marginal
variance of the process.
</p><!--l. 108--><p class="indent" >   If we have a realization <span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>at <span 
class="cmmi-10x-x-109">n </span>locations, we can define its joint covariance matrix. Each
entry of this joint covariance matrix <span 
class="cmr-10x-x-109">&#x03A3; </span>is <span 
class="cmr-10x-x-109">&#x03A3;</span><sub><span 
class="cmmi-8">i,j</span></sub> <span 
class="cmr-10x-x-109">= </span><span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub><span 
class="cmmi-10x-x-109">Cor</span><sub><span 
class="cmmi-8">M</span></sub><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">)</span><span 
class="cmmi-10x-x-109">,X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">j</span></sub><span 
class="cmr-10x-x-109">))</span>. It is common to assume
that <span 
class="cmmi-10x-x-109">X</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">) </span>has a zero mean. We have now completely defined a multivariate distribution for
<span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">)</span>.
</p><!--l. 116--><p class="indent" >   Now, suppose that we have data <span 
class="cmmi-10x-x-109">y</span><sub><span 
class="cmmi-8">i</span></sub> observed at locations <span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub>, <span 
class="cmmi-10x-x-109">i </span><span 
class="cmr-10x-x-109">= 1</span><span 
class="cmmi-10x-x-109">,...,n</span>. If an underlying GF
generated these data, we can fit the parameters of this process, based on the identity
<span 
class="cmmi-10x-x-109">y</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">) = </span><span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">)</span>, where <span 
class="cmmi-10x-x-109">y</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">) </span>is a realization of the GF. In this case, the likelihood function is the
multivariate distribution with mean <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmmi-8">x</span></sub> and covariance <span 
class="cmr-10x-x-109">&#x03A3;</span>. If we assume <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmmi-8">x</span></sub> <span 
class="cmr-10x-x-109">= </span><span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">0</span></sub>, we have four
parameters to estimate.
</p><!--l. 128--><p class="indent" >   In many situations we assume that we have an underlying GF but cannot directly
observe it and instead observe data with measurement error, i.e., <span 
class="cmmi-10x-x-109">y</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">) = </span><span 
class="cmmi-10x-x-109">x</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">) + </span><span 
class="cmmi-10x-x-109">e</span><sub><span 
class="cmmi-8">i</span></sub>.
It is common to assume that <span 
class="cmmi-10x-x-109">e</span><sub><span 
class="cmmi-8">i</span></sub> is independent of <span 
class="cmmi-10x-x-109">e</span><sub><span 
class="cmmi-8">j</span></sub> for all <span 
class="cmmi-10x-x-109">i</span><span 
class="cmmi-10x-x-109">&#x2260;</span><span 
class="cmmi-10x-x-109">j </span>and <span 
class="cmmi-10x-x-109">e</span><sub><span 
class="cmmi-8">i</span></sub> <span 
class="cmsy-10x-x-109">~ </span><span 
class="cmmi-10x-x-109">N</span><span 
class="cmr-10x-x-109">(0</span><span 
class="cmmi-10x-x-109">,&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><span 
class="cmr-10x-x-109">)</span>.
This additional parameter, <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub>, measures the noise, called the nugget effect. In this
case the covariance of the marginal distribution of <span 
class="cmmi-10x-x-109">y</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">s</span><span 
class="cmr-10x-x-109">) </span>is <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup><span 
class="cmmi-10x-x-109">I </span><span 
class="cmr-10x-x-109">+ &#x03A3;</span>. This model is
a short extension of the basic GF model, and in this case, we have one additional
parameter to estimate. To look more about this model see <span class="cite">[<a 
href="spde-tutorialli2.html#Xdiggleribeiro:2007">Diggle and Ribeiro Jr,
2007</a>]</span>.
</p><!--l. 145--><p class="indent" >   It is possible to describe this model within a larger class of models, the hierarchical
models. Suppose that we have observations <span 
class="cmmi-10x-x-109">y</span><sub><span 
class="cmmi-8">i</span></sub> on locations <span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub>, <span 
class="cmmi-10x-x-109">i </span><span 
class="cmr-10x-x-109">= 1</span><span 
class="cmmi-10x-x-109">,...,n</span>. We start
with
</p>
   <table 
class="equation"><tr><td><a 
 id="x5-5002r2"></a>
   <center class="math-display" >
<img 
src="spde-tutorial1x.png" alt="yi|&#x03B8;,&#x03B2;,xi,Fi ~ P(yi|&#x03BC;i,&#x03D5;)
     x ~ GF  (0,&#x03A3; )
" class="math-display"  /></center></td><td class="equation-label">(1.2)</td></tr></table>
<!--l. 152--><p class="nopar" >
where <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmmi-8">i</span></sub> <span 
class="cmr-10x-x-109">= </span><span 
class="cmmi-10x-x-109">h</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">F</span><sub><span 
class="cmmi-8">i</span></sub><sup><span 
class="cmmi-8">T</span> </sup><span 
class="cmmi-10x-x-109">&#x03B2; </span><span 
class="cmr-10x-x-109">+ </span><span 
class="cmmi-10x-x-109">x</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">)</span>, <span 
class="cmmi-10x-x-109">F </span>is a matrix of covariates, <span 
class="cmmi-10x-x-109">x </span>is the random effect, <span 
class="cmmi-10x-x-109">&#x03B8; </span>are parameters of
                                                                                 
                                                                                 
the random effect, <span 
class="cmmi-10x-x-109">&#x03B2; </span>are covariate coefficients, <span 
class="cmmi-10x-x-109">h</span><span 
class="cmr-10x-x-109">() </span>is a function mapping the linear predictor
<span 
class="cmmi-10x-x-109">F</span><sub><span 
class="cmmi-8">i</span></sub><sup><span 
class="cmmi-8">T</span> </sup><span 
class="cmmi-10x-x-109">&#x03B2; </span><span 
class="cmr-10x-x-109">+ </span><span 
class="cmmi-10x-x-109">x</span><sub><span 
class="cmmi-8">i</span></sub> to <span 
class="cmmi-10x-x-109">E</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">y</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">) = </span><span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmmi-8">i</span></sub> and <span 
class="cmmi-10x-x-109">&#x03D5; </span>is a dispersion parameter of the distribution, in the exponential
family, which is assumed for <span 
class="cmmi-10x-x-109">y</span><sub><span 
class="cmmi-8">i</span></sub>. To write the GF with a nugget effect, we replace
<span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">0</span></sub> with <span 
class="cmmi-10x-x-109">F</span><sub><span 
class="cmmi-8">i</span></sub><sup><span 
class="cmmi-8">T</span> </sup><span 
class="cmmi-10x-x-109">&#x03B2;</span>, assume a Gaussian distribution for <span 
class="cmmi-10x-x-109">y</span><sub><span 
class="cmmi-8">i</span></sub>, with variance <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup> and <span 
class="cmmi-10x-x-109">x </span>as a
GF.
</p><!--l. 167--><p class="indent" >   We can extend this basic hierarchical model in many ways, and we return to some extensions
in later sections. If we know the properties of the GF, we can study all the practical models that
contain, or are based on, this random effect.
</p><!--l. 173--><p class="indent" >   It is worth mentioning that the data, or the random effect, on a finite number of <span 
class="cmmi-10x-x-109">n </span>points
where we have observed data are considered a realization of a multivariate Gaussian
distribution. Therefore, to evaluate the likelihood function, or the random effect distribution, we
need to compute the multivariate Gaussian density. So, we have, in the log scale, the
expression
</p>
   <table 
class="equation"><tr><td><a 
 id="x5-5003r3"></a>
   <center class="math-display" >
<img 
src="spde-tutorial2x.png" alt="  1 (                                            )
- -- nlog(2&#x03C0;)+ log(|&#x03A3;|)+ [x(s)- &#x03BC;x]T&#x03A3;- 1[x(s)-  &#x03BC;x]
  2
" class="math-display"  /></center></td><td class="equation-label">(1.3)</td></tr></table>
<!--l. 184--><p class="nopar" >
where <span 
class="cmr-10x-x-109">&#x03A3; </span>is a dense <span 
class="cmmi-10x-x-109">n </span><span 
class="cmsy-10x-x-109">&#x00D7; </span><span 
class="cmmi-10x-x-109">n</span>. To compute this, we need a factorization of this matrix.
Because this matrix is a dense, this is a operation of order <span 
class="cmmi-10x-x-109">O</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">n</span><sup><span 
class="cmr-8">3</span></sup><span 
class="cmr-10x-x-109">)</span>, so this is a &#8217;big n
problem&#8217;.
</p><!--l. 190--><p class="indent" >   An alternative used in some software for geostatistical analysis is to use the empirical
variogram to fit the parameters of the correlation function. This option does not use any
likelihood for the data or uses a multivariate Gaussian distribution for the spatially
structured random effect. A good description of these techniques is made in <span class="cite">[<a 
href="spde-tutorialli2.html#Xcressie:1993">Cressie,
1993</a>]</span>.
</p><!--l. 199--><p class="indent" >   However, it is adequate to assume a likelihood for the data and a GF for the spatial
dependence as in the model based approach proposed for geostatistics, <span class="cite">[<a 
href="spde-tutorialli2.html#Xdiggleribeiro:2007">Diggle and Ribeiro Jr,
2007</a>]</span>. At times we need to use the multivariate Gaussian distribution for the random effect. But,
if the dimension of the GF is big, it becomes impractical for model-based inference to directy use
the covariance as defined previously.
</p><!--l. 208--><p class="indent" >   In another area of the spatial statistics, the analysis of areal data, there are models specified
by conditional distributions that imply a joint distribution with a sparse precision matrix. These
models are called Gaussian Markov random fields (GMRF), <span class="cite">[<a 
href="spde-tutorialli2.html#XRueHeld:2005">Rue and Held, 2005</a>]</span>. It is
easier to make Bayesian inference when we use a GMRF than when we use the GF,
because to work with two dimensional GMRF models we have a cost of <span 
class="cmmi-10x-x-109">O</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">n</span><sup><span 
class="cmr-8">3</span><span 
class="cmmi-8">&#x2215;</span><span 
class="cmr-8">2</span></sup><span 
class="cmr-10x-x-109">) </span>on the
computations with its precision matrix. This makes it easier to conduct analyses with big
&#8217;n&#8217;.
</p><!--l. 3--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">1.2   </span> <a 
 id="x5-60001.2"></a>Simulation of a data set</h3>
                                                                                 
                                                                                 
<!--l. 7--><p class="noindent" >First we look at the model with a parametrization used in a commonly used software program
for analyzing point-referenced data in <span 
class="aeb10-x-x-109">R</span>, the <span 
class="aeb10-x-x-109">geoR </span>package, <span class="cite">[<a 
href="spde-tutorialli2.html#XgeoR">Ribeiro Jr and Diggle, 2001</a>]</span>. In this
section we show how we simulate a dataset with this parametrization.
</p><!--l. 14--><p class="indent" >   Recall that one realization of a GF is just one realization of a multivariate Gaussian
distribution with an appropriate covariance matrix. To specify this matrix, we need a set of
locations and the matrix of the distances between each point and all others. Based on this <span 
class="cmmi-10x-x-109">n</span><span 
class="cmsy-10x-x-109">&#x00D7;</span><span 
class="cmmi-10x-x-109">n</span>
distance matrix, we compute the covariance matrix and do one simulation of a multivariate
Gaussian distribution.
</p><!--l. 26--><p class="indent" >   Suppose that we have a set of <span 
class="cmmi-10x-x-109">n </span><span 
class="cmr-10x-x-109">= 100 </span>locations on a square with area one with bottom
left and top right limits: (0,0) and (1,1). We choose these locations with a higher
density in the bottom left corner than in the top right corner. The <span 
class="aeb10-x-x-109">R </span>code to do this
is:
</p>
   <div class="fancyvrb" id="fancyvrb1"><a 
 id="x5-6002r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;n</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;200;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;set.seed(123)</span><br class="fancyvrb" /><a 
 id="x5-6004r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;pts</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;cbind(s1=sample(1:n/n-0.5/n)^2,</span><span 
class="aesltt-10x-x-109">&#x00A0;s2=sample(1:n/n-0.5/n)^2)</span></div>
<!--l. 38--><p class="noindent" >and to get the (lower triangle) matrix of distances we do
</p>
   <div class="fancyvrb" id="fancyvrb2"><a 
 id="x5-6006r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;dmat</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;dist(pts)</span></div>
<!--l. 44--><p class="noindent" >and for the Matérn covariance we need the parameters: <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub><sup><span 
class="cmr-8">2</span></sup>, <span 
class="cmmi-10x-x-109">&#x03BA; </span>and <span 
class="cmmi-10x-x-109">&#x03BD;</span>. Additionally, we need
the mean <span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">0</span></sub> and the nugget parameter <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup>. We declare values to these parameters
using
</p>
   <div class="fancyvrb" id="fancyvrb3"><a 
 id="x5-6008r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;beta0</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;10;</span><span 
class="aesltt-10x-x-109">&#x00A0;sigma2e</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;0.3;</span><span 
class="aesltt-10x-x-109">&#x00A0;sigma2x</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;5;</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;7;</span><span 
class="aesltt-10x-x-109">&#x00A0;nu</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;1</span></div>
<!--l. 55--><p class="indent" >   We first consider <span 
class="cmmi-10x-x-109">y </span>as mean <span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">0</span></sub> and with covariance <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup><span 
class="cmmi-10x-x-109">I </span><span 
class="cmr-10x-x-109">+ &#x03A3;</span>. We get the covariance
using
</p>
   <div class="fancyvrb" id="fancyvrb4"><a 
 id="x5-6010r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;mcor</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;as.matrix(2^(1-nu)*(kappa*dmat)^nu*</span><br class="fancyvrb" /><a 
 id="x5-6012r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;besselK(dmat*kappa,nu)/gamma(nu))</span>
<br class="fancyvrb" /><a 
 id="x5-6014r3"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;diag(mcor)</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;1;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;mcov</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;sigma2e*diag(n)</span><span 
class="aesltt-10x-x-109">&#x00A0;+</span><span 
class="aesltt-10x-x-109">&#x00A0;sigma2x*mcor</span></div>
<!--l. 66--><p class="indent" >   Now we going to simulate one realization of a geostatistical model. First, we do the
simulation of one realization of the multivariate Gaussian distribution. Here we remember that if
we want to get <span 
class="cmmi-10x-x-109">y </span><span 
class="cmsy-10x-x-109">~ </span><span 
class="cmmi-10x-x-109">N</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">&#x03BC;,</span><span 
class="cmr-10x-x-109">&#x03A3;) </span>from <span 
class="cmmi-10x-x-109">z </span><span 
class="cmsy-10x-x-109">~ </span><span 
class="cmmi-10x-x-109">N</span><span 
class="cmr-10x-x-109">(0</span><span 
class="cmmi-10x-x-109">,I</span><span 
class="cmr-10x-x-109">)</span>, we do <span 
class="cmmi-10x-x-109">y </span><span 
class="cmr-10x-x-109">= </span><span 
class="cmmi-10x-x-109">&#x03BC; </span><span 
class="cmr-10x-x-109">+ </span><span 
class="cmmi-10x-x-109">zL</span>, where <span 
class="cmmi-10x-x-109">L </span>is a matrix that
<span 
class="cmmi-10x-x-109">L</span><sup><span 
class="cmmi-8">T</span> </sup><span 
class="cmmi-10x-x-109">L </span><span 
class="cmr-10x-x-109">= &#x03A3;</span>. So, we use the Cholesky factorization of the covariance matrix, because if <span 
class="cmmi-10x-x-109">L </span>is the
Cholesky of the <span 
class="cmr-10x-x-109">&#x03A3;</span>, them <span 
class="cmmi-10x-x-109">L</span><sup><span 
class="cmmi-8">T</span> </sup><span 
class="cmmi-10x-x-109">L </span><span 
class="cmr-10x-x-109">= &#x03A3;</span>. In <span 
class="aeb10-x-x-109">R </span>we use:
</p>
   <div class="fancyvrb" id="fancyvrb5"><a 
 id="x5-6016r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;L</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;chol(mcov);</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;set.seed(234);</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;y1</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;beta0</span><span 
class="aesltt-10x-x-109">&#x00A0;+</span><span 
class="aesltt-10x-x-109">&#x00A0;drop(rnorm(n)%*%L)</span></div>
<!--l. 83--><p class="indent" >   We show these simulated data in a graph of the locations where the size of the
points is proportional to the simulated values in Figure&#x00A0;<a 
href="#x5-60251">1.1<!--tex4ht:ref: fig:grf1 --></a>, produced with the code
below
</p>
   <div class="fancyvrb" id="fancyvrb6"><a 
 id="x5-6018r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;par(mar=c(3,3,1,1),</span><span 
class="aesltt-10x-x-109">&#x00A0;mgp=c(1.7,</span><span 
class="aesltt-10x-x-109">&#x00A0;0.7,</span><span 
class="aesltt-10x-x-109">&#x00A0;0),</span><span 
class="aesltt-10x-x-109">&#x00A0;las=1)</span><br class="fancyvrb" /><a 
 id="x5-6020r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;plot(pts,</span><span 
class="aesltt-10x-x-109">&#x00A0;asp=1,</span><span 
class="aesltt-10x-x-109">&#x00A0;xlim=c(0,1.2),</span><span 
class="aesltt-10x-x-109">&#x00A0;cex=y1/10)</span>
<br class="fancyvrb" /><a 
 id="x5-6022r3"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;q</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;quantile(y1,</span><span 
class="aesltt-10x-x-109">&#x00A0;0:5/5)</span><br class="fancyvrb" /><a 
 id="x5-6024r4"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;legend(</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">topright</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">,</span><span 
class="aesltt-10x-x-109">&#x00A0;format(q,</span><span 
class="aesltt-10x-x-109">&#x00A0;dig=2),</span><span 
class="aesltt-10x-x-109">&#x00A0;pch=1,</span><span 
class="aesltt-10x-x-109">&#x00A0;pt.cex=q/10)</span></div>
                                                                                 
                                                                                 
<hr class="figure" /><div class="figure" 
><a 
 id="x5-60251"></a><img 
src="spde-tutorial3x.png" alt="PIC" class="graphics" width="213.39748pt" height="182.14091pt"  /><!--tex4ht:graphics  
name="spde-tutorial3x.png" src="figs/lik-plot1.eps"  
-->
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1.1: </span><span  
class="content">Visualization of the simulated data</span></div><!--tex4ht:label?: x5-60251 -->
   </div><hr class="endfigure" />
<!--l. 101--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">1.3   </span> <a 
 id="x5-70001.3"></a>Maximum likelihood estimation</h3>
<!--l. 103--><p class="noindent" >In this section we perform maximum likelihood estimation for the parameters of the model used
to simulate the data in the previous section. It is useful to use the partial derivatives with
respect to each parameter to compute the Fisher information matrix. We can then use it in the
Newton-Raphson algorithm or in the Fisher scoring algorithm. It is even better if there
exists closed form expressions for the maximum likelihood estimators to some of the
parameters.
</p><!--l. 115--><p class="indent" >   Under a Gaussian likelihood we have that the mean is orthogonal to the variance. This
implies we can use closed form expressions to estimate the mean, or (in general) the regression
parameters. Additionally, we can re-write the covariance and derive a closed form
expression to estimate <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub><sup><span 
class="cmr-8">2</span></sup>. Then an optimization algorithm can be used for the remaining
parameters.
</p><!--l. 124--><p class="indent" >   Deriving with respect to <span 
class="cmmi-10x-x-109">&#x03B2; </span>we can compute its maximum likelihood estimator
solving
</p>
   <center class="math-display" >
<img 
src="spde-tutorial4x.png" alt="   &#x2032;     &#x02C6;    &#x2032;
(F W  F )&#x03B2; =  F W  y
" class="math-display"  /></center>
<!--l. 126--><p class="nopar" > where <span 
class="cmmib-10x-x-109">W</span> is the inverse of the covariance matrix. Writing the variance parameter of the noise,
<span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup>, in terms of the relative one, <span 
class="cmmi-10x-x-109">r </span><span 
class="cmr-10x-x-109">= </span><span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup><span 
class="cmmi-10x-x-109">&#x2215;&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub><sup><span 
class="cmr-8">2</span></sup>, we have
</p>
   <center class="math-display" >
<img 
src="spde-tutorial5x.png" alt="Cov(y) = &#x03C3;2(rI + C )
          x
" class="math-display"  /></center>
<!--l. 133--><p class="nopar" > where <span 
class="cmmib-10x-x-109">C</span> is the correlation matrix. This implies that <span 
class="cmmib-10x-x-109">W</span> <span 
class="cmr-10x-x-109">= (</span><span 
class="cmmi-10x-x-109">r</span><span 
class="cmmib-10x-x-109">I</span> <span 
class="cmr-10x-x-109">+</span> <span 
class="cmmib-10x-x-109">C</span><span 
class="cmr-10x-x-109">)</span><sup><span 
class="cmsy-8">-</span><span 
class="cmr-8">1</span></sup>. Deriving with respect to
<span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">x</span></sub><sup><span 
class="cmr-8">2</span></sup> we can find
</p>
   <center class="math-display" >
<img 
src="spde-tutorial6x.png" alt="&#x02C6;&#x03C3;2 = (y - F &#x02C6;&#x03B2;)&#x2032;W (y - F &#x02C6;&#x03B2;)&#x2215;n.
 x     i           i
" class="math-display"  /></center>
<!--l. 139--><p class="nopar" >
</p><!--l. 141--><p class="indent" >   Now, we can work with a concentrated log-likelihood, that is a function of the relative
variance of the noise <span 
class="cmmi-10x-x-109">r</span>, the scale <span 
class="cmmi-10x-x-109">&#x03BA; </span>and the smoothness parameter <span 
class="cmmi-10x-x-109">&#x03BD;</span>
</p>
   <center class="math-display" >
<img 
src="spde-tutorial7x.png" alt="  1-               2
- 2(|W |+ n (log(2&#x03C0;&#x02C6;&#x03C3;x) + 1)).
" class="math-display"  /></center>
<!--l. 146--><p class="nopar" > We use quasi-Newton methods to find the maximum likelihood estimates of these three
parameters.
</p><!--l. 150--><p class="indent" >   The likelihood function is just the multivariate normal density, considering the mean as a
regression with identity link and the covariance with a Matérn covariance plus the nugget effect.
In the implemented function (below), we have the matrix of distances between the points as one
of the arguments, because it is not necessary to recalculate this matrix at each iteration of the
minimization algorithm.
</p><!--l. 159--><p class="indent" >   We use the negative of the logarithm of the likelihood function because, by default, the
algorithm finds the minimum of a function. In the computation of the likelihood, we use the
Cholesky factorization to compute the determinant and also the inverse of the covariance
matrix.
</p>
   <div class="fancyvrb" id="fancyvrb7"><a 
 id="x5-7002r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;nllf</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;function(pars,</span><span 
class="aesltt-10x-x-109">&#x00A0;ff,</span><span 
class="aesltt-10x-x-109">&#x00A0;y,</span><span 
class="aesltt-10x-x-109">&#x00A0;m)</span><span 
class="aesltt-10x-x-109">&#x00A0;{</span><br class="fancyvrb" /><a 
 id="x5-7004r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;m</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;2^(1-pars[3])*(pars[2]*m)^pars[3]*</span>
<br class="fancyvrb" /><a 
 id="x5-7006r3"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;besselK(m*pars[2],pars[3])/gamma(pars[3])</span><br class="fancyvrb" /><a 
 id="x5-7008r4"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;diag(m)</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;1</span><span 
class="aesltt-10x-x-109">&#x00A0;+</span><span 
class="aesltt-10x-x-109">&#x00A0;pars[1]</span><br class="fancyvrb" /><a 
 id="x5-7010r5"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;m</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;chol(m)</span>
<br class="fancyvrb" /><a 
 id="x5-7012r6"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;ldet.5</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;sum(log(diag(m)))</span><br class="fancyvrb" /><a 
 id="x5-7014r7"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;m</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;chol2inv(m)</span><br class="fancyvrb" /><a 
 id="x5-7016r8"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;beta</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;solve(crossprod(ff,</span><span 
class="aesltt-10x-x-109">&#x00A0;m)%*%ff,</span>
<br class="fancyvrb" /><a 
 id="x5-7018r9"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;crossprod(ff,</span><span 
class="aesltt-10x-x-109">&#x00A0;m)%*%y)</span><br class="fancyvrb" /><a 
 id="x5-7020r10"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;z</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;y-ff%*%beta</span>
<br class="fancyvrb" /><a 
 id="x5-7022r11"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;s2x.hat</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;mean(crossprod(m,z)*z)</span><br class="fancyvrb" /><a 
 id="x5-7024r12"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;res</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;ldet.5</span><span 
class="aesltt-10x-x-109">&#x00A0;+</span><span 
class="aesltt-10x-x-109">&#x00A0;nrow(m)*(1+log(2*pi*s2x.hat))/2</span>
<br class="fancyvrb" /><a 
 id="x5-7026r13"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;attr(res,</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">param</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">)</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;###</span><span 
class="aesltt-10x-x-109">&#x00A0;to</span><span 
class="aesltt-10x-x-109">&#x00A0;return</span><span 
class="aesltt-10x-x-109">&#x00A0;the</span><span 
class="aesltt-10x-x-109">&#x00A0;parameters</span><span 
class="aesltt-10x-x-109">&#x00A0;together</span>
<br class="fancyvrb" /><a 
 id="x5-7028r14"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;c(beta=beta,</span><span 
class="aesltt-10x-x-109">&#x00A0;s2e=pars[1]*s2x.hat,</span><br class="fancyvrb" /><a 
 id="x5-7030r15"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;s2x=s2x.hat,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa=pars[2],</span><span 
class="aesltt-10x-x-109">&#x00A0;nu=pars[3])</span>
<br class="fancyvrb" /><a 
 id="x5-7032r16"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;return(res)</span><br class="fancyvrb" /><a 
 id="x5-7034r17"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;}</span></div>
<!--l. 186--><p class="noindent" >The implemented function is a function of the three length parameters vector (<span 
class="cmmi-10x-x-109">r</span>, <span 
class="cmmi-10x-x-109">&#x03BA; </span>and <span 
class="cmmi-10x-x-109">&#x03BD;</span>), the
covariate (design) matrix, the data and the matrix of distances:
</p><!--l. 191--><p class="indent" >   For a test, we calculate the likelihood at true values of the parameters
</p>
   <div class="fancyvrb" id="fancyvrb8"><a 
 id="x5-7036r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;(nllf(c(sigma2e/sigma2x,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa,</span><span 
class="aesltt-10x-x-109">&#x00A0;nu),</span><span 
class="aesltt-10x-x-109">&#x00A0;matrix(1,n),</span><span 
class="aesltt-10x-x-109">&#x00A0;y1,</span><span 
class="aesltt-10x-x-109">&#x00A0;as.matrix(dmat)))</span></div>
<!--l. 197--><p class="noindent" >
</p>
   <div class="fancyvrb" id="fancyvrb9"><a 
 id="x5-7038r1"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;[1]</span><span 
class="aett-10x-x-109">&#x00A0;281.6389</span><br class="fancyvrb" /><a 
 id="x5-7040r2"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;attr(,"param")</span><br class="fancyvrb" /><a 
 id="x5-7042r3"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;beta</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;s2e</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;s2x</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;kappa</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;nu</span>
<br class="fancyvrb" /><a 
 id="x5-7044r4"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;9.4656790</span><span 
class="aett-10x-x-109">&#x00A0;0.2715257</span><span 
class="aett-10x-x-109">&#x00A0;4.5254278</span><span 
class="aett-10x-x-109">&#x00A0;7.0000000</span><span 
class="aett-10x-x-109">&#x00A0;1.0000000</span></div>
<!--l. 204--><p class="noindent" >and at another set of the values
</p>
   <div class="fancyvrb" id="fancyvrb10"><a 
 id="x5-7046r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;(nllf(c(0,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa,</span><span 
class="aesltt-10x-x-109">&#x00A0;nu),</span><span 
class="aesltt-10x-x-109">&#x00A0;matrix(1,n),</span><span 
class="aesltt-10x-x-109">&#x00A0;y1,</span><span 
class="aesltt-10x-x-109">&#x00A0;as.matrix(dmat)))</span></div>
<!--l. 209--><p class="noindent" >
</p>
   <div class="fancyvrb" id="fancyvrb11"><a 
 id="x5-7048r1"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;[1]</span><span 
class="aett-10x-x-109">&#x00A0;394.9953</span><br class="fancyvrb" /><a 
 id="x5-7050r2"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;attr(,"param")</span><br class="fancyvrb" /><a 
 id="x5-7052r3"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;beta</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;s2e</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;s2x</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;kappa</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;nu</span>
<br class="fancyvrb" /><a 
 id="x5-7054r4"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;8.899256</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;0.000000</span><span 
class="aett-10x-x-109">&#x00A0;35.641913</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;7.000000</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;1.000000</span></div>
                                                                                 
                                                                                 
<!--l. 217--><p class="indent" >   We get the maximum likelihood estimates with the &#8217;L-BFGS-B&#8217; method available
through the <span 
class="aett-10x-x-109">optim() </span>function. The maximum likelihood estimates for <span 
class="cmmi-10x-x-109">r</span>, <span 
class="cmmi-10x-x-109">&#x03BA; </span>and <span 
class="cmmi-10x-x-109">&#x03BD;</span>
are
</p>
   <div class="fancyvrb" id="fancyvrb12"><a 
 id="x5-7056r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;(ores</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;optim(c(sigma2e/sigma2x,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa,</span><span 
class="aesltt-10x-x-109">&#x00A0;nu),</span><span 
class="aesltt-10x-x-109">&#x00A0;nllf,</span><span 
class="aesltt-10x-x-109">&#x00A0;hessian=TRUE,</span>
<br class="fancyvrb" /><a 
 id="x5-7058r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;ff=matrix(1,n),</span><span 
class="aesltt-10x-x-109">&#x00A0;y=y1,</span><span 
class="aesltt-10x-x-109">&#x00A0;m=as.matrix(dmat),</span>
<br class="fancyvrb" /><a 
 id="x5-7060r3"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;method=</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">L-BFGS-B</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">,</span><span 
class="aesltt-10x-x-109">&#x00A0;lower=rep(1e-5,3)))$par</span></div>
<!--l. 227--><p class="noindent" >
</p>
   <div class="fancyvrb" id="fancyvrb13"><a 
 id="x5-7062r1"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;[1]</span><span 
class="aett-10x-x-109">&#x00A0;0.08628548</span><span 
class="aett-10x-x-109">&#x00A0;9.40307960</span><span 
class="aett-10x-x-109">&#x00A0;1.08654743</span></div>
<!--l. 231--><p class="noindent" >and we get all the estimated parameters by evaluating our concentrated log-likelihood again to get
all estimates
</p>
   <div class="fancyvrb" id="fancyvrb14"><a 
 id="x5-7064r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;(lkhat</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;attr(nllf(ores$par,</span><span 
class="aesltt-10x-x-109">&#x00A0;matrix(1,n),</span><br class="fancyvrb" /><a 
 id="x5-7066r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;y1,</span><span 
class="aesltt-10x-x-109">&#x00A0;as.matrix(dmat)),</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">param</span><span 
class="tcst-1095">'</span><span 
class="aesltt-10x-x-109">))</span></div>
<!--l. 239--><p class="noindent" >
</p>
   <div class="fancyvrb" id="fancyvrb15"><a 
 id="x5-7068r1"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;beta</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;s2e</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;s2x</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;kappa</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;nu</span>
<br class="fancyvrb" /><a 
 id="x5-7070r2"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;9.5457270</span><span 
class="aett-10x-x-109">&#x00A0;0.2824723</span><span 
class="aett-10x-x-109">&#x00A0;3.2736940</span><span 
class="aett-10x-x-109">&#x00A0;9.4030796</span><span 
class="aett-10x-x-109">&#x00A0;1.0865474</span></div>
<!--l. 245--><p class="indent" >   This solution via maximum likelihood is to show how it works. The <span 
class="aeb10-x-x-109">geoR </span>package includes
functions to do simulations and also to perform likelihood estimation. However, the Matérn
correlation function is parametrized differently in the <span 
class="aeb10-x-x-109">geoR </span>package, which uses <span 
class="cmmi-10x-x-109">&#x03D5; </span><span 
class="cmr-10x-x-109">= 1</span><span 
class="cmmi-10x-x-109">&#x2215;&#x03BA; </span>for the
scale parameter and it uses kappa for the smoothness parameter. Also <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmmi-8">e</span></sub><sup><span 
class="cmr-8">2</span></sup> is called
<span 
class="aett-10x-x-109">tausq</span>.
</p><!--l. 254--><p class="indent" >   The <span 
class="aett-10x-x-109">grf() </span>function can be used to get samples of a geostatistical model with several options
for the correlation function. To get exactly the same data, we use
</p>
   <div class="fancyvrb" id="fancyvrb16"><a 
 id="x5-7072r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;require(geoR);</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;set.seed(234)</span><br class="fancyvrb" /><a 
 id="x5-7074r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;grf1</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;grf(grid=pts,</span><span 
class="aesltt-10x-x-109">&#x00A0;cov.pars=c(sigma2x,</span><span 
class="aesltt-10x-x-109">&#x00A0;1/kappa),</span><span 
class="aesltt-10x-x-109">&#x00A0;mean=beta0,</span>
<br class="fancyvrb" /><a 
 id="x5-7076r3"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;nugget=sigma2e,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa=nu,</span><span 
class="aesltt-10x-x-109">&#x00A0;messages=FALSE)</span></div>
<!--l. 265--><p class="indent" >   We can use the <span 
class="aett-10x-x-109">likfit() </span>function to perform the maximum likelihood estimation. With this
function we obtain the maximum likelihood estimates for the smoothness parameter
using
</p>
   <div class="fancyvrb" id="fancyvrb17"><a 
 id="x5-7078r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;(g1res</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;likfit(grf1,</span><span 
class="aesltt-10x-x-109">&#x00A0;ini=c(sigma2x,</span><span 
class="aesltt-10x-x-109">&#x00A0;1/kappa),</span><span 
class="aesltt-10x-x-109">&#x00A0;messages=FALSE,</span>
<br class="fancyvrb" /><a 
 id="x5-7080r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;nugget=sigma2e,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa=nu,</span><span 
class="aesltt-10x-x-109">&#x00A0;fix.kappa=FALSE))</span></div>
<!--l. 274--><p class="noindent" >
</p>
   <div class="fancyvrb" id="fancyvrb18"><a 
 id="x5-7082r1"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;likfit:</span><span 
class="aett-10x-x-109">&#x00A0;estimated</span><span 
class="aett-10x-x-109">&#x00A0;model</span><span 
class="aett-10x-x-109">&#x00A0;parameters:</span><br class="fancyvrb" /><a 
 id="x5-7084r2"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;beta</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;tausq</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;sigmasq</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;phi</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;kappa</span>
<br class="fancyvrb" /><a 
 id="x5-7086r3"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;"9.5457"</span><span 
class="aett-10x-x-109">&#x00A0;"0.2824"</span><span 
class="aett-10x-x-109">&#x00A0;"3.2741"</span><span 
class="aett-10x-x-109">&#x00A0;"0.1064"</span><span 
class="aett-10x-x-109">&#x00A0;"1.0862"</span>
<br class="fancyvrb" /><a 
 id="x5-7088r4"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;Practical</span><span 
class="aett-10x-x-109">&#x00A0;Range</span><span 
class="aett-10x-x-109">&#x00A0;with</span><span 
class="aett-10x-x-109">&#x00A0;cor=0.05</span><span 
class="aett-10x-x-109">&#x00A0;for</span><span 
class="aett-10x-x-109">&#x00A0;asymptotic</span><span 
class="aett-10x-x-109">&#x00A0;range:</span><span 
class="aett-10x-x-109">&#x00A0;0.4403836</span><br class="fancyvrb" /><a 
 id="x5-7090r5"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span>
<br class="fancyvrb" /><a 
 id="x5-7092r6"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;likfit:</span><span 
class="aett-10x-x-109">&#x00A0;maximised</span><span 
class="aett-10x-x-109">&#x00A0;log-likelihood</span><span 
class="aett-10x-x-109">&#x00A0;=</span><span 
class="aett-10x-x-109">&#x00A0;-281.1</span></div>
<!--l. 284--><p class="indent" >   If we fix the smoothness parameter <span 
class="cmmi-10x-x-109">&#x03BD; </span>on the value, we find the maximum likelihood estimates
of other parameters using
</p>
   <div class="fancyvrb" id="fancyvrb19"><a 
 id="x5-7094r1"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;(fit.l</span><span 
class="aesltt-10x-x-109">&#x00A0;&#x003C;-</span><span 
class="aesltt-10x-x-109">&#x00A0;likfit(grf1,</span><span 
class="aesltt-10x-x-109">&#x00A0;ini.cov.pars=c(sigma2x,</span><span 
class="aesltt-10x-x-109">&#x00A0;1/kappa),</span>
<br class="fancyvrb" /><a 
 id="x5-7096r2"></a><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;</span><span 
class="aesltt-10x-x-109">&#x00A0;nugget=sigma2e,</span><span 
class="aesltt-10x-x-109">&#x00A0;kappa=1,</span><span 
class="aesltt-10x-x-109">&#x00A0;messages=FALSE))</span></div>
                                                                                 
                                                                                 
<!--l. 292--><p class="noindent" >
</p>
   <div class="fancyvrb" id="fancyvrb20"><a 
 id="x5-7098r1"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;likfit:</span><span 
class="aett-10x-x-109">&#x00A0;estimated</span><span 
class="aett-10x-x-109">&#x00A0;model</span><span 
class="aett-10x-x-109">&#x00A0;parameters:</span><br class="fancyvrb" /><a 
 id="x5-7100r2"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;beta</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;tausq</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;sigmasq</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;phi</span>
<br class="fancyvrb" /><a 
 id="x5-7102r3"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;"9.5349"</span><span 
class="aett-10x-x-109">&#x00A0;"0.2709"</span><span 
class="aett-10x-x-109">&#x00A0;"3.3234"</span><span 
class="aett-10x-x-109">&#x00A0;"0.1156"</span><br class="fancyvrb" /><a 
 id="x5-7104r4"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;Practical</span><span 
class="aett-10x-x-109">&#x00A0;Range</span><span 
class="aett-10x-x-109">&#x00A0;with</span><span 
class="aett-10x-x-109">&#x00A0;cor=0.05</span><span 
class="aett-10x-x-109">&#x00A0;for</span><span 
class="aett-10x-x-109">&#x00A0;asymptotic</span><span 
class="aett-10x-x-109">&#x00A0;range:</span><span 
class="aett-10x-x-109">&#x00A0;0.4620667</span>
<br class="fancyvrb" /><a 
 id="x5-7106r5"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;</span><br class="fancyvrb" /><a 
 id="x5-7108r6"></a><span 
class="aett-10x-x-109">&#x00A0;</span><span 
class="aett-10x-x-109">&#x00A0;likfit:</span><span 
class="aett-10x-x-109">&#x00A0;maximised</span><span 
class="aett-10x-x-109">&#x00A0;log-likelihood</span><span 
class="aett-10x-x-109">&#x00A0;=</span><span 
class="aett-10x-x-109">&#x00A0;-281.1</span></div>
<!--l. 301--><p class="noindent" >Notice that the likelihood here has a similar value as the previous one, because the previously
estimated value of <span 
class="cmmi-10x-x-109">&#x03BD; </span>is close to the fixed value here.
                                                                                 
                                                                                 
</p>
   <!--l. 1--><div class="crosslinks"><p class="noindent">[<a 
href="spde-tutorialch2.html" >next</a>] [<a 
href="spde-tutorialli1.html" >prev</a>] [<a 
href="spde-tutorialli1.html#tailspde-tutorialli1.html" >prev-tail</a>] [<a 
href="spde-tutorialch1.html" >front</a>] [<a 
href="spde-tutorial3.html#spde-tutorialch1.html" >up</a>] </p></div>
<!--l. 1--><p class="indent" >   <a 
 id="tailspde-tutorialch1.html"></a>  </p> 
</body></html> 
