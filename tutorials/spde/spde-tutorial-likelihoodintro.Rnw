\input{spde-tutorial-introduction} 

\section{Simulation of a data set} 

\SweaveOpts{prefix.string=figs/lik}
<<echo=F,results=hide>>=
options(width=75, prompt = " ", continue = "   ")
@ 

First we look at the model with 
a parametrization used in a commonly used software 
program for analyzing point-referenced data 
in \pkg{R}, the \pkg{geoR} package, \cite{geoR}. 
In this section we show how we simulate a dataset 
with this parametrization. 

Recall that one realization of 
a GF is just one realization of a 
multivariate Gaussian distribution with 
an appropriate covariance matrix. 
To specify this matrix, we need a set 
of locations and the matrix of the distances 
between each point and all others. 
Based on this $n\times n$ distance matrix, 
we compute the covariance matrix and 
do one simulation of a multivariate 
Gaussian distribution. 

Suppose that we have a set of $n=100$ locations 
on a square with area one with bottom left and 
top right limits: (0,0) and (1,1). 
We choose these locations with a higher density in 
the bottom left corner than in the top right corner. 
The \pkg{R} code to do this is:
<<rpts>>=
n <- 200;  set.seed(123) 
pts <- cbind(s1=sample(1:n/n-0.5/n)^2, s2=sample(1:n/n-0.5/n)^2)
@ 
and to get the (lower triangle) matrix of distances we do
<<distpts>>=
dmat <- dist(pts)
@ 
and for the Mat\'ern covariance we need the 
parameters: $\sigma^2_x$, $\kappa$ and $\nu$. 
Additionally, we need the mean $\beta_0$  and 
the nugget parameter $\sigma^2_e$. 
We declare values to these parameters using
<<params>>=
beta0 <- 10; sigma2e <- 0.3; sigma2x <- 5; kappa <- 7; nu <- 1
@ 

We first consider $y$ as mean $\beta_0$ and 
with covariance $\sigma^2_eI + \Sigma$. 
We get the covariance using
<<covMatm>>=
mcor <- as.matrix(2^(1-nu)*(kappa*dmat)^nu*
                  besselK(dmat*kappa,nu)/gamma(nu))
diag(mcor) <- 1;   mcov <- sigma2e*diag(n) + sigma2x*mcor
@ 

Now we going to simulate one realization of a 
geostatistical model. 
First, we do the simulation of one realization 
of the multivariate Gaussian distribution. 
Here we remember that if we want to get 
$y\sim N(\mu, \Sigma)$ from $z\sim N(0, I)$, we do 
$y = \mu + zL$, where $L$ is a matrix that $L^{T}L=\Sigma$. 
So, we use the Cholesky factorization of the 
covariance matrix, because if $L$ is the Cholesky 
of the $\Sigma$, them $L^{T}L=\Sigma$.
In \pkg{R} we use:
<<chol1mvnorm>>=
L <- chol(mcov);   set.seed(234);   y1 <- beta0 + drop(rnorm(n)%*%L)
@ 

We show these simulated data in a graph of the locations 
where the size of the points is proportional to the simulated values
in Figure~\ref{fig:grf1}, produced with the code below
<<plot1c,eval=F>>=
par(mar=c(3,3,1,1), mgp=c(1.7, 0.7, 0), las=1)
plot(pts, asp=1, xlim=c(0,1.2), cex=y1/10)
q <- quantile(y1, 0:5/5)
legend('topright', format(q, dig=2), pch=1, pt.cex=q/10)
@ 
\setkeys{Gin}{width=0.5\textwidth}
\begin{figure}\centering
<<plot1,fig=T,eps=F,echo=F,width=5.5,height=4.7>>=
<<plot1c>>
@ 
\caption{Visualization of the simulated data}
\label{fig:grf1}
\end{figure}

\section{Maximum likelihood estimation}

In this section we perform maximum likelihood estimation
for the parameters of the model used to 
simulate the data in the previous section. 
It is useful to use the partial 
derivatives with respect to each parameter to 
compute the Fisher information matrix. 
We can then use it in the Newton-Raphson algorithm 
or in the Fisher scoring algorithm. 
It is even better if there exists closed form 
expressions for the maximum likelihood estimators 
to some of the parameters. 

Under a Gaussian likelihood we have that the
mean is orthogonal to the variance. 
This implies we can use closed form expressions to estimate the mean, 
or (in general) the regression parameters. 
Additionally, we can re-write the covariance and 
derive a closed form expression to estimate $\sigma_x^2$. 
Then an optimization algorithm can be used for the 
remaining parameters. 

Deriving with respect to $\beta$ we can compute 
its maximum likelihood estimator solving 
\[ (\bF^{'}\bW\bF)\hat{\beta} = \bF^{'}\bW\by \]
where $\bW$ is the inverse of the covariance matrix. 
Writing the variance parameter of the noise, 
$\sigma^2_e$, in terms of the relative one, 
$r=\sigma_e^2/\sigma_x^2$, we have 
\[
Cov(\by) = \sigma^2_x(r\bI + \bC )
\]
where $\bC$ is the correlation matrix. 
This implies that $\bW = (r\bI + \bC )^{-1}$. 
Deriving with respect to $\sigma^2_x$ we can find 
\[
\hat{\sigma}_x^2 = (y_i-\bF\hat{\beta})^{'}\bW(y_i-\bF\hat{\beta})/n\;.
\]

Now, we can work with a concentrated log-likelihood, 
that is a function of the relative variance of the noise $r$, 
the scale $\kappa$ and the smoothness parameter $\nu$ 
\[
-\frac{1}{2}(|\bW| + n(\log(2\pi\hat{\sigma}_x^2)+1))\;.
\]
We use quasi-Newton methods to find the 
maximum likelihood estimates of these three parameters. 

The likelihood function is just the multivariate 
normal density, considering the mean as a regression 
with identity link and the covariance with a Mat\'ern 
covariance plus the nugget effect. 
In the implemented function (below), we have 
the matrix of distances between the points as one of the arguments, 
because it is not necessary to recalculate this matrix 
at each iteration of the minimization algorithm. 

We use the negative of the logarithm of the likelihood 
function because, by default, the algorithm 
finds the minimum of a function. 
In the computation of the likelihood, we use the 
Cholesky factorization to compute the determinant 
and also the inverse of the covariance matrix. 
<<lik1>>=
nllf <- function(pars, ff, y, m) {
  m <- 2^(1-pars[3])*(pars[2]*m)^pars[3]*
    besselK(m*pars[2],pars[3])/gamma(pars[3])
  diag(m) <- 1 + pars[1] 
  m <- chol(m) 
  ldet.5 <- sum(log(diag(m))) 
  m <- chol2inv(m)
  beta <- solve(crossprod(ff, m)%*%ff, 
                crossprod(ff, m)%*%y) 
  z <- y-ff%*%beta   
  s2x.hat <- mean(crossprod(m,z)*z) 
  res <- ldet.5 + nrow(m)*(1+log(2*pi*s2x.hat))/2
  attr(res, 'param') <- ### to return the parameters together
      c(beta=beta, s2e=pars[1]*s2x.hat, 
        s2x=s2x.hat, kappa=pars[2], nu=pars[3])
  return(res)
}
@ 
The implemented function is a function of the 
three length parameters vector ($r$,
$\kappa$ and $\nu$), the covariate (design) 
matrix, the data and the matrix of distances:

For a test, we calculate the likelihood at true values of the 
parameters 
<<nlltest>>=
(nllf(c(sigma2e/sigma2x, kappa, nu), matrix(1,n), y1, as.matrix(dmat)))
@ 
and at another set of the values
<<nlltest2>>=
(nllf(c(0, kappa, nu), matrix(1,n), y1, as.matrix(dmat)))
@ 

We get the maximum likelihood estimates with the 'L-BFGS-B' 
method available through the \code{optim()} function. 
The maximum likelihood estimates for $r$, 
$\kappa$ and $\nu$ are
<<llfit1>>=
(ores <- optim(c(sigma2e/sigma2x, kappa, nu), nllf, hessian=TRUE, 
               ff=matrix(1,n), y=y1, m=as.matrix(dmat), 
               method='L-BFGS-B', lower=rep(1e-5,3)))$par
@ 
and we get all the estimated parameters by 
evaluating our concentrated log-likelihood again 
to get all estimates 
<<diaghess>>=
(lkhat <- attr(nllf(ores$par, matrix(1,n), 
                    y1, as.matrix(dmat)), 'param'))
@ 

This solution via maximum likelihood is to show how it works. 
The \pkg{geoR} package includes functions to do
simulations and also to perform likelihood estimation. 
However, the Mat\'ern correlation function is parametrized 
differently in the \pkg{geoR} package, which uses 
$\phi=1/\kappa$ for the scale parameter and 
it uses kappa for the smoothness parameter. 
Also  $\sigma_e^2$ is called \code{tausq}.

The \code{grf()} function can be used to get samples of a 
geostatistical model with several options for the 
correlation function. To get exactly the same data, we use 
<<grf1>>=
require(geoR);   set.seed(234)
grf1 <- grf(grid=pts, cov.pars=c(sigma2x, 1/kappa), mean=beta0,
            nugget=sigma2e, kappa=nu, messages=FALSE) 
@ 

We can use the \code{likfit()} function to perform the 
maximum likelihood estimation. With this function we 
obtain the maximum likelihood estimates for the 
smoothness parameter using
<<withgeoR>>=
(g1res <- likfit(grf1, ini=c(sigma2x, 1/kappa), messages=FALSE,
                 nugget=sigma2e, kappa=nu, fix.kappa=FALSE))
@ 

If we fix the smoothness parameter $\nu$ on the value, 
we find the maximum likelihood estimates of 
other parameters using
<<geoRtoy-l>>=
(fit.l <- likfit(grf1, ini.cov.pars=c(sigma2x, 1/kappa), 
                 nugget=sigma2e, kappa=1, messages=FALSE))
@ 
Notice that the likelihood here has a similar value as the previous one, 
because the previously estimated value of $\nu$ is  
close to the fixed value here. 

