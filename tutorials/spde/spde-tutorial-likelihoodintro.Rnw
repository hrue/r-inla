\input{spde-tutorial-introduction}

\section{Simulation of a data set} 

\SweaveOpts{prefix.string=figs/sim}
<<echo=F,results=hide>>=
options(width=75, prompt = " ", continue = "   ")
@ 

First we took a look at the model %%and fitting process 
from parametrization used in a commonly software 
used to analyse the point refereed data 
in \pkg{R}, the \pkg{geoR} package, \cite{geoR}. 
In this section we show how we simulate a dataset 
with this parametrization. 

We remember here that one realization of 
a GF is just one realization of a 
multivariate Gaussian distribution with 
an appropriate covariance matrix. 
To specify these matrix, we need a set 
of locations and the matrix of distance 
between each point with all others. 
Based on this matrix $n\times n$ of distances, 
we compute the covariance matrix and 
do one simulation of a multivariate 
Gaussian distribution. 

Suppose that we have a set of $n=100$ locations, 
on a square with area one with bottom left and 
top right limits: (0,0) and (1,1). 
We choose these locations with density in 
left bottom corner higher than top right corner. 
The \pkg{R} code to do it is:
<<rpts>>=
n <- 200;  set.seed(123) 
pts <- cbind(s1=sample(1:n/n-0.5/n)^2, s2=sample(1:n/n-0.5/n)^2)
@ 
and for get the (lower triangle) matrix of distances we do
<<distpts>>=
dmat <- dist(pts)
@ 
and for the Mat\'ern covariance we need the 
parameters: $\sigma^2_x$, $\kappa$ and $\nu$. 
Additionally, we need the mean $\beta_0$  and 
the nugget parameter $\sigma^2_e$. 
We declare an values to such parameters by
<<params>>=
beta0 <- 10; sigma2e <- 0.3; sigma2x <- 5; kappa <- 7; nu <- 1
@ 

We, first, consider $y$ as mean $\beta_0$ and 
that covariance $\sigma^2_eI + \Sigma$. 
And, we get the covariance by
<<covMatm>>=
mcor <- as.matrix(2^(1-nu)*(kappa*dmat)^nu*
                  besselK(dmat*kappa,nu)/gamma(nu))
diag(mcor) <- 1;   mcov <- sigma2e*diag(n) + sigma2x*mcor
@ 

Now we going to simulate one realization of a 
geostatistical model. 
First, we do the simulation of one realization 
of the multivariate Gaussian distribution. 
Here we remember that if we want to get 
$y\sim N(\mu, \Sigma)$ from $z\sim N(0, I)$, we do 
$y = \mu + zL$, where $L$ is a matrix that $L^{T}L=\Sigma$. 
So, we use the Cholesky factorization of the 
covariance matrix, because if $L$ is the Cholesky 
of the $\Sigma$, so $L^{T}L=\Sigma$.
In \pkg{R} we use:
<<chol1mvnorm>>=
L <- chol(mcov);   set.seed(234);   y1 <- beta0 + drop(rnorm(n)%*%L)
@ 

We show this simulated data in a graph of the locations 
with size of points proportional of the simulated values
on Figure~\ref{fig:grf1} with code below
<<plot1c,eval=F>>=
par(mar=c(3,3,1,1), mgp=c(1.7, 0.7, 0), las=1)
plot(pts, asp=1, xlim=c(0,1.2), cex=y1/10)
q <- quantile(y1, 0:5/5)
legend('topright', format(q, dig=2), pch=1, pt.cex=q/10)
@ 
\setkeys{Gin}{width=0.5\textwidth}
\begin{figure}\centering
<<plot1,fig=T,eps=F,echo=F,width=5.5,height=4.7>>=
<<plot1c>>
@ 
\caption{Visualization of the simulated data}
\label{fig:grf1}
\end{figure}

\section{Maximum likelihood estimation}

In this section we get the maximum likelihood 
estimation of the parameters of the model used to 
simulate the data on the previous section. 
We know that is adequate the use of the partial 
derivatives with respect to each parameter and 
the Fisher information matrix to use the Fisher 
scoring algorithm. 
Under Gaussian likelihood we have that the 
mean and variance are independently. 
So, taking the derivative with respect to $\beta$ 
we get 
\[ (\bF^{'}\Sigma^{-1}\bF)\hat{\beta} = \bF^{'}\bF \]
So, we want to write a likelihood function as a function 
of the unknown parameters and the data. 
For the others parameters we naively use one of 
the quasi-Newton methods, without using derivatives. 

There are another details to a good performance on 
the maximum likelihood estimation. One is to write 
the variance parameters, $\sigma^2_e$ and $\sigma^2_x$, 
in terms of the relative one. Such details are on 
the \textit{Model Based Geostatistics} book, 
\cite{diggleribeiro:2007}, and on the \pkg{geoR} 
functions documentations. 

Here we just write the negative of the multivariate 
normal density, considering the mean as a regression 
with identity link and the covariance with Mat\'ern 
covariance plus the nugget effect. 
In the function implemented bellow, we have the 
also that the matrix of distances 
between the points because are one of the arguments, 
because it is not necessary to recalculate 
at each interaction of the minimization algorithm. 
We use the negative of the logarithm of the likelihood 
function because, by default, the algorithm 
find the minimum of a function. 
In the computation of the likelihood, we use the Cholesky 
factorization to compute the determinant and also the inverse 
of the covariance matrix. 
The implemented function is a function of the 
four length parameters vector ($\sigma_e^2$, 
$\sigma_x^2$, $\kappa$ and $\nu$), the covariate (design) 
matrix, the data and the matrix of distances:
<<lik1>>=
nllf <- function(pars, ff, data, m) {
  m <- 2^(1-pars[4])*(pars[3]*m)^pars[4]*
    besselK(m*pars[3],pars[4])/gamma(pars[4])
  diag(m) <- 1;   m <- pars[1]*diag(length(data)) + pars[2]*m
  m <- chol(m);   ldet <- sum(log(diag(m)));  m <- chol2inv(m)
  beta <- solve(crossprod(ff, m)%*%ff, crossprod(ff, m)%*%data) 
  z <- data-ff%*%beta;   ss <- drop(crossprod(z,m)%*%z) 
  return(ldet + (nrow(m)*log(2*pi) + ss)/2)
}
@ 
the first argument of this function is the vector of the five 
parameters of the model, such as $\beta_0$, $\sigma^2_e$, 
$\sigma^2_s$, $\kappa$ and $\nu$. 

For test, we calculates the likelihood at true values of the 
parameters and at another set of the values
<<nlltest>>=
c(nllf(c(sigma2e, sigma2x, kappa, nu), matrix(1,n), y1, as.matrix(dmat)), 
  nllf(c(0, sigma2x, kappa, nu), matrix(1,n), y1, as.matrix(dmat)))
@ 
We get the maximum likelihood estimates with 'L-BFGS-B' 
method implemented on \code{optim()} function. 
Also, using \code{hessian=TRUE}, we got the approximate 
Hessian matrix to use in asymptotic inference. 
We got the maximum likelihood estimates
<<llfit1>>=
(ores <- optim(c(sigma2e, sigma2x, kappa, nu), nllf, hessian=TRUE, 
               ff=matrix(1,n), data=y1, m=as.matrix(dmat), 
               method='L-BFGS-B', lower=rep(1e-5,4)))$par
@ 
and the squared root of the hessian diagonal 
<<diaghess>>=
(se <- sqrt(diag(solve(ores$hessian))))
@ 

This naive solution by likelihood is to show how it works. 
But, in the \pkg{geoR} package, we have functions to get simulations 
and to do estimation. The difference is that the \pkg{geoR} 
package uses $\phi=1/kappa$ for the scale parameter and 
it calls kappa for the smoothness parameter.
The \code{grf()} function can be used to get samples of the 
geostatistical model from many correlation 
functions. To get exactly the same data, we use 
<<grf1>>=
require(geoR);   set.seed(234)
grf1 <- grf(grid=pts, cov.pars=c(sigma2x, 1/kappa), mean=beta0,
            nugget=sigma2e, kappa=nu, messages=FALSE) 
@ 

Also, we have the \code{likfit()} function to perform the 
maximum likelihood estimation. With this function we 
also got the maximum likelihood estimates for the 
smoothness parameter by
<<withgeoR>>=
(g1res <- likfit(grf1, ini=c(sigma2x, 1/kappa), messages=FALSE,
                 nugget=sigma2e, kappa=nu, fix.kappa=FALSE))
@ 
In the \code{geoR} parametrization, 
the $\sigma_e^2$ is called \code{tausq}, $1/\kappa$ is 
called \code{phi} and the smoothness parameter $\nu$ 
is called \code{kappa}. 

But, for comparison with INLA results, we fix the 
smoothness parameter $\nu$ on the true value used to simulate 
the data, and find the maximum likelihood estimates to 
another parameters by
<<geoRtoy-l>>=
(fit.l <- likfit(grf1, ini.cov.pars=c(sigma2x, 1/kappa), 
                 nugget=sigma2e, kappa=1, messages=FALSE))
@ 
Notice that we also estimate the mean parameter $\beta$, 
the parameter of fixed effect part of the model. 
Also, we note that the likelihood has similar value, 
just because the estimated value of $\nu$ is very 
close to the fixed value. 

