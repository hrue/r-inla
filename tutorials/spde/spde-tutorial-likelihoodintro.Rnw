\input{spde-tutorial-introduction} 

\section{Simulation of a data set} 

\SweaveOpts{prefix.string=figs/lik}
<<echo=F,results=hide>>=
options(width=75, prompt = " ", continue = "   ")
@ 

First we took a look at the model %%and fitting process 
from parametrization used in a commonly software 
used to analyse the point refereed data 
in \pkg{R}, the \pkg{geoR} package, \cite{geoR}. 
In this section we show how we simulate a dataset 
with this parametrization. 

We remember here that one realization of 
a GF is just one realization of a 
multivariate Gaussian distribution with 
an appropriate covariance matrix. 
To specify these matrix, we need a set 
of locations and the matrix of distance 
between each point with all others. 
Based on this matrix $n\times n$ of distances, 
we compute the covariance matrix and 
do one simulation of a multivariate 
Gaussian distribution. 

Suppose that we have a set of $n=100$ locations, 
on a square with area one with bottom left and 
top right limits: (0,0) and (1,1). 
We choose these locations with density in 
left bottom corner higher than top right corner. 
The \pkg{R} code to do it is:
<<rpts>>=
n <- 200;  set.seed(123) 
pts <- cbind(s1=sample(1:n/n-0.5/n)^2, s2=sample(1:n/n-0.5/n)^2)
@ 
and for get the (lower triangle) matrix of distances we do
<<distpts>>=
dmat <- dist(pts)
@ 
and for the Mat\'ern covariance we need the 
parameters: $\sigma^2_x$, $\kappa$ and $\nu$. 
Additionally, we need the mean $\beta_0$  and 
the nugget parameter $\sigma^2_e$. 
We declare an values to such parameters by
<<params>>=
beta0 <- 10; sigma2e <- 0.3; sigma2x <- 5; kappa <- 7; nu <- 1
@ 

We, first, consider $y$ as mean $\beta_0$ and 
that covariance $\sigma^2_eI + \Sigma$. 
And, we get the covariance by
<<covMatm>>=
mcor <- as.matrix(2^(1-nu)*(kappa*dmat)^nu*
                  besselK(dmat*kappa,nu)/gamma(nu))
diag(mcor) <- 1;   mcov <- sigma2e*diag(n) + sigma2x*mcor
@ 

Now we going to simulate one realization of a 
geostatistical model. 
First, we do the simulation of one realization 
of the multivariate Gaussian distribution. 
Here we remember that if we want to get 
$y\sim N(\mu, \Sigma)$ from $z\sim N(0, I)$, we do 
$y = \mu + zL$, where $L$ is a matrix that $L^{T}L=\Sigma$. 
So, we use the Cholesky factorization of the 
covariance matrix, because if $L$ is the Cholesky 
of the $\Sigma$, so $L^{T}L=\Sigma$.
In \pkg{R} we use:
<<chol1mvnorm>>=
L <- chol(mcov);   set.seed(234);   y1 <- beta0 + drop(rnorm(n)%*%L)
@ 

We show this simulated data in a graph of the locations 
with size of points proportional of the simulated values
on Figure~\ref{fig:grf1} with code below
<<plot1c,eval=F>>=
par(mar=c(3,3,1,1), mgp=c(1.7, 0.7, 0), las=1)
plot(pts, asp=1, xlim=c(0,1.2), cex=y1/10)
q <- quantile(y1, 0:5/5)
legend('topright', format(q, dig=2), pch=1, pt.cex=q/10)
@ 
\setkeys{Gin}{width=0.5\textwidth}
\begin{figure}\centering
<<plot1,fig=T,eps=F,echo=F,width=5.5,height=4.7>>=
<<plot1c>>
@ 
\caption{Visualization of the simulated data}
\label{fig:grf1}
\end{figure}

\section{Maximum likelihood estimation}

In this section we get the maximum likelihood 
estimation of the parameters of the model used to 
simulate the data on the previous section. 
We know that is adequate the use of the partial 
derivatives with respect to each parameter and 
the Fisher information matrix to use the Fisher 
scoring algorithm. 
Also, we can have closed expressions for some 
parameters. 

To get good performance on the maximum likelihood estimation, 
we can write the variance parameter of the noise, 
$\sigma^2_e$, in terms of the relative one, 
$r=\sigma_e^2/\sigma_x^2$, such that 
\[
Cov(\bby) = \sigma^2_x(r\bI + \bC )
\]
where $\bC$ is the correlation matrix. 

Under Gaussian likelihood we have that the 
mean and variance are independently. 
Taking the derivative with respect to $\beta$ 
we get 
\[ (\bF^{'}\bW\bF)\hat{\beta} = \bF^{'}\bW\bby \]
where $\bW = (r\bI + \bC )^{-1}$. 
With this parametrization we can derive 
with respect to $\sigma_x^2$ and have 
\[
\hat{\sigma}_x^2 = (y_i-\bF\hat{\beta})^{'}\bW(y_i-\bF\hat{\beta})/n\;.
\]

Now, we can work with a concentrated log-likelihood, 
that is a function of the noise relative variance $r$, 
the scale $\kappa$ and the smoothness parameter $\nu$ 
\[
-\frac{1}{2}(|\bW| + n(\log(2\pi\hat{\sigma}_x^2)+1))
\]

We use the quasi-Newton methods to find the 
maximum likelihood estimates of these three parameters. 

The likelihood function is just the the multivariate 
normal density, considering the mean as a regression 
with identity link and the covariance with Mat\'ern 
covariance plus the nugget effect. 
In the implemented function (bellow), we have the 
also that the matrix of distances 
between the points because are one of the arguments, 
because it is not necessary to recalculate 
at each interaction of the minimization algorithm. 

We use the negative of the logarithm of the likelihood 
function because, by default, the algorithm 
find the minimum of a function. 
In the computation of the likelihood, we use the 
Cholesky factorization to compute the determinant 
and also the inverse of the covariance matrix. 
<<lik1>>=
nllf <- function(pars, ff, y, m) {
  m <- 2^(1-pars[3])*(pars[2]*m)^pars[3]*
    besselK(m*pars[2],pars[3])/gamma(pars[3])
  diag(m) <- 1 + pars[1] 
  m <- chol(m) 
  ldet.5 <- sum(log(diag(m))) 
  m <- chol2inv(m)
  beta <- solve(crossprod(ff, m)%*%ff, 
                crossprod(ff, m)%*%y) 
  z <- y-ff%*%beta   
  s2x.hat <- mean(crossprod(m,z)*z) 
  res <- ldet.5 + nrow(m)*(1+log(2*pi*s2x.hat))/2
  attr(res, 'param') <- ### to return the parameters together
      c(beta=beta, s2e=pars[1]*s2x.hat, 
        s2x=s2x.hat, kappa=pars[2], nu=pars[3])
  return(res)
}
@ 
The implemented function is a function of the 
three length parameters vector ($r$,
$\kappa$ and $\nu$), the covariate (design) 
matrix, the data and the matrix of distances:

For test, we calculates the likelihood at true values of the 
parameters 
<<nlltest>>=
(nllf(c(sigma2e/sigma2x, kappa, nu), matrix(1,n), y1, as.matrix(dmat)))
@ 
and at another set of the values
<<nlltest2>>=
(nllf(c(0, kappa, nu), matrix(1,n), y1, as.matrix(dmat)))
@ 

We get the maximum likelihood estimates with 'L-BFGS-B' 
method implemented on \code{optim()} function. 
The maximum likelihood estimates for $r$, 
$\kappa$ and $\nu$ are
<<llfit1>>=
(ores <- optim(c(sigma2e/sigma2x, kappa, nu), nllf, hessian=TRUE, 
               ff=matrix(1,n), y=y1, m=as.matrix(dmat), 
               method='L-BFGS-B', lower=rep(1e-5,3)))$par
@ 
and we got all the estimated parameters just 
evaluating our concentrated log-likelihood again 
to get all estimatives 
<<diaghess>>=
(lkhat <- attr(nllf(ores$par, matrix(1,n), 
                    y1, as.matrix(dmat)), 'param'))
@ 

This solution by likelihood is to show how it works. 
In the \pkg{geoR} package, we have functions to do
simulations and also to perform likelihood estimation. 
The difference is that the \pkg{geoR} 
package uses $\phi=1/\kappa$ for the scale parameter and 
it calls kappa for the smoothness parameter. 
Also  $\sigma_e^2$ is called \code{tausq}

The \code{grf()} function can be used to get samples of the 
geostatistical model from many correlation 
functions. To get exactly the same data, we use 
<<grf1>>=
require(geoR);   set.seed(234)
grf1 <- grf(grid=pts, cov.pars=c(sigma2x, 1/kappa), mean=beta0,
            nugget=sigma2e, kappa=nu, messages=FALSE) 
@ 

Also, we have the \code{likfit()} function to perform the 
maximum likelihood estimation. With this function we 
also got the maximum likelihood estimates for the 
smoothness parameter by
<<withgeoR>>=
(g1res <- likfit(grf1, ini=c(sigma2x, 1/kappa), messages=FALSE,
                 nugget=sigma2e, kappa=nu, fix.kappa=FALSE))
@ 

If we fix the smoothness parameter $\nu$ on the value, 
we find the maximum likelihood estimates to 
another parameters by
<<geoRtoy-l>>=
(fit.l <- likfit(grf1, ini.cov.pars=c(sigma2x, 1/kappa), 
                 nugget=sigma2e, kappa=1, messages=FALSE))
@ 
Notice that likelihood here has similar value than previous, 
just because the previously estimated value of $\nu$ is  
close to the fixed value here. 

