\section{Space-time coregionalization model}\label{sec:stcoreg} 

This content is part of the book available at
\url{http://www.r-inla.org/spde-book},
whose Gitbook version is freely available
along all the code and datasets.

<<sett,echo=F,results='hide'>>=
library(knitr)
opts_chunk$set(
fig.path='figs/stcoreg'
)
options(width=77, prompt = " ", continue = "   ")
library(INLA)
lcall <- inla.getOption('inla.call')
## inla.setOption(inla.call='remote')
## inla.setOption(num.threads=4)
source('R/spde-tutorial-functions.R')
set.seed(1)
@ 

In this Chapter we present a way to fit a 
spacetime version of the  
Bayesian spatial coregionalization model proposed by 
\cite{schmidtG:2003}. 
Because we do the modeling with SPDE 
that consider the model on a mesh and it can be 
considered projections for other points in the 
spacetime domain. 
This is an important point as we can have the outcomes 
measured at different points in space and time. 
The only need is to have the data in the same spacetime domain. 

WARNING: a crude mesh and empirical Bayes is used 
in order to run this example in a short time. 

\subsection{The model and parametrization} 

The case of three outcomes is defined considering the following equations 
\[ 
y_1(s,t) = \alpha_1 + z_1(s,t) + e_1(s,t) 
\]
\[
y_2(s,t) = \alpha_2 + \lambda_1 y_1(s,t) + z_2(s,t) + e_2(s,t) 
\]
\[
y_3(s,t) = \alpha_3 + \lambda_2 y_1(s,t) + \lambda_3 y_2(s,t) + z_3(s,t) + e_3(s,t) 
\] 
where the $z_{k}(s,t)$ are spacetime correlated processes and 
$e_{k}(s,t)$ are uncorrelated error terms, $k=1,2,3$. 

In order to fit this model in \texttt{R-INLA} we consider a 
reparametrization. 
This reparametrization is to change the second equation as follows 
\begin{eqnarray} 
y_2(s,t) & = & \alpha_2 + \lambda_1[\alpha_1 + z_1(s,t) + e_1(z,t)] + z_2(s,t) + e_2(s,t) \nonumber \\
  & = & (\alpha_2 + \lambda_1\alpha_1) + 
        \lambda_1 [z_1(s,t) + e_1(s,t)] + 
        z_2(s,t) + e_2(s,t) \nonumber 
\end{eqnarray}
and the third equation as follows 
\begin{eqnarray}
y_3(s,t) & = & \alpha_3 + \lambda_2(\alpha_2 + \lambda_1\alpha_1) + 
               \lambda_2\lambda_1[z_1(s,t) + e_1(s,t)] + 
               \lambda_3\{\alpha_2 + \lambda_1\alpha_1 + 
               \lambda_1[z_1(s,t) + e_1(s,t)] + 
               z_2(s,t) + e_2(s,t) \} + z_3(s,t)  \nonumber \\
  & = & [\alpha_3 + \lambda_2\alpha_1 + 
        \lambda_3(\alpha_2 + \lambda_1\alpha_1)] + \\
  &  & (\lambda_2 + \lambda_3\lambda_1)[z_1(s,t) + e_1(s,t)] + 
       \lambda_3[z_2(s,t) + e_2(s,t)] + z_3(s,t) + e_3(s,t) \nonumber 
\end{eqnarray}
We have then two new intercepts 
$\alpha_2^{*}=\alpha_2 + \lambda_1\alpha_1$ and 
$\alpha_3^{*}=\alpha_3 + \lambda_2(\alpha_2 + \lambda_1\lambda_1) + \lambda_3(\alpha_2 + \lambda_1\alpha_1)$. 
We also have one new regression coeffiecient 
$\lambda_2^{*}=\lambda_2 + \lambda_3\lambda_1$. 

This model can be fitted in \texttt{R-INLA} using the copy feature. 
In the parametrization above it is needed to copy the linear predictor 
in the first equation to the second and the linear predictor in the 
second equation to the third. 

We will use the copy feature to fit $\lambda_1=\beta_1$. 
In the second equation and $\lambda_2 + \lambda_3\lambda_1 = \beta_2$ will be the first copy parameter in the third equation. 
A second copy will be used in the third equation to fit $\lambda_3=\beta_3$. 

\subsection{Data simulation}

Parameter setting 
<<param>>=
alpha <- c(-5, 3, 10) ### intercept on reparametrized model
m.var <- (3:5)/10 ### random field marginal variances
kappa <- c(12, 10, 7) ### GRF scales: inverse range parameters
beta <- c(.7, .5, -.5) ### copy par.: reparam. coregionalization par.
rho <- c(.7, .8, .9) ### temporal correlations
n <- 300;  k <- 9  ### number of spatial locations and time points
@ 

When working with SPDE models 
is not required for the spatial locations to be the same for each 
process to fit this model in \texttt{R-INLA}, 
as shown in the Chapter~8 of \cite{blangiardoC:2015} 
and in the measurement error example in Section~\ref{sec:me}. 
As we define the model over a set of time knots 
to fit a spacetime continuous random field, 
it is also not required for the spacetime coordinates from each 
outcome to be the same. 
However, to simplify the code, we just use the same 
spatial locations and the same time points for all three processes. 
<<sloc>>=
loc <- cbind(runif(n), runif(n)) 
@ 

We can use the \texttt{rMatern()} 
function defined in the section~\ref{sec:simulatoy}
to simulate independent random field realizations for each time.  
This function is available in the file at 
\url{http://inla.r-inla-download.org/r-inla.org/tutorials/spde/R/spde-tutorial-functions.R}
<<rfs,results='hide'>>=
x1 <- rMatern(k, loc, kappa[1], m.var[1])
x2 <- rMatern(k, loc, kappa[2], m.var[2])
x3 <- rMatern(k, loc, kappa[3], m.var[3])
@ 

The time evolution will follows an autoregressive first order process 
as we used in Chapter~\ref{ch:spacetime}. 
<<st>>=
z1 <- x1; z2 <- x2; z3 <- x3
for (j in 2:k) {
    z1[, j] <- rho[1] * z1[,j-1] + sqrt(1-rho[1]^2) * x1[,j]
    z2[, j] <- rho[2] * z2[,j-1] + sqrt(1-rho[2]^2) * x2[,j]
    z3[, j] <- rho[3] * z3[,j-1] + sqrt(1-rho[3]^2) * x3[,j]
}   
@ 
The term $\sqrt{(1-\rho^2)}$ is because we are sampling from the 
stationary distribution, and is in accord to the 
first order autoregressive process parametrization implemented in \texttt{R-INLA}. 

Then we define the observation samples 
<<yyy>>=
e.sd <- c(0.3, 0.2, 0.15)
y1 <- alpha[1] + z1 + rnorm(n, 0, e.sd[1])
y2 <- alpha[2] + beta[1] * z1 + z2 + rnorm(n, 0, e.sd[2])
y3 <- alpha[3] + beta[2] * z1 + beta[3] * z2 + z3 + 
    rnorm(n, 0, e.sd[3])
@ 

\subsection{Model fitting}

Build the mesh to use in the fitting process 
(this is a crude mesh used here for short computational time pourpose)
<<mesh>>=
mesh <- inla.mesh.2d(loc, max.edge=0.2, 
                     offset=0.1, cutoff=0.1)
@ 
<<eval=F,echo=F,results='hide'>>=
mesh$n
plot(mesh, asp=1)
points(loc, pch=19)
@ 

Defining the SPDE model considering the PC-prior 
derived in \cite{fuglstadetal:2017} for the 
model parameters as the practical range, $\sqrt{8\nu}/\kappa$, 
and the marginal standard deviation.  
<<spde>>=
spde <- inla.spde2.pcmatern(
    mesh=mesh, alpha=2, ### mesh and smoothness parameter
    prior.range=c(0.05, 0.01), ### P(practic.range<0.05)=0.01
    prior.sigma=c(1, 0.01)) ### P(sigma>1)=0.01
@ 

Defining all the index set for the space-time fields 
and the for the copies. 
As we have the same mesh, they are the same. 
<<idx>>=
s1 = s2 = s3 = s12 = s13 = s23 = rep(1:spde$n.spde, times=k)
g1 = g2 = g3 = g12 = g13 = g23 = rep(1:k, each=spde$n.spde)
@ 

Prior for $\rho_j$ is chosen as the Penalized Complexity prior, \cite{simpsonetal:2017}
<<pbeta>>=
rho1p <- list(theta=list(prior='pccor1', param=c(0, 0.9))) 
ctr.g <- list(model='ar1', hyper=rho1p)
@ 
Ther prior chosen above consider $P(\rho>0)=0.9$.

Priors for each of the the copy parameters $N(0, 10)$
%%as unit variance Gaussian centered at the values used to do the simulation, which are informative priors:
<<pcopy>>=
hc3 <- hc2 <- hc1 <- list(theta=list(prior='normal', param=c(0,10)))
@ 

Define the formula including all the terms in the model. 
<<form>>=
form <- y ~ 0 + intercept1 + intercept2 + intercept3 + 
  f(s1, model=spde, ngroup=k, group=g1, control.group=ctr.g) + 
  f(s2, model=spde, ngroup=k, group=g2, control.group=ctr.g) + 
  f(s3, model=spde, ngroup=k, group=g3, control.group=ctr.g) + 
  f(s12, copy="s1", group=g12, fixed=FALSE, hyper=hc1) + 
  f(s13, copy="s1", group=g13, fixed=FALSE, hyper=hc2) + 
  f(s23, copy="s2", group=g23, fixed=FALSE, hyper=hc3) 
@ 

Define the projector matrix 
(all they are equal in this example, but it can be different)
<<stlokA>>=
stloc <- kronecker(matrix(1,k,1), loc) ### rep. coordinates each time
A <- inla.spde.make.A(mesh, stloc, n.group=k, group=rep(1:k, each=n))
@ 

Organize the data in three data stack and join it
<<stack>>=
stack1 <- inla.stack(
  data=list(y=cbind(as.vector(y1), NA, NA)), A=list(A), 
  effects=list(list(intercept1=1, s1=s1, g1=g1))) 
stack2 <- inla.stack(
  data=list(y=cbind(NA, as.vector(y2), NA)), A=list(A), 
  effects=list(list(intercept2=1, s2=s2, g2=g2, 
                    s12=s12, g12=g12))) 
stack3 <- inla.stack(
  data=list(y=cbind(NA, NA, as.vector(y3))), A=list(A), 
  effects=list(list(intercept3=1, s3=s3, g3=g3, 
                    s13=s13, g13=g13, s23=s23, g23=g23))) 
stack <- inla.stack(stack1, stack2, stack3) 
@ 

We consider a penalized complexity prior for 
the errors precision, \cite{simpsonetal:2017}, 
<<fixnugget>>=
eprec <- list(hyper=list(theta=list(prior='pc.prec', 
                                    param=c(1, 0.01))))
@ 

We have 15 hyperparameters in the model. 
To make the optimization process fast, we use the parameter 
values used in the simulation as the initial values
<<initheta>>=
theta.ini <- c(log(1/e.sd^2), 
               c(log(sqrt(8)/kappa), log(sqrt(m.var)), 
                 qlogis(rho))[c(1,4,7, 2,5,8, 3,6,9)], beta)
@ 

With 15 hyperparameters in the model and the 
CCD strategy will use 287 integration points to compute 
$$\pi(x_i|y) = \int \pi(y|x)\pi(x|\theta)\pi(\theta)d\theta $$ 
We avoid it using the Empirical Bayes, 
setting \texttt{int.strategy='eb'} and these 
marginals will consider only the 
modal configuration for $\theta$. 

<<result,results='hide'>>=
(result <- inla(form, rep('gaussian', 3), data=inla.stack.data(stack), 
                control.family=list(eprec, eprec, eprec), 
                control.mode=list(theta=theta.ini, restart=TRUE),
                control.inla=list(int.strategy='eb'), 
                control.predictor=list(A=inla.stack.A(stack))))$cpu
@ 
<<cpu,echo=FALSE>>=
result$cpu
@ 
<<mode>>=
result$logfile[grep('Number of function evaluations', result$logfile)] 
round(result$mode$theta, 2) 
@ 

Summary of the posterior marginal density for the intercepts 
<<intercepts>>=
round(cbind(true=alpha, result$summary.fix), 2) 
@ 

Posterior marginal for the errors precision
<<prec>>=
round(cbind(true=c(e=e.sd^-2), result$summary.hy[1:3, ]), 4)
@ 

Summary of the posterior marginal density for the temporal correlations:
<<rho>>=
round(cbind(true=rho, result$summary.hy[c(6,9,12),]), 4) 
@ 

Summary of the posterior marginal density for the copy parameters:
<<fixed>>=
round(cbind(true=beta, result$summary.hy[13:15,]), 4)
@ 

Look for the random field parameters for each field. 
The practical range for each random field
<<range>>=
round(cbind(true=sqrt(8)/kappa, result$summary.hy[c(4, 7, 10),]), 3)
@ 
The standard deviation for each random field
<<rfvar>>=
round(cbind(true=m.var^0.5, result$summary.hy[c(5, 8, 11),]), 3)
@ 

The posterior mean for each random field is projected to 
the observation locations and shown against the 
simulated correspondent fields in Figure~\ref{fig:stzfit} 
with the code bellow. 
<<stzfit,eval=FALSE>>=
par(mfrow=c(1,3), mar=c(2,2,0.5,0.5), mgp=c(1.5,0.5,0))
plot(drop(A%*%result$summary.ran$s1$mean), as.vector(z1),
     xlab='', ylab='', asp=1); abline(0:1)
plot(drop(A%*%result$summary.ran$s2$mean), as.vector(z2),
     xlab='', ylab='', asp=1); abline(0:1)
plot(drop(A%*%result$summary.ran$s3$mean), as.vector(z3),
     xlab='', ylab='', asp=1); abline(0:1)
@ 
\begin{figure}\centering
<<stzfitplot,echo=FALSE,fig.width=15,heigh=3,out.width='0.97\\textwidth'>>=
<<stzfit>> 
@ 
\caption{True and fitted random field values.}
\end{figure}\label{fig:stzfit}

Remember that the crude approximation for the 
covariance and the simplifications on the inference 
procedure is not recommended to use in practice. 
It can be considered for having initial results.  
Even thou, it seems that the method was reazonable 
well having covered the parameter values used to 
simulate the data. 
