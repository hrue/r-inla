\section{Coregionalization model}\label{sec:coreg} 

This content is part of the book available at 
\url{http://www.r-inla.org/spde-book},
whose Gitbook version is freely available 
along all the code and datasets. 


<<sett,echo=F,results='hide',message=FALSE,warning=FALSE>>=
library(knitr)
opts_chunk$set(
fig.path='figs/coreg',
message=FALSE, warning=FALSE
)
options(width=77, prompt = " ", continue = "   ")
library(INLA)
lcall <- inla.getOption('inla.call')
## inla.setOption(inla.call='remote')
## inla.setOption(num.threads=4)
source('R/spde-tutorial-functions.R')
set.seed(1)
@ 

In this Chapter we present a way to fit the 
Bayesian coregionalization model proposed by 
\cite{schmidtG:2003}. 
A particular case was considered as a 
covariate joint modeling in Chapter 8 of \cite{blangiardoC:2015}. 
Later in this tutorial we do consider a generalization 
for the space-time case, see Section~\ref{sec:stcoreg}. 
Also, the approach implemented in \texttt{R-INLA} 
allows completelly missalignment for all the outcomes, 
it only need the same domain. 

\subsection{The model and parametrization} 

The case of three outcomes is defined considering the following equations 
\[ 
y_1(s) = \alpha_1 + z_1(s) + e_1(s) 
\]
\[
y_2(s) = \alpha_2 + \lambda_1 y_1(s) + z_2(s) + e_2(s) 
\]
\[
y_3(s) = \alpha_3 + \lambda_2 y_1(s) + \lambda_3 y_2(s) + z_3(s) + e_3(s) 
\]
where the $z_{k}(s)$ are spacetime correlated processes and 
$e_{k}(s)$ are uncorrelated error terms, $k=1,2,3$. 

In order to fit this model in \texttt{R-INLA} we consider a 
reparametrization. 
This reparametrization is to change the second equation as follows 
\begin{eqnarray} 
y_2(s) & = & \alpha_2 + \lambda_1[\alpha_1 + z_1(s) + e_1(z)] + z_2(s) + e_2(s) \nonumber \\
  & = & (\alpha_2 + \lambda_1\alpha_1) + 
        \lambda_1 [z_1(s) + e_1(s)] + 
        z_2(s) + e_2(s) \nonumber 
\end{eqnarray}
and the third equation as follows 
\begin{eqnarray}
y_3(s) & = & \alpha_3 + \lambda_2(\alpha_2 + \lambda_1\alpha_1) + 
               \lambda_2\lambda_1[z_1(s) + e_1(s)] + 
               \lambda_3\{\alpha_2 + \lambda_1\alpha_1 + 
               \lambda_1[z_1(s) + e_1(s)] + 
               z_2(s) + e_2(s) \} + z_3(s)  \nonumber \\
  & = & [\alpha_3 + \lambda_2\alpha_1 + 
        \lambda_3(\alpha_2 + \lambda_1\alpha_1)] + \\
  &  & (\lambda_2 + \lambda_3\lambda_1)[z_1(s) + e_1(s)] + 
       \lambda_3[z_2(s) + e_2(s)] + z_3(s) + e_3(s) \nonumber 
\end{eqnarray}
We have then two new intercepts 
$\alpha_2^{*}=\alpha_2 + \lambda_1\alpha_1$ and 
$\alpha_3^{*}=\alpha_3 + \lambda_2(\alpha_2 + \lambda_1\lambda_1) + \lambda_3(\alpha_2 + \lambda_1\alpha_1)$. 
We also have one new regression coeffiecient 
$\lambda_2^{*}=\lambda_2 + \lambda_3\lambda_1$. 

This model can be fitted in \texttt{R-INLA} using the copy feature. 
In the parametrization above it is needed to copy the linear predictor 
in the first equation to the second and the linear predictor in the 
second equation to the third. 

We will use the copy feature to fit $\lambda_1=\beta_1$. 
In the second equation and $\lambda_2 + \lambda_3\lambda_1 = \beta_2$ will be the first copy parameter in the third equation. 
A second copy will be used in the third equation to fit $\lambda_3=\beta_3$. 

\subsection{Data simulation}

Parameter setting 
<<param>>=
alpha <- c(-5, 3, 10) ### intercept on reparametrized model
m.var <- (3:5)/10 ### random field marginal variances
kappa <- c(12, 10, 7) ### GRF scales: inverse range parameters
beta <- c(.7, .5, -.5) ### copy par.: reparam. coregionalization par.
n1 <- 99; n2 <- n1+1; n3 <- n2+1 ### number of spatial locations
@ 

It is not required to the spatial locations to be the same for each 
process to fit this model in \texttt{R-INLA}. 
We will consider a different set of locations for each outcome. 
<<sloc>>=
loc1 <- cbind(runif(n1), runif(n1)) 
loc2 <- cbind(runif(n2), runif(n2)) 
loc3 <- cbind(runif(n3), runif(n3)) 
@ 

We can use the \texttt{rMatern()} function 
to simulate independent random field realizations for each time.  
This function is available in the file at 
\url{http://inla.r-inla-download.org/r-inla.org/tutorials/spde/R/spde-tutorial-functions.R}. 

In order to build the second and third outcomes, 
we do consider samples for the random field in 
the first outcome at all the locations and 
for the random field on the second outcome in 
the second and third set of locations. 
<<rfs,results='hide'>>=
z1 <- rMatern(1, rbind(loc1, loc2, loc3), kappa[1], m.var[1])
z2 <- rMatern(1, rbind(loc2, loc3), kappa[2], m.var[2])
z3 <- rMatern(1, loc3, kappa[3], m.var[3])
@ 

Then we define the observation samples 
<<yyy>>=
e.sd <- c(0.3, 0.2, 0.15)
y1 <- alpha[1] + z1[1:n1] + rnorm(n1, 0, e.sd[1])
y2 <- alpha[2] + beta[1] * z1[n1+1:n2] + z2[1:n2] + 
    rnorm(n2, 0, e.sd[2])
y3 <- alpha[3] + beta[2] * z1[n1+n2+1:n3] + 
    beta[3] * z2[n2+1:n3] + z3 + rnorm(n3, 0, e.sd[3])
@ 

\subsection{Model fitting}

We wil build only one mesh to fit all the 
three spatial random fields. 
This makes easier to link it across different 
outcomes at diferent spatial locations. 
We will use all the locations
<<mesh>>=
mesh <- inla.mesh.2d(rbind(loc1, loc2, loc3), ###loc.domain=locd, 
                     max.edge=c(0.05, 0.2), 
                     offset=c(0.05, 0.3), cutoff=0.01)
@ 
One can also use only the domain to build the mesh. 
However, since the sparsity of the resulting 
total precision matrix also depends on the sparsity of 
the projector matrices, having the points as nodes in the 
mesh will gives a projector matrix a bit sparser.

<<eval=F,echo=F,results='hide'>>=
mesh$n
plot(mesh, asp=1)
points(loc1, pch=15, col=2)
points(loc2, pch=16, col=3)
points(loc3, pch=17, col=4)
@ 

Defining the SPDE model considering the PC-prior 
derived in \cite{fuglstadetal:2017} for the 
model parameters as the practical range, $\sqrt{8\nu}/\kappa$, 
and the marginal standard deviation.  
<<spde>>=
spde <- inla.spde2.pcmatern(
    mesh=mesh, alpha=2, ### mesh and smoothness parameter
    prior.range=c(0.05, 0.01), ### P(practic.range<0.05)=0.01
    prior.sigma=c(1, 0.01)) ### P(sigma>1)=0.01
@ 
This object model can be considered for all the random effects, 
if we do want to consider the same prior for the hyperparameters.

For each of the the copy parameters we have 
a $N(0, 10)$ prior distribution 
<<pcopy>>=
hc3 <- hc2 <- hc1 <- list(theta=list(prior='normal', param=c(0,10)))
@ 

Define the formula including all the terms in the model. 
<<form>>=
form <- y ~ 0 + intercept1 + intercept2 + intercept3 + 
  f(s1, model=spde) + f(s2, model=spde) + f(s3, model=spde) + 
  f(s12, copy="s1", fixed=FALSE, hyper=hc1) + 
  f(s13, copy="s1", fixed=FALSE, hyper=hc2) + 
  f(s23, copy="s2", fixed=FALSE, hyper=hc3) 
@ 

Define the projector matrix for each set of locations 
<<stlokA>>=
A1 <- inla.spde.make.A(mesh, loc1) 
A2 <- inla.spde.make.A(mesh, loc2) 
A3 <- inla.spde.make.A(mesh, loc3) 
@ 

Organize the data in three data stack and join it
<<stack>>=
stack1 <- inla.stack(
  data=list(y=cbind(as.vector(y1), NA, NA)), A=list(A1), 
  effects=list(list(intercept1=1, s1=1:spde$n.spde))) 
stack2 <- inla.stack(
  data=list(y=cbind(NA, as.vector(y2), NA)), A=list(A2), 
  effects=list(list(intercept2=1, s2=1:spde$n.spde, 
                    s12=1:spde$n.spde)))
stack3 <- inla.stack(
  data=list(y=cbind(NA, NA, as.vector(y3))), A=list(A3), 
  effects=list(list(intercept3=1, s3=1:spde$n.spde, 
                    s13=1:spde$n.spde, 
                    s23=1:spde$n.spde)))
stack <- inla.stack(stack1, stack2, stack3) 
@ 

We consider a penalized complexity prior for 
the errors precision, \cite{simpsonetal:2017}, 
<<fixnugget>>=
eprec <- list(hyper=list(theta=list(prior='pc.prec', 
                                    param=c(1, 0.01))))
@ 

We have two hyperparameters for each spatial effect, 
one for each likelihood and three copy parameters, 
which is also considered as hyperparametes. 
That is 12 hyperparameters in total. 
To make the optimization process fast, we use the parameter 
values used in the simulation as the initial values
<<initheta>>=
theta.ini <- c(log(1/e.sd^2), 
               c(log(sqrt(8)/kappa), log(sqrt(m.var)) 
                 )[c(1,4, 2,5, 3,6)], beta)
@ 

We will consider the empirical Bayes approach instead 
of integrating over the hyperparameters. 
It is just to avoind to do computations over the 
281 configurations of the hyperparameters in the CCD 
integration strategy. 
It will saves a bit less of one minute in computational time 
when using 6 threads. Fitting the model 
<<result,results='hide'>>=
(result <- inla(form, rep('gaussian', 3), 
                data=inla.stack.data(stack), 
                control.family=list(eprec, eprec, eprec), 
                control.predictor=list(A=inla.stack.A(stack)),
                control.mode=list(theta=theta.ini, restart=TRUE),
                control.inla=list(int.strategy='eb')))$cpu
@ 
<<cpu,echo=FALSE>>=
result$cpu
@ 
<<mode>>=
result$logfile[grep('Number of function evaluations', result$logfile)] 
round(result$mode$theta, 2) 
@ 

Summary of the posterior marginal density for the intercepts 
<<intercepts>>=
round(cbind(true=alpha, result$summary.fix), 2) 
@ 

Posterior marginal for the errors precision
<<prec>>=
round(cbind(true=c(e=e.sd^-2), result$summary.hy[1:3, ]), 4)
@ 

Summary of the posterior marginal density for the copy parameters:
<<fixed>>=
round(cbind(true=beta, result$summary.hy[10:12,]), 4)
@ 

Look for the random field parameters for each field. 
The practical range for each random field
<<range>>=
round(cbind(true=sqrt(8)/kappa, result$summary.hy[c(4,6,8),]), 3)
@ 
The standard deviation for each random field
<<rfvar>>=
round(cbind(true=m.var^0.5, result$summary.hy[c(5,7,9),]), 3)
@ 

We can plot the posterior mean for each random field 
projected at the data locations. 
We can see it in Figure~\ref{fig:zfit}. 
It seems that the method was reazonable 
well having covered the parameter values used to 
simulate the data. 

<<zfit,eval=FALSE>>=
par(mfrow=c(2,3), mar=c(2.5,2.5,1.5,0.5), mgp=c(1.5,0.5,0))
plot(drop(A1%*%result$summary.ran$s1$mean), z1[1:n1],
     xlab='Posterior mean', ylab='Simulated', 
     asp=1, main='z1 in y1'); abline(0:1)
plot(drop(A2%*%result$summary.ran$s1$mean), z1[n1+1:n2],
     xlab='Posterior mean', ylab='Simulated', 
     asp=1, main='z1 in y2'); abline(0:1)
plot(drop(A3%*%result$summary.ran$s1$mean), z1[n1+n2+1:n3],
     xlab='Posterior mean', ylab='Simulated', 
     asp=1, main='z1 in y3'); abline(0:1)
plot(drop(A2%*%result$summary.ran$s2$mean), z2[1:n2],
     xlab='Posterior mean', ylab='Simulated', 
     asp=1, main='z2 in y2'); abline(0:1)
plot(drop(A3%*%result$summary.ran$s2$mean), z2[n2+1:n3],
     xlab='Posterior mean', ylab='Simulated', 
     asp=1, main='z2 in y3'); abline(0:1)
plot(drop(A3%*%result$summary.ran$s3$mean), z3[1:n3],
     xlab='Posterior mean', ylab='Simulated', 
     asp=1, main='z3 in y3'); abline(0:1)
@ 
\begin{figure}\centering
<<zfitplot,echo=FALSE,fig.width=10,heigh=4,out.width='0.9\\textwidth'>>=
<<zfit>> 
@ 
\caption{Simulated and posterior mean fitted 
  for the random fields.}
\end{figure}\label{fig:zfit}

