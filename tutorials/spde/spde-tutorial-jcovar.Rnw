\chapter{Joint covariate modeling with misalignment}

<<sett,echo=F,results=hide>>=
options(width=75)
require(INLA)
inla.setOption(inla.call='remote')
require(geoR)
@ 

Here we focus on the situation when we have a response 
$y$ and a covariate $c$, but we have misalignment. 
We have $y$ observed at $n_y$ locations and 
$x$ observed at $n_c$ locations. 
In this example, we design a soluction that 
not depends if we have or not some common 
observed locations for $c$ and $y$. 
A restriction is the assumption that $c$ 
have spatial dependency. 

\section{The model}

Taking into acount that $c$ have spatial dependency, 
a simple approach is to define a model for $c$, 
predict it on locations that we have $y$ and build 
the model for $y$. But, in this two stage model, 
we don't take into account the prediction error 
of $c$ on second model. The measurement error models 
is an approach to solve it, \cite{muffetal:2013}. 
But, we want to build a spatial model for $c$, 
and another spatial model for $y$, where the 
estimation process is made jointly. 

We consider the following model for $c$ 
\[
c_i \sim N(\alpha_c + m_i, \sigma_c^2)
\]
where $m_i$ is modeled as a zero mean random field, 
$\alpha_c$ is the marginal mean of $c$ and 
$\sigma_c$ is a measurement error of $c$. 
So, when we predict $c$ at location $s$, 
we have $m(s)$. Because $E(m(s))=0$, 
if we just consider $m(s)$ as covariate 
for $y(s)$, i. e., the centered $c$. 

So, let following model for $y$ 
\[
y_i \sim N(\alpha_y + \beta m_i + x_i, \sigma_y^2)
\]
where $\alpha_y$ is an intercept, $\beta$ is the 
regression coefficient on (centered) $c$, 
$m_i$ is the centered $c$ predicted at location 
of $y_i$, $x_i$ is an zero mean random field 
and $\sigma_y^2$ measures the $y$ errors 
that remain unexplained. 

A particular case is when we don't have 
the $x$ term in the model for $y$. 
Another case, is where we don't have 
white noise in the covariate, i. e., 
the covariate is considered just a 
realization of a random field. 

\subsection{Simulation from the model}

To test the approach on next section, 
we do a simulation from this model. 
First, we set the model parameters. 
<<params>>=
n.y <- 123;         n.c <- 234
alpha.y <- -5;      alpha.c <- 10
sigma2.y <- 0.5;    sigma2.c <- 0.3
beta <- -3
@ 

First, we do the simulation of the locations 
<<simloc>>=
set.seed(1)
loc.c <- cbind(runif(n.c), runif(n.c))
loc.y <- cbind(runif(n.y), runif(n.y))
@ 

Let the parameters of both random fields $m$ and $x$:
<<rfparms>>=
kappa.m <- 7;         sigma2.m <- 3
kappa.x <- 5;         sigma2.x <- 2
@ 
and we use the \code{grf()} function of the \pkg{geoR}, 
\cite{geoR}, package to do the simulation of both random fields. 
We need the simulation of $m$ in both set of locations
<<simula>>=
library(geoR)
set.seed(2)
mm <- grf(grid=rbind(loc.c, loc.y), messages=FALSE, 
          cov.pars=c(sigma2.m, 1/kappa.m), kappa=2)$data
xx <- grf(grid=loc.y, messages=FALSE, 
          cov.pars=c(sigma2.x, 1/kappa.x), kappa=2)$data
@ 
and simulate the covariate and the response with 
<<sim-y>>=
set.seed(3)
cc <- alpha.c + mm + rnorm(n.c+n.y, 0, sqrt(sigma2.c))
yy <- alpha.y + beta*mm[n.c+1:n.y] + xx + 
  rnorm(n.y, 0, sqrt(sigma2.y))
@ 

\section{Fitting the model}

First we make the mesh 
<<mesh>>=
pl01 <- matrix(c(0,1,1,0,0, 0,0,1,1,0), ncol=2)
(mesh <- inla.mesh.create.helper(, pl01, cutoff=.03, 
                                 max.edge=c(.05,.1)))$n
@ 
and use it for both the random fields. 
So, the index set based on the mesh 
are both the same values. So, we extrat 
it from the output of the 
\code{inla.spde.make.index()} function 
<<index>>=
ind <- inla.spde.make.index('i', mesh$n)$i
@ 
for posterior inclusion on the data stack. 

We do simulations of the covariate on the locations 
of the response just to simulate the response. 
But, in the problem that we want to solve in pratice, 
we don't have the covariate on the response locations. 
So, the predictor matrix is different 
for response and covariate. 
Also we need a matrix with zeros to add on 
each of the predictor matrix to associate with 
the NA elements on response matrix defined later 
<<Apred>>=
Ac <- rBind(inla.spde.make.A(mesh, loc=loc.c), 
            Matrix(0, n.y, mesh$n))
Ay <- rBind(Matrix(0, n.c, mesh$n), 
            inla.spde.make.A(mesh, loc=loc.y))
@ 

To predict the covariate jointly, we need 
to model it jointly and we need two likelihoods. 
So, the response is formed by two colums matrix. 
We fill the first lines of first column of this 
matrix with the covariate values and the last 
lines of the second column with the response values. 
All the another positions is filled with NA.

We need an additional carefull in the data management. 
Because we want to estimate the effect of the covariate 
with the copy strategy, we need that the index on 
the both random field math the random field
<<dat>>=
stk <- inla.stack(list(Y=cbind(c(cc[1:n.c], rep(NA,n.y)), 
                         c(rep(NA,n.c), yy))), 
                  A=list(Ac, Ay), tag='dat', 
                  effects=list(data.frame(a.c=1, m=ind), 
                    data.frame(a.y=1, m.y=ind, x=ind)))
@ 

The estimation of the regression coefficient 
in this approach is treated as a hyperparameter, 
such as copy parameter of an latent field. 
In this case, we need to do a good prior specification. 
For example, is possible to know, a priori, the signal. 
We set a $N(-3,5)$ prior to $\beta$. 
Also, we define the formulae for the model. 
<<formula>>=
form <- Y ~  0 + a.c + f(m, model=spde) + 
  a.y + f(x, model=spde) + f(m.y, copy='m', fixed=FALSE, 
               hyper=list(theta=list(param=c(-3,25), initial=0))) 
@ 
define the spde model and fit the model with 
<<fit>>=
spde <- inla.spde2.matern(mesh)
res <- inla(form, data=inla.stack.data(stk), 
            family=rep('gaussian',2), 
            control.predictor=list(compute=TRUE, A=inla.stack.A(stk))) 
@ 

\section{The results}

The true values of the intercepts and 
the summary of the posterior marginals 
<<resfix>>=
round(cbind(True=c(alpha.c, alpha.y), res$summary.fix), 4)
@ 

The true values of the precisions and 
the summary of the posterior marginals 
<<reshyl>>=
round(cbind(True=1/c(Prec.c=sigma2.c, Prec.y=sigma2.y), 
            res$summary.hy[1:2,]), 4)
@ 

The true value of the regression coefficient and 
the summary of the posterior marginal 
<<reshyb>>=
round(c(True=beta, res$summary.hy[7,]), 4)
@ 

The true values for the precision of the both random 
fields and the summary of the posterior marginals 
<<rf>>=
m.rf <- inla.spde2.result(res, 'm', spde)
x.rf <- inla.spde2.result(res, 'x', spde)
round(cbind(True=c(s2m=sigma2.m, s2x=sigma2.x), 
            mean=c(inla.emarginal(function(x) x, 
              m.rf$marginals.variance.n[[1]]), 
              inla.emarginal(function(x) x, 
                             x.rf$marginals.variance.n[[1]])), 
            rbind(inla.hpdmarginal(.95, m.rf$marginals.variance.n[[1]]), 
                  inla.hpdmarginal(.95, x.rf$marginals.variance.n[[1]]))), 4)
@ 

The true values for the scale parameter $\kappa$ 
and the summary of the posterior marginals 
<<kappa>>=
round(cbind(True=c(kappa.m, kappa.x), 
            mean=c(inla.emarginal(function(x) exp(x), res$marginals.hy[[4]]),
              inla.emarginal(function(x) exp(x), res$marginals.hy[[6]]))), 4)
@ 

