\chapter{Non stationary model}

<<opts,echo=F,results=hide>>=
options(width=75)
require(INLA)
require(gridExtra)
lcall <- inla.getOption('inla.call')
@ 

\section{Introduction}

To introduce the non stationarity 
we need to remember the definition 
of the precision matrix of the 
GMRF that defines the RF. 
This matrix is defined on equations 
(\ref{eq:Qalpha}) and (\ref{eq:Qfrac}). 
The non stationarity is made by a 
redefinition of the precision matrix. 

This new definition is 
\begin{equation}\label{eq:Qnst}
  \bQ = \bD^{(0)}(\bD^{(1)}\bM^{(0)}\bD^{(1)} + 
  \bD^{(2)}\bD^{(1)}\bM^{(1)} + (\bM^{(1)})^T\bD^{(1)}\bD^{(2)} + 
  \bM^{(2)})\bD^{(0)} 
\end{equation}
where $\bM^{(0)}$, $\bM^{(1)}$ and $\bM^{(2)}$, 
are provided from the finite element 
method - FEM based on the mesh. 
For $\alpha=1$ ($\nu=0$), we have 
$\bM^{(0)}=\bC$, $(\bM^{(1)})_{ij}=0$ and 
$\bM^{(2)}=\bG$. 
For $\alpha=2$ ($\nu=1$), we have 
$\bM^{(0)}=\bC$, $(\bM^{(1)})_{ij}=\bG$ and 
$\bM^{(2)}=\bG\bC^{-1}\bG$. 

All three $\bD^{(0)}$, $\bD^{(1)}$ and $\bD^{(2)}$ 
are diagonal with elements used to 
describe the non-stationarity. 
The definition of these matrixes are
\begin{align*}
\bD^{(0)} = diag\{\bD^{(0)}_i\} = diag\{e^{{\phi}^{(0)}_i}\} \\
\bD^{(1)} = diag\{\bD^{(1)}_i\} = diag\{e^{{\phi}^{(1)}_i}\} \\
\bD^{(2)} = diag\{\bD^{(2)}_i\} = diag\{{\phi}^{(2)}_i\}
\end{align*}
where 
\begin{equation*}
{\phi}^{(k)}_i = \bB^{(k)}_{i,0} + \sum_{j=1}^p \bB^{(k)}_{i,j} \theta_j, 
\quad i=1,\ldots,n
\end{equation*}
with the $\bB^{(k)}:$ $n$-by-$(p+1)$ 
user defined matrix. 

The default stationary SPDE model uses 
$\bB=[0 1 0]$ (one by three) matrix 
for the marginal variance and uses 
$\bB=[0 0 1]$ (one by three) matrix 
for the scaling parameter $\kappa$. 
In the next section, we add one of the 
location coordinates as a fourth column 
to build a non stationary model. 

\section{Simulation from model}

First, we define a polygon to 
do the simulation. 
We defint an unitary square
<<poly>>=
pl01 <- cbind(c(0,1,1,0,0), c(0,0,1,1,0))
@ 

We want to use the SPDE approach to do 
the simulation. So, we first need to 
build a mesh on the polygon
<<mesh>>=
(mesh <- inla.mesh.create.helper(, pl01, max.edge=c(0.07,.12)))$n
@ 

Now, we define the spde model with 
<<spde>>=
spde <- inla.spde2.matern(mesh, B.tau=cbind(0, 1, 0, mesh$loc[,1]),
                          B.kappa=cbind(0, 0, 1, mesh$loc[,1]),
                          theta.prior.mean=rep(0, 3),
                          theta.prior.prec=rep(1, 3))
@ 

And we going to define the precision 
matrix used to do the simulation. 
Based on the spde model defined, 
we define two different precision matrix, 
just defining two different $\theta$ vectors
<<thetas>>=
theta1 <- c(-1, 2, -1)
theta2 <- c(-1, 2, 1)
@ 
and we have both the precision matrix with
<<Q>>=
Q1 <- inla.spde2.precision(spde, theta=theta1)
Q2 <- inla.spde2.precision(spde, theta=theta2)
@ 
and we have that the second precision matrix 
have larger values, because its values increase 
on the both coordinates locations and for the 
first, decreases. We see below the summary of both 
precision matrix for its diagonal and the 
positive elements out of its diagonal
<<summaryQ>>=
rbind(Q1=summary(diag(Q1)), Q2=summary(diag(Q2)))
rbind(Q1=summary(Q1[Q1>0 & lower.tri(Q1)]), 
      Q2=summary(Q2[Q2>0 & lower.tri(Q2)]))
@ 
This inplies that the variance of the second 
random field is greather than the first one. 

Both precision matrix consider that the 
locations are the triangles vertices of mesh. 
So, the simulation made with it is a realization 
of the random field on each point of the 
triangles vertices of the mesh.
We do the simulation with the sum to zero constrait, 
just to show it. 
We use the same see for each simulation, 
also just to show it. 
<<changecalltolocal,echo=F>>=
inla.setOption(inla.call=lcall)
@ 
<<samples>>=
constr <- list(A=matrix(1,1,mesh$n), e=0)
sample1 <-  as.vector(inla.qsample(1,Q1, constr=constr, seed=1))
sample2 <-  as.vector(inla.qsample(1,Q2, constr=constr, seed=1))
@
<<changecalltoremote,echo=F>>=
inla.setOption(inla.call='remote')
@ 

We compute the standard deviations for both the 
samples considering groups defined in accord to 
the first coordinate of the locations: 
<<ssummary>>=
tapply(sample1, round(inla.group(mesh$loc[,1], 5),3), sd)
tapply(sample2, round(inla.group(mesh$loc[,1], 5),3), sd)
@ 
We observe that the variance of the sample 
from the first random field increase when the 
first coordinate increase and the opposite 
for the sample of the second random field.

We see the simulated values projected 
on a grid on Figure~\ref{fig:s12ns}. 
We use a projector matrix to project the 
simulated values on the grid limited on the 
unit square with limits (0,0) and (1,1) with 
<<plotsamples,eval=F>>=
proj <- inla.mesh.projector(mesh, xlim=0:1, ylim=0:1)
grid.arrange(levelplot(inla.mesh.project(proj,field=sample1), 
                       xlab='', ylab='', scale=list(draw=FALSE),
                       col.regions=topo.colors(100)), 
             levelplot(inla.mesh.project(proj,field=sample2), 
                       xlab='', ylab='', scale=list(draw=FALSE),
                       col.regions=topo.colors(100)), nrow=1)
@ 
\begin{figure}\centering
<<vplotsamples,echo=F,fig=TRUE,eps=F,width=10,heigh=4.5>>=
<<plotsamples>>
@ 
\caption{Two simulated random fields, using two 
  diferent $\theta$ on same basis functions.}
\label{fig:s12ns}
\end{figure}

\section{Estimation with data simulated on the mesh vertices}

The model can be fitted easly with 
the data simulated on mesh vertices. 
Considering that we have data exactly 
on each vertice of the mesh, we don't 
need the use of any predictor matrix 
and the stack functionality. 
Because we have just realizations of the 
random field, we don't have noise 
and need to fix the precision of the 
Gaussian likelihood on higth value, 
for example on the value $e^{20}$
<<likehy>>=
clik <- list(hyper=list(theta=list(initial=20, fixed=TRUE)))
@ 
Remember that we have a zero mean random field, 
so we also don't have fixed parameters to fit. 
We just do 
<<fit12>>=
formula <- y ~ 0 + f(i, model=spde)
fit1 <- inla(formula, control.family=clik, 
             data=data.frame(y=sample1, i=1:mesh$n))
fit2 <- inla(formula, control.family=clik, 
             data=data.frame(y=sample2, i=1:mesh$n))
@ 

We look at the summary of the posterior 
for $\theta$ (joined with the true values). 
For the first sample 
<<hy1summaries>>=
round(cbind(true=theta1, fit1$summary.hy), 4)
@ 
and for the second
<<hy2summaries>>=
round(cbind(true=theta2, fit2$summary.hy), 4)
@ 
We see that for both we have good results. 
In next section we see more results. 

\section{Estimation with locations not on mesh vertices}

Suppose that we have the data on the locations 
simulated by the commands below 
<<>>=
set.seed(2);     n <- 500
loc <- cbind(runif(n), runif(n))
@ 

Now, we project the data simulated 
on the mesh vertices to this locations. 
To do it, we need a projection matrix
<<projloc>>=
projloc <- inla.mesh.projector(mesh, loc)
@ 
with 
<<projectsamples>>=
x1 <- inla.mesh.project(projloc, sample1)
x2 <- inla.mesh.project(projloc, sample2)
@ 
and we have the sample data on these locations.

Now, because the this locations aren't vertices 
of the mesh, we need to use the stack functionality. 
First, we need the predictor matrix. 
But this is the same used to 'sample' the data.

And we define the stack for each one of the samples
<<stacks>>=
stk1 <- inla.stack(list(y=x1), A=list(projloc$proj$A), tag='d',
                  effects=list(data.frame(i=1:mesh$n)))
stk2 <- inla.stack(list(y=x2), A=list(projloc$proj$A), tag='d',
                  effects=list(data.frame(i=1:mesh$n)))
@ 

And we fit the model with
<<fitt>>=
res1 <- inla(formula, data=inla.stack.data(stk1), control.family=clik, 
             control.predictor=list(compute=TRUE, A=inla.stack.A(stk1)))
res2 <- inla(formula, data=inla.stack.data(stk2), control.family=clik, 
             control.predictor=list(compute=TRUE, A=inla.stack.A(stk2)))
@ 

The true and summary of marginal 
posterior distribution for $\theta$:
<<spostth>>=
round(cbind(True=theta1, res1$summary.hy), 4)
round(cbind(True=theta2, res2$summary.hy), 4)
@ 

<<projpostrf>>=
x1.mean <- inla.mesh.project(proj, field=res1$summary.ran$i$mean)
x1.sd <- inla.mesh.project(proj, field=res1$summary.ran$i$sd)
x2.mean <- inla.mesh.project(proj, field=res2$summary.ran$i$mean)
x2.sd <- inla.mesh.project(proj, field=res2$summary.ran$i$sd)
@ 

We visualize, for both random fields, the 
simulated, the predicted (posterior mean) 
and the posterior standard deviation on 
Figure~\ref{fig:visprojp} with commands below 
<<visprojp,eval=F>>=
do.call(function(...) grid.arrange(..., nrow=2), 
        lapply(list(inla.mesh.project(proj, sample1), x1.mean, x1.sd, 
                    inla.mesh.project(proj, sample2), x2.mean, x2.sd), 
               levelplot, xlab='', ylab='', 
               col.regions=topo.colors(100), scale=list(draw=FALSE)))
@ 
\begin{figure}\centering
<<fvisprojp,echo=F,fig=T,eps=F,width=10,height=5>>=
<<visprojp>>
@ 
\caption{Simulated (top and bottom left), 
  posterior mean (top and bottom mid) and 
  posterior standard deviations (top and 
  bottom right) for both random fields.}
\label{fig:visprojp}
\end{figure}

We see on the Figure~\ref{fig:visprojp} 
that the predicted values are similar to 
the simulated ones. 
Also, we see that the variance increase 
proportionally to the first coordinate. 
And we see the oposite for the second random field. 
Its because we a negative value the respective 
$\theta$ to first and positive to second. 
Also, we see that the variance of 
the first is greater than the second. 

