/*! \mainpage 
  
  \section Intro GMRFLib: a C-library for fast and exact simulation of Gaussian Markov random fields

  This manual describes the library \em GMRFLib of
  \em C -routines for fast and exact simulation of Gaussian
  Markov Random Fields (GMRF) on graphs.  The library performs

  - unconditional simulation of a GMRF,
  - various types of conditional simulation from a GMRF,
  - evaluation of the corresponding log-density, and
  - generation of blockupdates in MCMC-algorithms using
  - GMRF-approximations or auxilliary variables,
  - construction of non-Gaussian approximations to hidden GMRFs,
  - approximate inference using integrated nested Laplace approximations (INLA).
 
  \par  The GMRFLib-library is written by 

  \htmlonly H&aring;vard Rue (code and doc), Turid Follestad (doc),
  Hanne T. Wist (doc) and Sara Martino (doc)\endhtmlonly

  \par About the documentation

  It seems that I am (HRue) unable to keep the documentation up to
  date; New code and features are added all the time, but the
  documentation is left behind. Also, parts of the documentaiton seems
  a bit out-of-date, and there should be a good tutorial +++ If
  someone can/will help me on this issue, please let me know.

  \par Thanks to

  We are also greatful to people who as contributed by with code which
  is now integrated in GMRFLib:

  - Finn Lindgren (Mathematical Statistics, Centre for Mathematical
  Sciences, Lund, Sweden) for computing all the coefficients needed in
  \c sphere.c

  - Rudolf Fruehwirth (Institut fuer Hochenergiephysik
  Oesterreichische Akademie der Wissenschaften, Wien, Austria), who
  has contributed with \c GMRFLib_mixture_lgamma()
 
  - Hanne T. Wist contributed with an initial version of \c geo.c and
  computed all the coefficients in \c geo-coefs2.h and \c geo-coefs3.h
  based on <a
  href="http://www.math.ntnu.no/~hrue/GMRFLib/fitting-GMRFs-to-GFs.r">this
  R-code</a>.

  Further, we are greatful to 

  - Brad Bell (bradbell) (apl washington edu) which has provided a <a
    href="../tutorial/html/index.html"> tutorial examples of howto use
    GMRFLib</a>.


  \par Comments

  Email comments and errors to: \em hrue@math.ntnu.no

  \par Copyright
    \em GMRFLib: Fast and exact simulation of Gaussian Markov
    random fields on graphs. \n\n
    \htmlonly 
    Copyright &copy 2001-2007 H&aring;vard Rue
    \endhtmlonly \n\n    
    This program is free software; you can redistribute it and/or
    modify it under the terms of the GNU General Public License as
    published by the Free Software Foundation; either version 2 of the
    License, or (at your option) any later version. \n\n    
    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    General Public License for more details.  \n\n    
    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
    02111-1307, USA.  

  \htmlonly
  In the 
  <a href="pages.html">Related Pages</a>
  you can find
  <ul>
  <li>
  <a href="intropage.html">An introduction to this manual and a short 
  description of Gaussian Markov random fields</a>
  </li>
  <li>
  <a href="install.html">Description of how to install and compile this 
  library</a>
  </li>
  <li>
  <a href="Changelog.html">Changelog</a>
  </li>
  </ul>
  \endhtmlonly
*/  



/*! \page intropage Introduction and description of GMRFs

 - \ref intro

 - \ref GMRFintro

 - \ref description \n
   \ref specification \n
   \ref sampling \n
   \ref cond_sim \n
   \ref log_dens \n
   \ref block\n
   \ref hidden_GMRF\n
   \ref INLA\n

\section intro Introduction

This manual gives the documentation of the library \em GMRFLib of
routines for fast and exact simulation of Gaussian Markov random
fields on graphs, including the special cases of two-dimensional
lattice graphs and one-dimensional linear graphs. The algorithms are
computationally fast, and in most cases with \e n variables or nodes
in the graph, the algorithms require <em>O(n)</em> flops in the
one-dimensional case, and <em>O(n^{3/2})</em> flops in the
two-dimensional case. (Under suitable assumptions, of course).  For
most problems, there exists a reordering of the nodes of the graph
that results in a precision matrix with a relatively small bandwidth
or fill-in. This fact is the basis of the implementation of the
routines in \e GMRFLib.


In \ref GMRFintro, we give a brief introduction to Gaussian Markov
random fields. In \ref description, a description of the different
tasks solved by the \em GMRFLib -library, as well as some background
on the implementation of the different routines are given.

\htmlonly <a href="files.html">File List</a> \endhtmlonly and
\htmlonly <a href="annotated.html">Data Structures</a> \endhtmlonly
contain a detailed documentation of the \em C -routines and
storage schemes.

Some examples of how to use the routines are given in \htmlonly <a
href="pages.html">Related Pages</a>, \endhtmlonly including a worked
out example form spatial disease mapping.

In \ref install instructions on how to install and compile the code
are given.


\section GMRFintro A brief introduction to Gaussian Markov random fields

All routines in \em GMRFLib are computations on Gaussian
Markov Random Fields (GMRF) defined on graphs. Before defining a
general graph, we describe a GMRF on a lattice, which is a special
case of a graph.

Let \f$ \Lambda \f$  be a two-dimensional lattice with size 
\f$ n_{row}\times n_{col} \f$, which we index by 
\f$ i=0,...,n_{row}-1 \f$ and \f$ j=0,...,n_{col}-1 \f$.  
Further, let <em>\b x</em> be a Gaussian field (GF) with mean 
\f$ \mbox{\boldmath$\mu$} \f$ and \f$ \mbox{\boldmath$\Sigma$} \f$, 
defined on the lattice \f$ \Lambda \f$. Then, 
<em><b>x</b>_{ij}</em> is the value of the GF <em>\b x</em> at lattice 
site (<em>i,j </em>); \f$ i=0,...,n_{row}-1;\; j=0,...,n_{col}-1 \f$.  

The correlation structure of a Gaussian Markov random field (GMRF) is
usually defined by the precision matrix 
\f$ \mbox{\boldmath$Q$}=\mbox{\boldmath$\Sigma$}^{-1} \f$
rather than the covariance matrix \f$ \mbox{\boldmath$\Sigma$} \f$.  
The structure of \em \b Q is defined by the \em neighbourhood system. 
Denote by \f$ \partial_{ij} \f$
the neighbourhood of site (<em>i,j </em>). The library
\em GMRFLib uses a <em>rectangular window</em> to define the
neighbourhood \f$ \partial_{ij} \f$ of (<em>i,j </em>), such that
  \f[ \partial_{ij} = \left\{ (k,l) \in \Lambda\; :\;  | i - k| \le
  m_{row}\quad \mbox{and}\quad | j - l| \le m_{col} \right\}. 
  \hspace{2cm} (GMRF-1)\f]  

Here, \f$ m_{row} \f$ and \f$ m_{col} \f$ are constants and do not 
depend on (<em>i,j </em>).
This choice of \f$ \partial_{ij} \f$ defines the neighbourhood of 
(<em>i,j </em>) 
as the \f$ (2m_{row}+1)\times(2m_{col}+1) \f$ window centred at 
(<em>i,j </em>). Common choices are 
\f$ m_{row}=m_{col} = 1, 2 \mbox{ and } 3 \f$, giving a 
neighbourhood system of size <em>3*3, 5*5</em> or <em>7*7</em>. 
For a further discussion, see Rue and Tjelmeland (2002).

A GMRF <em>\b x</em> is a Gaussian field for which the following Markov
property hold: <em><b>x</b>_{ij}</em> and <em><b>x</b>_{kl}</em>
are conditional independent given
\f$ \mbox{\boldmath$x$}_{\Lambda\setminus \{(i,j),(k,l)\}}, 
\forall (k,l)\not\in \partial_{ij} \f$
Let \f$ \pi \f$ be the generic notation as the density of
its arguments, and let 
\f$ \mbox{\boldmath$x$}_{A} = {x_i : i \in A } \f$
and 
\f$ \mbox{\boldmath$x$}_{-A} = {x_i : i \notin A } \f$.
The conditional independence could also be written as
\f$ \pi(x_{ij}| \mbox{\boldmath$x$}_{-ij}) = 
\pi(x_{ij} | \mbox{\boldmath$x$}_{d_{ij}}) \f$.
The precision matrix <em>\b Q</em> of a GMRF has the property that
\f$ \mbox{\boldmath$Q$}_{ij,kl} = 0 \mbox{ if } (k,l) \notin 
\partial_{ij} \f$. 
Hence, only a few terms in <em>\b Q</em> have to be specified. 
For each \f$ (i,j) \in \Lambda \f$, these elements are 
\f$ \mbox{\boldmath$Q$}_{ij,kl} \forall (k,l) \in 
\partial_{ij} \f$ and
the diagonal element \f$ \mbox{\boldmath$Q$}_{ij,ij} \f$.

Note that <em>\b Q</em> must be positive definite and symmetric.

A \em general graph is defined by a set of nodes 
\f$ \Lambda \f$, not
necessarily on a lattice, and a neighbourhood, 
\f$ \partial_{i}; \forall i \in \Lambda \f$, of nodes, defined such that for a 
Gaussian field \em \b x, the conditional density of <em>x_i</em> given 
<em><b>x</b>_{-i}</em> only depends on 
\f$ \mbox{\boldmath$x$}_{\partial_i} \f$.  
This constitutes the Markov property of a GMRF on a general graph.  
A lattice is a special case of graph, where the nodes are regularly 
spaced, and the neighbourhood has a regular form.


\section description Description of the tasks solved by GMRFLib

The \em GMRFLib library contains routines for solving four main tasks
concerning GMRF's. These are unconditional and conditional sampling
from a GMRF, evaluation of the log-density of a sample from a GMRF and
constructing non-Gaussian approximations to hidden GMRFs. The routines
are implemented for a GMRF <em>\b x</em> of this form

  \f[\pi(\mbox{\boldmath$x$}) \propto \exp\left( -\frac{1}{2} 
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$})^T
  (\mbox{\boldmath$Q$} + \mbox{diag}(\mbox{\boldmath$c$}))
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$}) + 
  \mbox{\boldmath$b$}^T\mbox{\boldmath$x$}
  \right). \hspace{2cm} (GMRF-2) \f]

The mean and covariance matrix of <em>\b x</em> are given by

  \f[ \mbox{E}(\mbox{\boldmath$x$}) = \mbox{\boldmath$\mu$} 
  + (\mbox{\boldmath$Q$}+\mbox{diag}(\mbox{\boldmath$c$}))^{-1}
  \mbox{\boldmath$b$} \hspace{2cm} (GMRF-3) \f]
  \f[ \mbox{Var}(\mbox{\boldmath$x$}) = (\mbox{\boldmath$Q$} 
  + \mbox{diag}(\mbox{\boldmath$c$}))^{-1}. \hspace{2cm} (GMRF-4) \f]

Additonally, we can impose conditioning either though a set of <em>x_i</em>'s
are fixed, or in more general that some linear combinations

  \f[ \mbox{\boldmath$Ax$} = \mbox{\boldmath$e$} \hspace{2cm} (GMRF-5) \f]

are known, or observed with error

  \f[ \mbox{\boldmath$Ax$} = \mbox{\boldmath$e$} 
  +\mbox{\boldmath$\epsilon$} \hspace{2cm} (GMRF-6) \f]

Here, \f$ \mbox{\boldmath$\epsilon$} \f$ is a zero mean Gaussian 
variable with covariance matrix \f$ \mbox{\boldmath$\Sigma$} \f$, 
and \em \b A is a <em>k*n</em> matrix of rank
\em k. The conditioning of the form \em \b Ax is computed in an
efficient way, requiring <em>O(k^3)</em> additional flops.

In this section, we describe the tasks that can be solved using
\em GMRFLib, referring to the objects and routines that are to
be used. A detailed description and documentation of the objects and
routines are given in 
\htmlonly <a href="files.html">File List</a> \endhtmlonly and
\htmlonly <a href="annotated.html">Data Structures</a>\endhtmlonly.
All routines are based on
the operations on graphs, and before turning to a description of the
sampling algorithms, we describe how to specify and handle graphs.


\subsection specification Specification and handling of graphs

The GMRF can be specified on a general graph or on a regular lattice.
In general, a graph is defined by a set of \em n nodes, and the set of
neighbours, denoted \f$ \partial_i \f$, for each node \em i.  In \em
GMRFLib, all graphs are represented by the same data structure,
described in GMRFLib_graph_tp.  The user can specify the neighbourhood
structure of a graph by creating and initializing an instance of this
data structure in a \em C -program. However, the simplest approach to
specifying a general graph within \em GMRFlib is reading the
specification from a file.

For a few special cases, the graphs can alternatively be specified
using type-specific routines, specifying the parameters defining the
graphs. Whatever method is used to specify these graphs, the graphs
will be represented by the general data structure.  The functions are
introduced to simplify the specification of these graphs, since the
neighbourhood structures are specified by a limited number of
parameters. The special cases that are supported by separate routines
are lattice graphs, linear graphs and the graph corresponding to
weighted averages (wa-graphs).

- A <em>regular lattice graph</em> can be represented by a set of
  nodes on a \f$ n_{row} \mbox{ by } n_{col} \f$ lattice, such that 
  \f$ n = n_{row}\times n_{col} \f$. 
  In the case of a lattice, the neighbourhood \f$ \partial_i \f$ of node 
  \em i is defined as a rectangular window of size 
  \f$ 2m_{row} + 1 \mbox{ by } 2m_{col} + 1 \f$, around the centre 
  point \em i, as described in \ref GMRFintro. The graph is fully 
  specified by the parameters 
  \f$ n_{row}, n_{col}, m_{row} \mbox{ and }m_{col} \f$.

- A <em>linear graph</em> refers to one-dimensional graphs
  representing auto-regressive (AR) models of order \em p. The linear
  graph represents the conditional independence structure of a GMRF
  having density of the form  
    \f[ \pi(\mbox{\boldmath$x$})\propto \exp
    \left(-\frac{\kappa}{2}\sum_{i}\left(x_i - \sum_{k=1}^p \phi_k 
    x_{i-k}\right)^2\right),\hspace{2cm} (GMRF-7) \f]
  letting E<em>(\b x) = \b 0</em>.

- The <em>wa-graph</em> is introduced as the corresponding graph to a
  density of the form 
    \f[ \pi(\mbox{\boldmath$x$}) \propto \exp
    \left(-\frac{1}{2}\sum_{i}\left(w_{ii} x_i - \sum_{j\sim
    i} w_{ij} x_{j}\right)^2\right). \hspace{2cm} (GMRF-8) \f]
  The weights are not required to be symmetric, such that in general
  \f$ w_{ij} \neq w_{ji} \f$.  The reason for treating this model
  separately, is that by specifying a GMRF with density of the form
  <b>(GMRF-8)</b>, it is often easier and more intuitive to specify
  the weights \f$ w_{ij} \f$ and their corresponding graph, than
  specifying the neighbourhood structure of the GMRF <em>\b x</em>
  directly, using the representation <b>(GMRF-2)</b>. (However:
  neither one is easy!) In \em GMRFLib, 
  GMRFLib_init_wa_problem() (or its generalization 
  GMRFLib_init_nwa_problem()) is provided for transforming
  from the representation <b>(GMRF-8)</b> to the representation 
  <b>(GMRF-2)</b>.

The most important operations available concerning specification and
handling of graphs and lattices, along with the corresponding
functions, are 
- Read a graph from a file (ascii) GMRFLib_read_graph()
- Read a graph from a file (binary) GMRFLib_read_graph_binary()
- Write a graph from a file (ascii) GMRFLib_write_graph()
- Write a graph from a file (binary) GMRFLib_write_graph_binary()
- Print the specification of a graph to standard output or a file  
  GMRFLib_print_graph()
- Create an empty graph  GMRFLib_make_empty_graph()
- Free the memory held by a graph  GMRFLib_free_graph()
- Create a graph on a lattice GMRFLib_make_lattice_graph()
- Create the graph of a linear autoregressive AR(\em p )-model  
  GMRFLib_make_linear_graph()
- Extract a subgraph of a graph  GMRFLib_compute_subgraph()
- Check the graph definition for consistency GMRFLib_validate_graph()
- Prepare a user-defined graph for computations GMRFLib_prepare_graph()
- Complete a uncomplete graph  GMRFLib_complete_graph()
- Combine two graphs to create an expanded graph  GMRFLib_fold_graph()
- Expand a graph by multiple folding (<em>g * g * ...</em>) 
  GMRFLib_nfold_graph()
- Define the ordering of the nodes of a lattice  GMRFLib_lattice2node()
- Create a lattice from a set of ordered nodes  GMRFLib_node2lattice()
- Check whether  nodes are neighbours  GMRFLib_is_neighb()
- Compute <em>\b Qx</em> for the precision matrix <em>\b Q</em>
  and a vector <em>\b x</em> GMRFLib_Qx() 
- Remove nodes of a graph for which <em>Q(i,j) = 0</em> 
  GMRFLib_prune_graph()
- Copy a graph GMRFLib_copy_graph()
- Convert the graph of a weighted average problem to a general graph 
  GMRFLib_init_wa_problem()



\subsection sampling Sampling from a GMRF

The \em GMRFLib is designed for solving the general problem of
sampling from a GMRF <em>\b x</em> of size \em n with density given by the
general expression <b>(GMRF-2)</b>.  The library supports
unconditional simulation and three types of conditional simulation:
conditioning on fixed values, on a deterministic linear constraint or
on a stochastic linear constraint with Gaussian noise. Formally, the
possible constraints are
  \f[ x_i;\; i \in \mathcal{F} \mbox{ are fixed} 
  \hspace{2cm} (GMRF-9) \f]
and
  \f[ \mbox{\boldmath$Ax$} = \mbox{\boldmath$e$} 
  + \mbox{\boldmath$\epsilon$}, \mbox{  where  } 
  \left\{\begin{array}{ll} 
  \mbox{\boldmath$\epsilon$} \equiv \mbox{\boldmath$0$} & 
  \mbox{ (deterministic linear constraint)} \\
  \mbox{\boldmath$\epsilon$}\sim N(\mbox{\boldmath$0$},
  \mbox{\boldmath$\Sigma$}_{\epsilon}) & 
  \mbox{ (stochastic linear constraint)} 
  \end{array}\right. \hspace{2cm} (GMRF-10) \f]

Sampling from <b>(GMRF-2)</b> conditionally on a stochastic
linear constraint, is equivalent to sampling from the unconditional
distribution
  \f[ \pi(\mbox{\boldmath$x$}) \propto \exp\left( -\frac{1}{2} 
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$})^T
  (\mbox{\boldmath$Q$} + \mbox{diag}(\mbox{\boldmath$c$}))
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$}) + 
  \mbox{\boldmath$b$}^T\mbox{\boldmath$x$}-\frac{1}{2} 
  (\mbox{\boldmath$Ax$} - \mbox{\boldmath$e$})^T
  \mbox{\boldmath$\Sigma$}_{\epsilon}^{-1}
  (\mbox{\boldmath$Ax$} - \mbox{\boldmath$e$})\right).
  \hspace{2cm} (GMRF-11) \f] 

All these simulation methods are implemented in one function,
GMRFLib_sample().

The library also includes a function for constructing block-sampling
schemes in MCMC algorithms, GMRFLib_blockupdate, sampling
from the general model
  \f[ \pi(\mbox{\boldmath$x$}) \propto \exp\left( -\frac{1}{2} 
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$})^T
  (\mbox{\boldmath$Q$} + \mbox{diag}(\mbox{\boldmath$c$}))
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$}) + 
  \mbox{\boldmath$b$}^T\mbox{\boldmath$x$}
  +\sum d_i f_i(x_i) \right). \hspace{2cm} (GMRF-12) \f] 

(under the same general constraints as above).  Here, the functions
\f$ f_i(x_i) \f$ are general functions of the components of the GMRF
<em>\b x</em>.

In the subsections to follow, we describe the sampling methods in more
detail.


\subsubsection ucond_sim Unconditional simulation

<em>Methods for sparse matrices are most easily explained using a band
approach, which we use in this introduction. GMRFLib use by default a
more modern approach implemented in the TAUCS library, which aims to
reduce the number of fill-ins. A description of this approach is most
easily available in Rue & Held (2005, Chapter 2). These methods have
complexity O(n^{3/2}) for spatial applications while the band-approach
needs O(n^2).</em>

Unconditional simulation from a GMRF <em>\b x</em> with distribution given
by <b>(GMRF-2)</b> can be done fast and exact.  The sampling
routines utilize the fact that by computing the band-Cholesky
factorization
  \f[ \mbox{\boldmath$Q$} = \mbox{\boldmath$LL$}^T 
  \hspace{2cm} (GMRF-13) \f]
and then solving by band back-substitution
  \f[ \mbox{\boldmath$L$}^T\mbox{\boldmath$x$}=\mbox{\boldmath$z$}
  \hspace{2cm} (GMRF-14) \f]
where <em>\b z</em> is a vector of \em i.i.d standard Gaussian variables,
<em>\b x</em> is an exact sample from a GMRF with precision matrix 
<em>\b Q</em> and zero mean (Rue(2001)). Further, it is assumed that 
<em>\b Q</em> is sparse and banded with a relatively small bandwidth, 
<em>b_w</em>. The graphs on which the GMRF is defined, are customized such 
that the bandwidth is minimized for the problem at hand. As an example,
consider a \f$ n_{row} \times n_{col} \f$ lattice graph with a 
neighbourhood defined by a \f$ 2m_{row} + 1 \mbox{ by } 2m_{col} + 1 \f$ 
window.  The bandwidth <em>b_w</em> is chosen to be
  \f[ b_w = \min\{b_{w1}, b_{w2}\},\hspace{2cm} (GMRF-15) \f]
where
  \f[ b_{w1} = \min\{m_{col}, n_{col}-1\}\times n_{row}
  +\min\{m_{row}, n_{row}-1\} \hspace{3cm}\mbox{  and } \f]
  \f[ b_{w2} = \min\{m_{row}, n_{row}-1\}\times n_{col}
  +\min\{m_{col}, n_{col}-1\}.\hspace{2cm} (GMRF-16) \f]
The bandwidths <em>b_{w1}</em> and <em>b_{w2}</em> correspond to 
different storage schemes, column-wise and row-wise respectively, for 
which the most efficient one is chosen in \em GMRFLib.  The matrix 
<em>\b L</em> can be computed using only \f$ n_{row}n_{col}b_w^2 \f$ flops, 
and <em>\b Lx=z</em> can be solved using only \f$ 2n_{row}n_{col}b_w \f$
flops (Golub and van Loan (1996)).  High-quality routines for computing
<b>(GMRF-13)</b> and <b>(GMRF-14)</b> are available in the
\c Lapack Fortran-library (Anderson et al. (1995)).

For a general graph, if the bandwidth of the precision matrix based on
the original ordering of the nodes is not small, the \em GMRFLib -library 
will re-order the nodes so as to minimize the bandwidth automatically and 
thus increase the efficiency of the sampling.

Once the band-Cholesky factorization <em>\b L</em> has been computed,
repeated samples can be generated by solving <b>(GMRF-14)</b> for a set
of samples \f$ \mbox{\boldmath$z$} \stackrel{iid}{\sim} 
N(\mbox{\boldmath$0$},\mbox{\boldmath$I$}) \f$, reusing <em>\b L</em>.


\subsection cond_sim Conditional simulation

\subsubsection lin_constr Conditioning on a linear constraint

A conditional sample <em>\b x *</em> from the conditional distribution
\f$ \mbox{\boldmath$x$}|\mbox{\boldmath$Ax$}=\mbox{\boldmath$e$} \f$, 
where <em>\b A</em> is a \f$ n_{cond}\times n \f$
matrix of rank \f$ n_{cond} \f$, and <em>\b e</em> is a vector of length 
\f$ n_{cond} \f$, is obtained from an unconditional sample <em>\b x</em>, 
by calculating
  \f[ \mbox{\boldmath$x$}^* = \mbox{\boldmath$x$} - 
  \mbox{\boldmath$Q$}^{-1}\mbox{\boldmath$A$}^T\left(
  \mbox{\boldmath$AQ$}^{-1}\mbox{\boldmath$A$}^T\right)^{-1}	
  \left(\mbox{\boldmath$Ax$}-\mbox{\boldmath$e$}\right).
  \hspace{2cm} (GMRF-17) \f]
This is commonly referred to as conditioning using Kriging, see
Cressie (1993, Sec- 3.6.2). If repeated conditional samples are
required, then some of the calculations in <b>(GMRF-17)</b> can be
avoided.  \em GMRFLib takes advantage of this by reusing
  \f[ \mbox{\boldmath$Q$}^{-1}\mbox{\boldmath$A$}^T\left(
  \mbox{\boldmath$AQ$}^{-1}\mbox{\boldmath$A$}^T\right)^{-1}	
  \hspace{2cm} (GMRF-18) \f]


\subsubsection lin_constr_stoch Conditioning on a stochastic linear constraint

A sample <em>\b x *</em> from the conditional distribution
\f$ \mbox{\boldmath$x$}|\mbox{\boldmath$Ax$}+\mbox{\boldmath$\epsilon$}
=\mbox{\boldmath$e$} \f$, 
where <em>\b A</em> and <em>\b e</em> are defined as in \ref lin_constr
and \f$ \mbox{\boldmath$\epsilon$}\sim N(\mbox{\boldmath$0$},
\mbox{\boldmath$\Sigma$}_{\epsilon}) \f$, can be obtained
in a similar way as in the case of a deterministic constraint, with a
slight modification of <b>(GMRF-17)</b>. From an unconditional
sample <em>\b x</em>, a conditional sample <em>\b x *</em> is obtained by
sampling an \f$ \mbox{\boldmath$\epsilon$}^*\sim N(\mbox{\boldmath$0$},
\mbox{\boldmath$\Sigma$}_{\epsilon}) \f$, and then computing
  \f[ \mbox{\boldmath$x$}^* = \mbox{\boldmath$x$} - 
  \mbox{\boldmath$Q$}^{-1}\mbox{\boldmath$A$}^T\left(
  \mbox{\boldmath$AQ$}^{-1}\mbox{\boldmath$A$}^T 
  +\mbox{\boldmath$\Sigma$}_{\epsilon}\right)^{-1}	
  \left(\mbox{\boldmath$Ax$}-\mbox{\boldmath$e$}\right).
  \hspace{2cm} (GMRF-19) \f]
To prove <b>(GMRF-19)</b>, compute the mean and covariance matrix of
<em>\b x *</em>, and compare it to the values obtained using multivariate
normal theory, which are
  \f[ \mbox{E}(\mbox{\boldmath$x$}^*) = \mbox{E(\boldmath$x$)} - 
  \mbox{\boldmath$Q$}^{-1}\mbox{\boldmath$A$}^T\left(
  \mbox{\boldmath$AQ$}^{-1}\mbox{\boldmath$A$}^T 
  +\mbox{\boldmath$\Sigma$}_{\epsilon}\right)^{-1}	
  \left(\mbox{\boldmath$A$}\mbox{ E(\boldmath$x$)}
  -\mbox{\boldmath$e$}\right), \hspace{2cm} (GMRF-20) \f]
  \f[ \mbox{Var}(\mbox{\boldmath$x$}^*) = 
  \left(\mbox{\boldmath$Q$}+ \mbox{\boldmath$A$}^T
  \mbox{\boldmath$\Sigma$}_{\epsilon}^{-1}\mbox{\boldmath$A$}
  \right)^{-1}.\hspace{2cm} (GMRF-21) \f]
The comments on computational efficiency made in \ref lin_constr apply 
to the case of a stochastic constraint as well.


\subsubsection fixed_val Conditioning on fixed values

Assume that the GMRF <em>\b x</em> is observed for a subset 
\f$ \mathcal{F} \f$ of the nodes in the set \f$ \Lambda \f$, and denote 
the observed values by \f$ \mbox{\boldmath$x$}_{\mathcal{F}} \f$. 
Similarly let \f$ -\mathcal{F} \f$ denote the remaining nodes, that is 
\f$ -\mathcal{F} = \{i: i \in \Lambda \backslash \mathcal{F} \} \f$. 
We want to sample from the conditional distribution of 
\f$ \mbox{\boldmath$x$}_{\mathcal{F}} \f$ given 
\f$ \mbox{\boldmath$x$}_{-\mathcal{F}} \f$,
\f$ \pi(\mbox{\boldmath$x$}_{\mathcal{F}} \mid 
\mbox{\boldmath$x$}_{-\mathcal{F}}) \f$. 
Let \f$ \mbox{\boldmath$x$}_1 = \mbox{\boldmath$x$}_{\mathcal{F}}
\mbox{ and } \mbox{\boldmath$x$}_2 = \mbox{\boldmath$x$}_{-\mathcal{F}} \f$, 
and partition the precision matrix, <em>\b Q</em>, it's inverse 
<em>\b Q ^{-1}</em> and \f$ \mbox{\boldmath$\mu$} \f$ and <em>\b b</em>
in <b>(GMRF-2)</b> accordingly, such that
  \f[ \mbox{\boldmath$Q$} = \left( \begin{array}{cc}
  \mbox{\boldmath$Q$}_{11} & \mbox{\boldmath$Q$}_{12} \\
  \mbox{\boldmath$Q$}_{21} & \mbox{\boldmath$Q$}_{22} \\
  \end{array} \right), \;\;\; 
  \mbox{\boldmath$Q$}^{-1} = \left(\begin{array}{cc}
  \mbox{\boldmath$Q$}^{11} & \mbox{\boldmath$Q$}^{12} \\
  \mbox{\boldmath$Q$}^{21} & \mbox{\boldmath$Q$}^{22} \\
  \end{array} \right), \;\;\; 
  \mbox{\boldmath$\mu$} = \left(\begin{array}{c} 
  \mbox{\boldmath$\mu$}_1 \\ \mbox{\boldmath$\mu$}_2 \\  
  \end{array} \right), \;\;\; \mbox{ and }
  \mbox{\boldmath$b$} = \left(\begin{array}{c} 
  \mbox{\boldmath$b$}_1 \\ \mbox{\boldmath$b$}_2 \\ 
  \end{array} \right) \hspace{2cm} (GMRF-22) \f]

The conditional mean 
\f$ \mbox{\boldmath$\mu$}_{1\mid 2}=\mbox{E}(\mbox{\boldmath$x$}_1 \mid
\mbox{\boldmath$x$}_2) \f$ 
and precision matrix 
\f$ \mbox{\boldmath$Q$}_{1\mid 2}=(\mbox{Var}(\mbox{\boldmath$x$}_1
\mid \mbox{\boldmath$x$}_2))^{-1} \f$ are given by
  \f[ \mbox{\boldmath$\mu$}_{1\mid 2} = \mbox{E}(\mbox{\boldmath$x$}_1) -
  \mbox{\boldmath$Q$}_{11}^{-1}\mbox{\boldmath$Q$}_{12}
  (\mbox{\boldmath$x$}_2 - \mbox{E}(\mbox{\boldmath$x$}_2)) 
  \hspace{2cm} (GMRF-23) \f]

  \f[ \mbox{\boldmath$Q$}_{1\mid 2} = \mbox{\boldmath$Q$}_{11} + 
  \mbox{diag}(\mbox{\boldmath$c$}_1),
  \hspace{2cm} (GMRF-24) \f]

where \f$ \mbox{E}(\mbox{\boldmath$x$}_1) \f$ and 
\f$ \mbox{E}(\mbox{\boldmath$x$}_2) \f$ are the marginal means, given by
  \f[ \left( \begin{array}{c}\mbox{E}(\mbox{\boldmath$x$}_1) \\  
  \mbox{E}(\mbox{\boldmath$x$}_2) \end{array} \right) = 
  \left( \begin{array}{c} \mbox{\boldmath$\mu$}_1 \\  
  \mbox{\boldmath$\mu$}_2 \end{array} \right) + 
  \left(\begin{array}{cc}
  \mbox{\boldmath$Q$}^{11} & \mbox{\boldmath$Q$}^{12} \\
  \mbox{\boldmath$Q$}^{21} & \mbox{\boldmath$Q$}^{22} \\
  \end{array} \right)
  \left( \begin{array}{c}\mbox{\boldmath$b$}_1 \\ \mbox{\boldmath$b$}_2
  \end{array} \right). \hspace{2cm} (GMRF-25) \f]

To sample from the conditional distribution, we need to compute the
conditional mean and precision matrix. The conditional precision
matrix is simply \f$ \mbox{\boldmath$Q$}_{11} \f$, a sub-matrix of the 
full precision matrix. Thus, it's bandwidth will be equal to or less than 
the bandwidth of the full matrix. The conditional mean 
\f$ \mbox{\boldmath$\mu$}_{1|2} \f$ is computed by solving
  \f[ (\mbox{\boldmath$Q$}_{11} + \mbox{diag}(\mbox{\boldmath$c$}_1))\; 
  \mbox{\boldmath$\mu$}_{1|2} = \mbox{\boldmath$b$}^{'}, 
  \hspace{2cm} (GMRF-26) \f]
were \f$ \mbox{\boldmath$b$}^{'} \f$ is obtained by writing the Gaussian 
distribution of
\f$ \pi(\mbox{\boldmath$x$}_{1} \mid \mbox{\boldmath$x$}_{2}) \f$ on the form
  \f[ \pi(\mbox{\boldmath$x$}_{1} \mid \mbox{\boldmath$x$}_{2}) 
  \propto \exp\left( -\frac{1}{2} \mbox{\boldmath$x$}_1^T 
  (\mbox{\boldmath$Q$}{11} + \mbox{diag}(\mbox{\boldmath$c$}_1)) \;
  \mbox{\boldmath$x$}_1 + (\mbox{\boldmath$b$}^{'})^T\mbox{\boldmath$x$}_1
  \right). \hspace{2cm} (GMRF-27) \f]
Given the band-structure of \f$ \mbox{\boldmath$Q$}_{11} \f$, this can be done
efficiently, as described in \ref ucond_sim.


\subsection log_dens Evaluation of the log-density of a sample

GMRFLib_evaluate() evaluates the log-density of
a sample from a GMRF. The routine returns the full log-density,
including the normalizing constant. For an unconditional sample
<em>\b x</em>, the log-density is computed as
  \f[ \log\pi(\mbox{\boldmath$x$}) = -\frac{n}{2}\log(2 \pi) +
  \frac{1}{2}\log|\mbox{\boldmath$Q$} + \mbox{diag}(\mbox{\boldmath$c$})| 
  -\frac{1}{2}(\mbox{\boldmath$x$}-\mbox{\boldmath$\tilde\mu$})^T 
  (\mbox{\boldmath$Q$} + \mbox{diag}(\mbox{\boldmath$c$}))
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\tilde\mu$}) 
   \hspace{2cm} (GMRF-28) \f]
where \f$\mbox{\boldmath$\tilde\mu$}\f$ is the (computed) mean.

For a sample form the conditional distribution, the log-density is
computed as the right hand side of
  \f[ \pi(\mbox{\boldmath$x$} | \mbox{\boldmath$Ax$}) =
  \frac{\pi(\mbox{\boldmath$Ax$}|\mbox{\boldmath$x$})
  \pi(\mbox{\boldmath$x$})}{\pi(\mbox{\boldmath$Ax$})}
  \hspace{2cm} (GMRF-29) \f]
for deterministic linear constraints, and similarly for stochastic
linear constraints.  GMRFLib_evaluate() is called from within the sampling 
routine GMRFLib_sample(), reusing terms computed during the sampling, to
increase the efficiency.  The routine can also be called by the user
to evaluate the density of an arbitrary <em>\b x</em>.


\subsection block Block-sampling

In many applications, sampling from a GMRF <em>\b x</em> enters into Markov
Chain Monte Carlo (MCMC) algorithms designed for sampling based
estimation of the parameters of a model, given a set of data <em>\b y</em>.
Let \f$ \mbox{\boldmath$\psi$} \f$ be the set of parameters to be estimated.  
In a general MCMC-algorithm, we generate approximate samples from the
posterior distribution 
\f$ \pi(\mbox{\boldmath$\psi$}|\mbox{\boldmath$y$}) \f$, 
by sampling an ergodic Markov Chain having 
\f$ \pi(\mbox{\boldmath$\psi$}|\mbox{\boldmath$y$}) \f$, 
as its stationary distribution.  For an introduction to MCMC methods, see e.g.
Robert and Casella (1999) and
Gilks et al. (1996).

A frequently used method is the Gibbs sampler, where at each
iteration, each parameter is updated in turn, conditionally on the
last updates of the remaining parameters. One or more of the parameter
updates of the Gibbs sampler might involve a Metropolis-Hastings step.
This routine works fine in many applications, but if the parameters to
be estimated are highly correlated, the convergence and mixing might
be very slow. A modification of the Gibbs sampler is to group the
parameters in subsets or blocks, updating each block in turn.

One situation where this blocking approach is useful, is in the case
where the parameters of the GMRF <em>\b x</em> depend on unknown
hyper-parameters, that are to be estimated. It often turns out that
several of these parameters are highly correlated to the GMRF
<em>\b x</em>, and thus the GMRF and the hyper-parameters should be updated
jointly in one block. In \em GMRFLib a routine, GMRFLib_blockupdate(),
is implemented to solve this task.

In general, GMRFLib_blockupdate() generates samples from a Gaussian Markov 
random field, or Gaussian proposals for a nearly Gaussian Markov random 
field, conditionally on a set of hyper-parameters 
\f$ \mbox{\boldmath$\theta$} \f$.  The most general model for the
conditional density of <em>\b x</em> given 
\f$ \mbox{\boldmath$\theta$} \f$ is

  \f[ \pi(\mbox{\boldmath$x$}|\mbox{\boldmath$\theta$}) \propto 
  \exp\left( -\frac{1}{2}(\mbox{\boldmath$x$}-
  \mbox{\boldmath$\mu$}(\mbox{\boldmath$\theta$}))^T 
  [\mbox{\boldmath$Q$}(\mbox{\boldmath$\theta$}) + 
  \mbox{diag}(\mbox{\boldmath$c$}(\mbox{\boldmath$\theta$}))]
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$}
  (\mbox{\boldmath$\theta$})) + \mbox{\boldmath$b$}
  (\mbox{\boldmath$\theta$})^T \mbox{\boldmath$x$} + 
  \sum d_i(\mbox{\boldmath$\theta$})f(x_i;\mbox{\boldmath$\theta$}) 
  \right).\hspace{2cm} (GMRF-30) \f]

If the functions \f$ f(x_i;\mbox{\boldmath$\theta$}) \f$ are linear or 
quadratic in <em>x_i; i = 0,...,n-1</em>, the model is Gaussian, but the 
functions can be general, and this corresponds to the cases we termed as 
nearly Gaussian above.  The joint density of <em>\b x</em> and 
\f$ \mbox{\boldmath$\theta$} \f$, from which we want to sample, is given by

  \f[ \pi(\mbox{\boldmath$x$},\mbox{\boldmath$\theta$}) = 
  \pi(\mbox{\boldmath$x$}|\mbox{\boldmath$\theta$})
  \pi(\mbox{\boldmath$\theta$}),\hspace{2cm} (GMRF-31) \f]

where \f$ \pi(\mbox{\boldmath$\theta$}) \f$ is the prior distribution 
of the hyper-parameters \f$ \mbox{\boldmath$\theta$} \f$, and 
\f$ \pi(\mbox{\boldmath$x$}\mid\mbox{\boldmath$\theta$}) \f$ is
given by <b>(GMRF-30)</b>.

In the case of a MCMC update conditionally on data, the updates are to
be computed from the joint posterior distribution of <em>\b x</em> and
\f$ \mbox{\boldmath$\theta$} \f$ given the data <em>\b y</em>. In the 
posterior distribution
  \f[ \pi(\mbox{\boldmath$x$},\mbox{\boldmath$\theta$}| 
  \mbox{\boldmath$y$}) \propto \pi(\mbox{\boldmath$y$} |
  \mbox{\boldmath$x$},\mbox{\boldmath$\theta$})
  \pi(\mbox{\boldmath$x$}|\mbox{\boldmath$\theta$})
  \pi(\mbox{\boldmath$\theta$}),\hspace{2cm} (GMRF-32) \f]

the term 
\f$ \pi(\mbox{\boldmath$y$}|\mbox{\boldmath$x$},\mbox{\boldmath$\theta$})
\pi(\mbox{\boldmath$x$}|\mbox{\boldmath$\theta$}) \f$
should then be of the form <b>(GMRF-30)</b>, where the parameters and 
the functions \f$ f(x_i) \f$ will depend on the data <em>\b y</em>
in addition to the hyper-parameters \f$ \mbox{\boldmath$\theta$} \f$. 
In such a case the functions 
\f$ f(x_i;\mbox{\boldmath$\theta$});\; i=0\ldots, n-1 \f$ can,
but do not have to, be equal to the elements of the log-likelihood of
<em>\b x</em>, given the data. An example of an application where this is
the case, is described in detail in \ref ex_blockupdate.

In a similar way as for the GMRF sampling methods described in
\ref sampling, the block-sampling can be done conditionally on fixed 
values or a deterministic or stochastic linear constraint. The 
block-sampling algorithm is described in more detail in blockupdate.c.

For an application of the block-sampling algorithm, see
Knorr-Held and Rue (2002).


\subsection hidden_GMRF Construction of non-Gaussian approximations to Hidden GMRFs (HGMRFs)

This cannot be explained in short, please refer to Chapter 5.2 in Rue
and Held (2005) or the origianl article, Rue, Steinsland and Erland (2004).

\subsection INLA Approximate Inference using Integrated Nested Laplace Approximations (INLA).

Integrated nested Laplace approximation (INLA) provides with a fast,
deterministic alternative to MCMC based inference for latent Gaussian
models. The details cannot be explained in short, please refer to the
article Rue, Martino and Chopin (2007).\n

The \em GMRFLib contains routines for performing approximate inference
for the posterior
\f[ \pi(\mbox{\boldmath$x$}, \mbox{\boldmath$\theta$} \mid \mbox{\boldmath$y$}) \propto
\pi(\mbox{\boldmath$\theta$})
\pi(\mbox{\boldmath$x$} \mid \mbox{\boldmath$\theta$}) \prod_{i} \pi(y_i \mid x_i, \mbox{\boldmath$\theta$})
,\hspace{2cm} (GMRF-33) \f]			
where \f$ \pi(\mbox{\boldmath$x$} \mid \mbox{\boldmath$\theta$}) \f$
is a GMRF.\n
The most general form   for the posterior density in <b>(GMRF-33)</b>
is 
  \f[  \pi(\mbox{\boldmath$x$}, \mbox{\boldmath$\theta$} \mid
  \mbox{\boldmath$y$}) \propto 
  \exp\left( -\frac{1}{2}(\mbox{\boldmath$x$}-
  \mbox{\boldmath$\mu$}(\mbox{\boldmath$\theta$}))^T 
  [\mbox{\boldmath$Q$}(\mbox{\boldmath$\theta$}) + 
  \mbox{diag}(\mbox{\boldmath$c$}(\mbox{\boldmath$\theta$}))]
  (\mbox{\boldmath$x$}-\mbox{\boldmath$\mu$}
  (\mbox{\boldmath$\theta$})) + \mbox{\boldmath$b$}
  (\mbox{\boldmath$\theta$})^T \mbox{\boldmath$x$} + 
  \sum d_i(\mbox{\boldmath$\theta$})f(x_i; y_i,\mbox{\boldmath$\theta$}) 
  \right) \pi(\mbox{\boldmath$\theta$}).\hspace{2cm} (GMRF-34) \f]

We assume that the functions \f$ f_i(x_i,y_i) \f$ contain also
 non-quadratic terms of \f$ x_i \f$, so that <em>\b x|y</em> is not
 normal.

The routines in the \em GMRFLib compute approximate densities for:

- posterior marginals for \f$x_i\f$ given a fixed value of the
hyperparameter \f$\mbox{\boldmath$\theta$}\f$, \f$ \widetilde{\pi}(x_i
\mid \mbox{\boldmath$\theta$}, \mbox{\boldmath$y$}) \f$\n \n Three
different approximations are available for this density. In order of
accuracy: Gaussian, simplified Laplace and Laplace approximation.\n
The routine \c GMRFLib_ai_marginal_hidden() solves this task.\n

- posterior marginals for \f$x_i\f$ 
\f$ \widetilde{\pi}(x_i \mid  \mbox{\boldmath$y$}) \f$\n
\n
This density is computed via numerical integration as
\f[    \widetilde{\pi}(x_i\mid \mbox{\boldmath$y$}) =
    \sum_{k}\;
    \widetilde{\pi}(x_i \mid \mbox{\boldmath$\theta$}_k,
    \mbox{\boldmath$y$})
    \;\times\;
    \widetilde{\pi}(\mbox{\boldmath$\theta$}_k \mid \mbox{\boldmath
    $y$}) \;\times\; \Delta_k \f]
The points \f$\mbox{\boldmath$\theta$}_k\f$ and the weights
\f$\Delta_k\f$ can be choosen using either a grid or a central
composit design (CCD) strategy. \n
The routine \c GMRFLib_ai_INLA() solves this task.\n

- posterior distribution for the hyperparameter of the model  
\f$ \widetilde{\pi}(\mbox{\boldmath$\theta$} \mid \mbox{\boldmath$y$})
\f$\n
\n
This is computed as
 \f[   \widetilde{\pi}(\mbox{\boldmath$\theta$} \mid \mbox{\boldmath$y$}) \propto
  \frac{\pi(\mbox{\boldmath$x$},\mbox{\boldmath
    $\theta$}|\mbox{\boldmath$y$})}{ \widetilde{\pi}_{G}(\mbox{\boldmath
	$x$}|\mbox{\boldmath$\theta$},
        \mbox{\boldmath$y$})}\Bigg|_{\mbox{\boldmath$x$} = 
        \mbox{\boldmath$x$}^{\star}(\mbox{\boldmath$\theta$})}.\hspace{2cm} (GMRF-35)
 \f]
where \f$ \widetilde{\pi}_{G}(\mbox{\boldmath$x$}|\mbox{\boldmath
$\theta$}\f$ is a Gaussian approximation to
\f$\pi(\mbox{\boldmath$x$}|\mbox{\boldmath$\theta$}\f$ and
\f$\mbox{\boldmath$x$}^{\star}(\mbox{\boldmath$\theta$})\f$ is its
modal configuration.\n 
The routine  \c GMRFLib_ai_marginal_hyperparam() computes the
expression in <b>(GMRF-35)</b> for one value of \f$\mbox{\boldmath
$\theta$}\f$.\n
 If approximations to the posterior marginals for one or all 
\f$\theta_j\f$, \f$ \widetilde{\pi}(\theta_j\mid
\mbox{\boldmath$y$})\f$ 
are needed, they have to be computed via numerical
integration as:
\f[    \widetilde{\pi}(\theta_j\mid \mbox{\boldmath$y$}) =
    \sum_{k}\;
    \widetilde{\pi}(\theta_j , \mbox{\boldmath$\theta$}_{-j}^k\mid
    \mbox{\boldmath$y$}) \;\times\; \Delta_k \f] 
\n

The functions \c GMRFLib_ai_INLA() computes also the integrated
likelihood for the model, \f$ \widetilde{\pi}(\mbox{\boldmath$y$})
\f$. \n This is computed in the function in two different ways 
- assuming \f$ \pi(\mbox{\boldmath$\theta$} \mid
\mbox{\boldmath$y$})\f$ to be Gaussian and approximating \f$
\pi(\mbox{\boldmath$y$}) 
\f$ as constant times \f$\mid \mbox{\boldmath$H$}\mid
^{-\frac{1}{2}}\f$ where \f$\mbox{\boldmath$H$}\f$ is the hessian of
\f$ \pi(\mbox{\boldmath$\theta$} \mid \mbox{\boldmath$y$})\f$ computed
at its modal value.
- via numerical integration as the normalizing constant for the
posterior marginal of the hyperameters in in <b>(GMRF-35)</b>
 
See \ref ex_ai  for an example.\n

The routines allow for presence of linear contraints and fixed values.\n

The single functions are described in more details in approx-inference.c.
*/

/*! \page Tutorial Tutorial

  This is the <a href="../tutorial/html/index.html"> tutorial of how to
    use GMRFLib</a>, kindly provided by Brad Bell (bradbell) (apl
    washington edu).  
*/


/*! \page reference References

    (Outdated references...)

Anderson, E., Bai, Z., Bischof, C., Demmel, J., Dongarra, J., Croz, J., 
Greenbaum, A., Hammerling, S., McKenney, S., Ostrouchov, S. and Sorensen, D.
(1995). <em>LAPACK Users' Guide, 2 edn.</em>
Philadelphia: Society for Industrial and Applied Mathematics.

Cressie, N. (1993). <em>Statistics for Spatial Data.</em>
Wiley, New York.

Gilks, W. R., Richardson, S. and Spiegelhalter, D. J. (1996).
<em>Markov Chain Monte Carlo in practice.</em>
Chapman \& Hall, London, UK.

Golub, G. H. and van Loan, C. F. (1996).
<em>Matrix Computations, 3 edn.</em>
Johns Hopkins University Press, Baltimore.

Knorr-Held, L. and Rue, H. (2002).
On block updating in Markov random field models for disease mapping.
<em>Scandinavian Journal of Statistics</em>, 29(4):597-614.

Robert, C. P. and Casella, G. (1999).
<em>Monte Carlo statistical methods.</em>
Springer-Verlag, New York.

Rue, H. (2001). Fast sampling of Gaussian Markov random fields.
<em>Journal of the Royal Statistical Society, Series B</em>, 63(2):325-338.

Rue, H. and Held, L. (2005).
<em>Gaussian Markov Random Fields: Theory and Applications. Monographs
on Statistics and Applied Probability</em>, no 104, Chapman & Hall

Rue H. and I. Steinsland and S. Erland (2004) <em>Approximating hidden
{G}aussian {M}arkov random fields</em>, >Journal of the Royal
Statistical Society, Series B, to appear. 
  

Rue, H. and Tjelmeland, H. (2002)
Fitting Gaussian Markov random fields to Gaussian fields.
<em>Scandinavian Journal of Statistics</em>, 29(1):31-50.

Rue, H. and Held, L (2005)
Gaussian Markov Random Fields: Theory and Applications.
<em>Monographs on Statistics and Applied Probability</em>, vol 104,
Chapman & Hall: London.

Rue, H (2005) <em>Marginal variances for Gaussian Markov random
fields</em> Technical report, Department of Mathematical Sciences
Norwegian University of Science and Technology

Rue, H and S. Martino and N. Chopin (2007) <em>Approximate Bayesian
INference for Latent Gaussian Models Using Integrated Nested Laplace
Approximation</em> 
Technical report, Department of Mathematical Sciences
Norwegian University of Science and Technology

*/


/*! \page install Installing and compiling

Download the latest version of the \em GMRFLib-library, at

<tt>http://www.math.ntnu.no/~hrue/GMRFLib </tt>

Unpack <tt>GMRFLib-VERSION.tar.gz</tt> by

<tt>tar xvfz GMRFLib-VERSION.tar.gz</tt>

and the files will unpack in directory <tt>GMRFLib</tt>.
            
Install external libraries required

- TAUCS (Version >= 2.0)
- METIS
- LAPACK and BLAS (Fortran)
- zlib
- gsl

You may also want to replace BLAS and LAPACK (partly) with the more
optimised versions in

- ATLAS

If these are not already installed, the tarballs and precompiled
binarines for Atlas (some archs) are available in the directory
EXTLIBS.


Edit the <tt>Makefile</tt>, type

<tt>make</tt>

and install the library by

<tt>make install</tt>

and you may uninstall it later, if needed, by

<tt>make uninstall</tt>

The <tt>Makefile</tt> has some options in the top of the file.
the defaults suitable for a Linux-laptop.

\verbinclude doxygen_install.txt

Your need to decide about three matters.

- The PREFIX is where to install the files, and the default choice
  is suitable for a system installation. If you want to install them
  locally, you might use <tt>PREFIX=\$(HOME)/local</tt>.\n
  \em GMRFLib will install the library in <tt>\$(PREFIX)/lib</tt>, 
  the headerfiles in <tt>\$(PREFIX)/include/GMRFLib</tt>, and the 
  documentation in <tt>\$(PREFIX)/doc/GMRFLib</tt>.
- Choose which compiler to use and the compiler options. Make sure
  to use compile options allowing ``near optimal'' performance, for
  example on a Sun Ultra, your might chose \n\n
  <tt>CC = cc \n
  FC = f77 \n
  FLAGS= -fast </tt>\n\n
  and then recall to link your programs with the <tt>-fast</tt> 
  option as well.

To compile your program using the \em GMRFLib-library, you may
use 

<tt>\$(CC) \$(FLAGS) -c -I\$(PREFIX)/include my-prog.c \n
\$(FC) \$(FLAGS) -o my-prog my-prog.o -L\$(PREFIX)/lib -lGMRFLib
-ltaucs -lmetis -lblas -llapack -lz -lgls -lgslcblas -lm</tt>

Here, <tt>\$(CC)</tt> is the <tt>C</tt>-compiler as defined in
<tt>Makefile</tt> and similar with the other symbols.  You may need to
add other system libraries as well, but this is OS dependent.

If you use the Atlas-libraries (recomended), you may need to do 

<tt>\$(CC) \$(FLAGS) -c -I\$(PREFIX)/include my-prog.c \n
\$(FC) \$(FLAGS) -o my-prog my-prog.o -L\$(PREFIX)/lib \n
-lGMRFLib -ltaucs -lmetis -llapack-atlas -llapack  -lf77blas -lcblas
-latlas -lz -lgsl -lm </tt>

*/


/*! \page Changelog Changelog starting from version 2.0

Version 3.0-0-snaphot

	- ***WARNING***: There are changes in this version GMRFLib
          which does not necessarily makes it compatible with
          applications using version 2.x-x of GMRFLib. The changes are
          however minor, and easy to spot. Read below.

	- Some argument-checking in functions have been removed and
          the user can now override the error-handling
          system. However, alloc-errors will always use the default
          error-handler and then call abort().
	
	- The error-handling system has been improved. In that
	  occation, some functions returning the value in the
	  function-name has been changed to that the computed value is
	  returned as an argument. For example\n 
	  <em>int GMRFLib_compute_bandwidth(GMRFLib_graph_tp *graph, int
	  *remap);</em>\n 
	  has been changed to \n 
	  <em>int GMRFLib_compute_bandwidth(int *bandwidth, GMRFLib_graph_tp
	  *graph, int *remap);</em>\n 
	  In the old version, the bandwidth was return in the
	  function-name, whereas the new version, the error-code is
	  returned in the function-name and the result is returned in
	  the bandwidth-pointer.

	- Arguments to functions are now passed (more correcly) as \a
	  void *, and not \a char *. For example\n
	  <em>double Qfunc(int node, int nnode, char *arg) {....}</em>\n
	  must be changed to \n
	  <em>double Qfunc(int node, int nnode, void *arg) {....}</em>

	- Numerous internal changes.

	- Added support for reading and writing graphs in binary
          format through the functions \c GMRFLib_read_graph_binary()
          and \c GMRFLib_write_graph_binary().

	- Fixed a bug in handling graphs where the number of neighbors
          are zero. Thanks to Rasmus Waagepetersen for reporting this.

	- New features: Auxilliary variables for Poisson and Binomial
          observational models, which makes full conditionals
          Gaussian. see \c auxvar.c

	- New features: Approximate inference for latent Gaussian
          models using Integrated nested Laplace approximations
          (INLA). This involves a *lot* of new tools, see \c
          approx-inference.c and \c density.c.

        - Added support for editing graphs; see \c ged.c.

	- Added support for OpenMP (see http://www.openmp.org); more
          to come! The library has to be compiled with OpenMP support
          to enable these features. The \c GMRFLib_INLA() routine
          works excellent with OpenMP! Especially \c GMRFLib_ai_INLA()
          works great with OpenMP!

	- Added tool for defining hierarchical GMRF models; see \c hgmrf.c

Version 2.3-0

	- Spherical IGMRFs are now included: see the file \c sphere.c
          and the corresponding example-program. [Thanks to Finn
          Lindgren who computed all the nasty coefficients!]

	- The io-interface in GMRFLib now use the z-library
          (http://www.zlib.net/) so compressed (gzip'ed) files can be
          read as well as plain text files.

	- The second order RW on a 2D lattice is now implemented: see
          \ref GMRFLib_make_rw2d_graph() and \ref GMRFLib_rw2d() and
          \ref GMRFLib_rw2ddef_tp. [Thanks to Thomas Kneib for
          providing the boundary corrections!]

	- Minor changes in the code to ease integration with C++
          programs. [Thanks to Vedad Hadziavdic!]

	- GMRFLib_Qinv() is now implemented for the band-solver.

	- In \c geo.c: Some new coefficients are added.

	- GMRFLib needs now to be linked with the \em Gnu \em
	Scientific \em Library (http://www.gnu.org/software/gsl/)
	(version >= 1.8). There are quite a few internal changes in
	GMRFLib to integrate more closely with GSL, see for example
	the example in \c random.c 

	- Some extentions are added in the error-handling system, see
          \c error-handler.c and the example therein.


Version 2.2-1

	- Fixed a bug in the \c GMRFLib_blockupdate() routine, which
	was trigged by a non-zero mean.
	
	- Made some fixes in \c graph.c so it runs more smoothly where
	there are zero neigbours in a graph.  

Version 2.2-0

	- Added 'store' option to \c GMRFLib_blockupdate() which give
          significant speedup for repeated use. At level 1, the
          reordering, the sub_graph and the symbolic factorisation
          (using TAUCS) is now stored and reused. At level 2, also the
          problems compuated are stored and reused. See
          example-programs at \c GMRFLib_blockupdate().

	- \c GMRFLib_init_problem() now reuse the symbolic
          factorisation (using TAUCS) when the \c #GMRFLib_KEEP_graph
          flag is set. This gives some speedup.

	- In \c geo.c: A lot of new coefficients are added.  \c
	  GMRFLib_geo_problem_tp now contains the graph to the problem
	  definition. The example-program is changed accordingly. New
	  function: \c GMRFLib_revise_geo_problem(). Output of \c
	  GMRFLib_print_geo_coefs() has been simplified.

	- There are some speedup-improvements in \c
          GMRFLib_init_problem(). We now tabulate the Qfunction in \c
          GMRFLib_init_problem() so its used consistent with \c
          GMRFLib_evaluate(). 

	- Some changes are made to the fortran-code in the library so
          it compiles without warnings with `gfortran' (GNU Fortran 95
          compiler).

	- Version-number of the library is added to GMRFLib.h and it
          also occur in the default error-handler.

	- The irregular random walk 2 is implemented in \c
          GMRFLib_crw(), using the coefficients computed from an
          approximative Galerkin solution. Added \ref
          #GMRFLib_CRW_LAYOUT_SIMPLE to specify this option. The \c
          GMRFLib_crwdef_tp type is simplified (internal use only).

	- [Thanks to Sara Martino who reported a couple of bugs in the
           prelease of this version.]

Version 2.1-0

	- Added variables \ref GMRFLib_problem_tp::mean and \ref
          GMRFLib_problem_tp::mean_constr in \ref GMRFLib_problem_tp,
          which gives easier access to the mean before and after
          correcting for the constraints.

	- Added the functionality to tabulate Qfunction up to a scale,
	  to gain speedup for appropriate problems. Refer to the
	  description and example in \ref tabulate-Qfunc.c

	- Added support for GMRF approximations to Gaussian fields,
          and tables with coefficients, see \ref geo.c and examples.
          You need to link with an additional library to get these
          features, \c libGMRFLib-geo.a

	- A couple of (small) memory-leaks are fixed in \c
	  GMRFLib_blockupdate() and \c GMRFLib_init_problem().  These
	  were triggered under special occations. [Thanks to Ingelin
	  Steinsland for making us aware of them.]

	- Added example-qinv.c which demonstrate the use of \c
	  GMRFLib_Qinv().	

	- Treat global nodes spesifically in the nested dissection
          reordering, which gives a huge speedup for such cases.
	  
	- Bugfix in \c GMRFLib_doit_hidden_i(). The bug was triggered
	  under special occations. [Thanks to Sara Martino for making
	  us aware of this problem.]

	- Added function \c GMRFLib_xQx().

Version 2.0-1

	- Added functions to compute certain elements of the inverse
          of the precision matrix, in particular the marginal
          variance. Refer to \ref GMRFLib_Qinv and \ref
          GMRFLib_Qinv_get. (These functions are only available for
          the TAUCS solver, which is default.)

Version 2.0
	
	- initial version

	



*/

/*! \page options Some further options

The file globals.c define some global constants, which you
can change in your programs. Refer to \ref globals.c

*/
