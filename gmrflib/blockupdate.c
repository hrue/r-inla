
/* blockupdate.c
 * 
 * Copyright (C) 2001-2008 Havard Rue
 * 
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or (at
 * your option) any later version.
 * 
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
 *
 * The author's contact information:
 *
 *        Haavard Rue
 *        CEMSE Division
 *        King Abdullah University of Science and Technology
 *        Thuwal 23955-6900, Saudi Arabia
 *        Email: haavard.rue@kaust.edu.sa
 *        Office: +966 (0)12 808 0640
 *
 */

/*!
  \file blockupdate.c
  \brief The block-sampling algorithm implements Markov Chain Monte Carlo (MCMC)-updating of a GMRF
  <em>\b x</em> and it's hyper-parameters \f$ \mbox{\boldmath $\theta$} \f$ jointly in one block.
  
  The joint distribution of <em>\b x</em> and \f$ \mbox{\boldmath $\theta$} \f$, possibly
  conditioning on data, is supposed to be of the general form <b>(GMRF-30)</b> in \ref block

  The block-update routine \c GMRFLib_blockupdate() returns a sample <em>\b x'</em> from a Gaussian
  random field, conditional on a sample \f$ \mbox{\boldmath $\theta$}^{'} \f$ of the
  hyper-parameters \f$ \mbox{\boldmath $\theta$} \f$. The sample might be conditional on fixed
  values or on a linear deterministic or stochastic constraint; what method to use is specified in
  the same way as for \c GMRFLib_sample().

  The routine also computes the part of log acceptance probability corresponding to the update of
  <em>\b x</em>.  The acceptance probability of the step \f$ (\mbox{\boldmath $x,\theta$})
  \rightarrow (\mbox{\boldmath $x^{'},\theta^{'}$}) \f$, given the data <em>\b y</em>, is given by
  min{1,R}, where

  \f[ R \;=\; \frac{\pi(\mbox{\boldmath $x^{'},\theta^{'}\mid y$})} {\pi(\mbox{\boldmath
    $x,\theta\mid y$})} \times \frac{q(\mbox{\boldmath $x^{'}$} \rightarrow \mbox{\boldmath $x$}
    \mid \mbox{\boldmath $\theta$})\; q(\mbox{\boldmath $\theta^{'}$}\rightarrow \mbox{\boldmath
    $\theta$})} {q(\mbox{\boldmath $x$} \rightarrow \mbox{\boldmath $x$}^{'} \mid \mbox{\boldmath
    $\theta$}^{'})\; q(\mbox{\boldmath $\theta$}\rightarrow \mbox{\boldmath $\theta$}^{'})} \;=\;
    \frac{\pi(\mbox{\boldmath $y$}\mid\mbox{\boldmath $x$}^{'}, \mbox{\boldmath $\theta$}^{'})
    \pi(\mbox{\boldmath $x$}^{'} \mid \mbox{\boldmath $\theta$}^{'})} {\pi(\mbox{\boldmath $y$} \mid
    \mbox{\boldmath $x$}, \mbox{\boldmath $\theta$}) \pi(\mbox{\boldmath $x$} \mid \mbox{\boldmath
    $\theta$})} \frac{q(\mbox{\boldmath $x$}^{'} \rightarrow \mbox{\boldmath $x$} \mid
    \mbox{\boldmath $\theta$})}{q(\mbox{\boldmath $x$} \rightarrow \mbox{\boldmath $x$}^{'} \mid
    \mbox{\boldmath $\theta$}^{'})} \times \frac{\pi(\mbox{\boldmath
    $\theta$}^{'})}{\pi(\mbox{\boldmath $\theta$})} \frac{q(\mbox{\boldmath
    $\theta$}^{'}\rightarrow\mbox{\boldmath $\theta$})} {q(\mbox{\boldmath
    $\theta$}\rightarrow\mbox{\boldmath $\theta$}^{'})} \;=\;R_x \times R_{\theta} \f]

    The contribution computed by \c GMRFLib_blockupdate() is \f$ \log(R_x) \f$ EXCEPT FOR the log
    ratio of the normalizing constant of the prior \f$ \pi(\mbox{\boldmath $x$} \mid \mbox{\boldmath
    $\theta$}) \f$ of <em>\b x</em>, evaluated in \f$ \mbox{\boldmath $\theta$}^{'} \f$ and \f$
    \mbox{\boldmath $\theta$} \f$.  The normalizing constant might depend on the unknown
    hyper-parameters to be updated, and thus has to be taken into account.  The log-ratio of the
    normalizing constants, as well as the value \f$ \log(R_{\theta}) \f$, which is the contribution
    from the update of the hyper-parameters, have to be added explicitly in the application program.

    To summarize, a joint update of (\f$ \mbox{\boldmath $x,\theta$} \f$), with prior distribution
    \f$ \pi(\mbox{\boldmath $x$}\mid \mbox{\boldmath $\theta$})\pi(\mbox{\boldmath $\theta$}) \f$ is
    generated by running trough the following steps

    - Generate a proposal \f$ \mbox{\boldmath $\theta$}^{'} \f$ from \f$ q(\mbox{\boldmath
    $\theta$}\rightarrow \mbox{\boldmath $\theta$}^{'}) \f$.
    - Using \c GMRFLib_blockupdate(), generate a proposed value <em>\b x'</em> from \f$
    q(\mbox{\boldmath $x$}\rightarrow \mbox{\boldmath $x$}^{'}\mid \mbox{\boldmath $\theta$}^{'}) =
    \tilde{\pi}(\mbox{\boldmath $x$} \mid \mbox{\boldmath $\theta$}^{'},\mbox{\boldmath $y$}) \f$,
    where \f$ \tilde{\pi} \f$ is the Gaussian approximation to the posterior \f$ \pi(\mbox{\boldmath
    $x$}\mid \mbox{\boldmath $\theta$}^{'},\mbox{\boldmath $y$}) \f$.  From the routine, the
    contribution to the log acceptance rate from the unnormalized prior and the proposal distribution
    for <em>\b x</em> is also obtained.
    - Add the log-ratio of the normalization constants of the prior of the GMRF and the log ratios of
    the prior and proposal distribution of \f$ \mbox{\boldmath $\theta$} \f$ to the log acceptance
    rate.
    - Accept or reject the joint proposal (\f$ \mbox{\boldmath $x$}^{'},\mbox{\boldmath $\theta$}^{'}
    \f$).
    
    \par Example
    See \ref ex_blockupdate
*/

#ifndef HGVERSION
#define HGVERSION
#endif
static const char RCSId[] = "file: " __FILE__ "  " HGVERSION;

/* Pre-hg-Id: $Id: blockupdate.c,v 1.76 2009/08/26 06:12:46 hrue Exp $ */

#include <stdio.h>
#include <assert.h>
#include <math.h>
#include <string.h>
#if !defined(__FreeBSD__)
#include <malloc.h>
#endif

#include <stdlib.h>

#include "GMRFLib/GMRFLib.h"
#include "GMRFLib/GMRFLibP.h"

/*!

  \brief Create a \c GMRFLib_blockupdate_param_tp -object holding the default values.  \param[out]
  blockupdate_par A pointer to a \c GMRFLib_blockupdate_param_tp pointer.  At output the \c
  GMRFLib_blockupdate_param_tp -object contains the default values.

  \par Description of elements in \c GMRFLib_blockupdate_param_tp -object:
  \n \em modeoption: Mode or current value \n
  If #GMRFLib_MODEOPTION_MODE, the mode of the posterior distribution is 
  estimated and the expansion is done around the mode. \n
  If #GMRFLib_MODEOPTION_CURRENT, the expansion is done around the current 
  value of <em>\b x</em>. \n
  0 = mode, 1 = current \n
  <b>Default value: 0 </b> \n\n
  \em *fp: To display calculations \n
  If \c !NULL, the file on which to print calculated likelihood values 
  and acceptance rates. If \c NULL, no values are printed. \n
  <b>Default value: \c NULL  </b> \n\n
  \em step_len: Step-length to compute the taylor-expantions \n
  Step length in the computation of a Taylor expansion or second order 
  approximation of the log-likelihood around a point <em>\b x_0</em>. \n
  <b>Default value: 1.0e-4 </b> \n
*/
int GMRFLib_default_blockupdate_param(GMRFLib_blockupdate_param_tp ** blockupdate_par)
{
	GMRFLib_ASSERT(blockupdate_par, GMRFLib_EINVARG);

	*blockupdate_par = Calloc(1, GMRFLib_blockupdate_param_tp);
	(*blockupdate_par)->modeoption = GMRFLib_MODEOPTION_MODE;
	(*blockupdate_par)->fp = NULL;
	(*blockupdate_par)->step_len = GMRFLib_eps(0.25);
	(*blockupdate_par)->stencil = 5;

	return GMRFLib_SUCCESS;
}

/*!

  \brief Generate a blockproposal using a GMRF-approximation for a GMRF conditioned on (possible) non-Gaussian observations.

  \param[out] laccept The log of the acceptance rate of the proposed (new) value of <em>\b x</em>, returned by \a x_new.
  \param[out] x_new The proposed values of <em>\b x</em>, denoted by <em>\b x'</em>.

  \param[in] x_old The current (old) update of <em>\b x</em>.

  \param[in] b_new The value of <em>\b b</em> in <b>(GMRF-30)</b> in \ref block, based on proposed values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$.  If \c NULL, <em>\b b</em> is assumed to be 0.

  \param[in] b_old The value of <em>\b b</em> in <b>(GMRF-30)</b> in \ref block, based on current (old) values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$} \f$.  If \c NULL, <em>\b b</em> is assumed to be 0.

  \param[in] c_new The value of <em>\b c</em> in <b>(GMRF-30)</b> in \ref block, based on proposed values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$.  If \c NULL, <em>\b c</em> is assumed to be 0.

  \param[in] c_old The value of <em>\b c</em> in <b>(GMRF-30)</b> in based on current (old) values of the hyper-parameters, \f$
  \mbox{\boldmath $\theta$} \f$. If \c NULL, <em>\b c</em> is assumed to be 0.

  \param[in] mean_new The value of \f$ \mbox{\boldmath $\mu$} \f$ in <b>(GMRF-30)</b> in \ref block, based on proposed values of
  the hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$. If \c NULL, \f$ \mbox{\boldmath $\mu$} \f$ is assumed to be 0.

  \param[in] mean_old The value of \f$ \mbox{\boldmath $\mu$} \f$ in <b>(GMRF-30)</b> in \ref block, based on current (old)
  values of the hyper-parameters, \f$ \mbox{\boldmath $\theta$} \f$. If \c NULL, \f$ \mbox{\boldmath $\mu$} \f$ is assumed to be
  0.

  \param[in] d_new The value of <em>\b d</em> in <b>(GMRF-30)</b> in \ref block, based on proposed values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$. If \c NULL, <em>\b d</em> is assumed to be 0 and no optimizing is
  done (or needed).

  \param[in] d_old The value of <em>\b d</em> in <b>(GMRF-30)</b> in \ref block, based on current (old) values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$} \f$. If \c NULL, <em>\b d</em> is assumed to be 0 and no optimizing is done
  (or needed).

  \param[in] loglFunc_new A function of type \c GMRFLib_logl_tp(), returning the value of the function \f$ f(x_i) \f$ in
  <b>(GMRF-30)</b> in \ref block, in many applications equal to the log-likelihood of the problem. If the function \f$ f(x_i)
  \f$ depends on unknown hyper-parameters, this function uses the proposed values \f$ \mbox{\boldmath $\theta$}^{'} \f$.

  \param[in] loglFunc_arg_new A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a loglFunc_new.

  \param[in] loglFunc_old A function of type \c GMRFLib_logl_tp(), returning the value of the function \f$ f(x_i) \f$ in
  <b>(GMRF-30)</b> in \ref block, in many applications equal to the log-likelihood of the problem. If the function \f$ f(x_i)
  \f$ depends on unknown hyper-parameters, this function uses the current values \f$ \mbox{\boldmath $\theta$} \f$, if not, this
  function should be equal to \a loglFunc_new.

  \param[in] loglFunc_arg_old A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a loglFunc_old.

  \param[in] fixed_value If \c !NULL, the block-sampling of <em>\b x</em> is done conditionally on fixed values.  The elements
  of this array, of length \c graph->n, should take the value 0 or 1. The conditional mean and covariance matrix of \f$
  \{x_i:\mbox{\small\tt fixed\_value}[i]=0\} \f$ given \f$ \{x_i:\mbox{\small\tt fixed\_value}[i]=1\} \f$ are computed, and
  elements of the GMRF <em>\b x</em> corresponding to <tt>fixed_value = 1</tt>, are kept fixed at the corresponding values
  specified in the argument \a x_old. It is allowed that all values of <tt>fixed_value</tt> equals 1.

  \param[in] graph The graph on which the GMRF <em>\b x</em> is defined.

  \param[in] Qfunc_new A function of type \c GMRFLib_Qfunc_tp(), computing the values of the precision matrix <em>\b Q</em>. If
  the function depends on unknown hyper-parameters, this function computes the precision matrix as a function of their proposed
  values \f$ \mbox{\boldmath $\theta$}^{'} \f$.

  \param[in] Qfunc_arg_new A \em void pointer holding the address of a variable or data structure defining additional arguments
  to the function \a Qfunc_new.

  \param[in] Qfunc_old A function of type \c GMRFLib_Qfunc_tp(), computing the values of the precision matrix <em>\b Q</em>. If
  the function depends on unknown hyper-parameters, this function computes the precision matrix as a function of their current
  (old) values \f$ \mbox{\boldmath $\theta$} \f$. If not, this function should be equal to \a Qfunc_new.

  \param[in] Qfunc_arg_old A \em void pointer holding the address of a variable or data structure defining additional arguments
  to the function \a Qfunc_old.

  \param[in] Qfunc_old2new This function implements the <em>\b Q</em>-matrix used when proposing a new value <em>\b x'</em>
  given the current value <em>\b x</em>. It is needed only in cases where the precision matrix depends on unknown
  hyper-parameters, and is different from the matrix \a Qfunc_new. If \c NULL, \a Qfunc_old2new is set equal to \a Qfunc_new.

  \param[in] Qfunc_arg_old2new A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a Qfunc_old2new.

  \param[in] Qfunc_new2old This function implements the <em>\b Q</em>-matrix for the reverse of the proposal process, going from
  the proposed value <em>\b x'</em> to the the current value <em>\b x</em>. It is needed only in cases where the precision
  matrix depends on unknown hyper-parameters, and is different from the matrix \a Qfunc_old. If \c NULL, \a Qfunc_new2old is set
  equal to \a Qfunc_old.

  \param[in] Qfunc_arg_new2old A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a Qfunc_new2old.

  \param[in] constr_new A pointer to a \c GMRFLib_constr_tp -object holding the information on the type of linear constraint, in
  the case of constrained sampling. If the parameters of the constraint depend on unknown hyper-parameters, \a constr_new should
  define the constraint corresponding to the proposed values \f$ \mbox{\boldmath $\theta$}^{'} \f$.

  \param[in] constr_old A pointer to a \c GMRFLib_constr_tp -object holding the information on the type of linear constraint, in
  the case of constrained sampling. If the parameters of the constraint depend on unknown hyper-parameters, \a constr_old should
  define the constraint corresponding to the current values \f$ \mbox{\boldmath $\theta$} \f$. If the constraint does not depend
  on the hyper-parameters, \a constr_old and \a constr_new should be equal.

  \param[in] optpar The options to the optimizer. If \c NULL, default options are used.

  \param[in] blockupdate_par Some specifications for the block-sampler, as a \c GMRFLib_blockupdate_param_tp -object.
  
  \remarks All parameters in <b>(GMRF-30)</b> in \ref block might depend on unknown hyper-parameters \f$ \mbox{\boldmath
  $\theta$} \f$, such that \f$ \mbox{\boldmath $b=b(\theta)$} \f$ and so on. These hyper-parameters are also to be updated by
  the MCMC algorithm, and the contributions to the acceptance rate from these parameters are to be added to \a laccept after
  invoking GMRFLib_blockupdate(). If the parameters in <b>(GMRF-30)</b> in \ref block, depend on \f$ \mbox{\boldmath $\theta$}
  \f$, two sets of parameters have to be provided, one depending on the current (old) value of \f$ \mbox{\boldmath $\theta$}
  \f$, and one depending on the proposed values \f$ \mbox{\boldmath $\theta$}^{'} \f$, that are assumed to be generated prior to
  calling \c GMRFLib_blockupdate(). The two sets of values take subscripts \c new (corresponding to the proposals \f$
  \mbox{\boldmath $\theta$}^{'} \f$) and \c old (corresponding to the current, or old, values \f$ \mbox{\boldmath $\theta$}
  \f$). The same comment applies to the set of function defining the precision matrix <em>\b Q</em>, these functions might also
  depend on hyper-parameters.\n\n For the \em Q-functions, two additional functions are provided. These are needed for
  generating the proposals from the Gaussian proposal distribution in cases where the precision matrix depend on unknown
  hyper-parameters, and the precision matrix of the proposal distribution is different from the precision matrix <em>\b Q</em>
  of the GMRF at input. This might be the case when \f$ \mbox{\boldmath $Q(\theta)$} + \mbox{diag}(\mbox{\boldmath $c$}) \f$ is
  singular. The function \a GMRFLib_Qfunc_old2new is the <em>\b Q</em>-matrix for the distribution generating a proposal <em>\b
  x'</em> given <em>\b x</em>, and \a GMRFLib_Qfunc_new2old is the corresponding function, implementing the <em>\b Q</em>-matrix
  used in the reverse process, going from <em>\b x'</em> to <em>\b x</em>.

  \par Example
  See \ref ex_blockupdate

  \sa GMRFLib_logl_tp
 */
int GMRFLib_blockupdate(double *laccept,
			double *x_new, double *x_old,
			double *b_new, double *b_old,
			double *c_new, double *c_old,
			double *mean_new, double *mean_old,
			double *d_new, double *d_old,
			GMRFLib_logl_tp * loglFunc_new, void *loglFunc_arg_new,
			GMRFLib_logl_tp * loglFunc_old, void *loglFunc_arg_old,
			char *fixed_value,
			GMRFLib_graph_tp * graph,
			GMRFLib_Qfunc_tp * Qfunc_new, void *Qfunc_arg_new,
			GMRFLib_Qfunc_tp * Qfunc_old, void *Qfunc_arg_old,
			GMRFLib_Qfunc_tp * Qfunc_old2new, void *Qfunc_arg_old2new,
			GMRFLib_Qfunc_tp * Qfunc_new2old, void *Qfunc_arg_new2old,
			GMRFLib_constr_tp * constr_new, GMRFLib_constr_tp * constr_old,
			GMRFLib_optimize_param_tp * optpar, GMRFLib_blockupdate_param_tp * blockupdate_par)
{
	GMRFLib_ENTER_ROUTINE;
	GMRFLib_EWRAP1(GMRFLib_blockupdate_store
		       (laccept, x_new, x_old, b_new, b_old, c_new, c_old, mean_new, mean_old, d_new, d_old, loglFunc_new,
			loglFunc_arg_new, loglFunc_old, loglFunc_arg_old, fixed_value, graph, Qfunc_new, Qfunc_arg_new,
			Qfunc_old, Qfunc_arg_old, Qfunc_old2new, Qfunc_arg_old2new, Qfunc_new2old, Qfunc_arg_new2old,
			constr_new, constr_old, optpar, blockupdate_par, NULL));
	GMRFLib_LEAVE_ROUTINE;
	return GMRFLib_SUCCESS;
}

/*!

  \brief Generate a blockproposal using a GMRF-approximation for a GMRF conditioned on (possible) non-Gaussian observations
  storing and reusing computations for increased speed.
  
  
  This function is the same as \c GMRFLib_blockupdate() except an additional argument which holds computations that can be
  resused.
  
  \param[out] laccept The log of the acceptance rate of the proposed (new) value of <em>\b x</em>, returned by \a x_new.
  \param[out] x_new The proposed values of <em>\b x</em>, denoted by <em>\b x'</em>.

  \param[in] x_old The current (old) update of <em>\b x</em>.

  \param[in] b_new The value of <em>\b b</em> in <b>(GMRF-30)</b> in \ref block, based on proposed values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$.  If \c NULL, <em>\b b</em> is assumed to be 0.

  \param[in] b_old The value of <em>\b b</em> in <b>(GMRF-30)</b> in \ref block, based on current (old) values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$} \f$.  If \c NULL, <em>\b b</em> is assumed to be 0.

  \param[in] c_new The value of <em>\b c</em> in <b>(GMRF-30)</b> in \ref block, based on proposed values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$.  If \c NULL, <em>\b c</em> is assumed to be 0.

  \param[in] c_old The value of <em>\b c</em> in <b>(GMRF-30)</b> in based on current (old) values of the hyper-parameters, \f$
  \mbox{\boldmath $\theta$} \f$. If \c NULL, <em>\b c</em> is assumed to be 0.

  \param[in] mean_new The value of \f$ \mbox{\boldmath $\mu$} \f$ in <b>(GMRF-30)</b> in \ref block, based on proposed values of
  the hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$. If \c NULL, \f$ \mbox{\boldmath $\mu$} \f$ is assumed to be 0.

  \param[in] mean_old The value of \f$ \mbox{\boldmath $\mu$} \f$ in <b>(GMRF-30)</b> in \ref block, based on current (old)
  values of the hyper-parameters, \f$ \mbox{\boldmath $\theta$} \f$. If \c NULL, \f$ \mbox{\boldmath $\mu$} \f$ is assumed to be
  0.

  \param[in] d_new The value of <em>\b d</em> in <b>(GMRF-30)</b> in \ref block, based on proposed values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$}^{'} \f$. If \c NULL, <em>\b d</em> is assumed to be 0 and no optimizing is
  done (or needed).

  \param[in] d_old The value of <em>\b d</em> in <b>(GMRF-30)</b> in \ref block, based on current (old) values of the
  hyper-parameters, \f$ \mbox{\boldmath $\theta$} \f$. If \c NULL, <em>\b d</em> is assumed to be 0 and no optimizing is done
  (or needed).

  \param[in] loglFunc_new A function of type \c GMRFLib_logl_tp(), returning the value of the function \f$ f(x_i) \f$ in
  <b>(GMRF-30)</b> in \ref block, in many applications equal to the log-likelihood of the problem. If the function \f$ f(x_i)
  \f$ depends on unknown hyper-parameters, this function uses the proposed values \f$ \mbox{\boldmath $\theta$}^{'} \f$.

  \param[in] loglFunc_arg_new A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a loglFunc_new.

  \param[in] loglFunc_old A function of type \c GMRFLib_logl_tp(), returning the value of the function \f$ f(x_i) \f$ in
  <b>(GMRF-30)</b> in \ref block, in many applications equal to the log-likelihood of the problem. If the function \f$ f(x_i)
  \f$ depends on unknown hyper-parameters, this function uses the current values \f$ \mbox{\boldmath $\theta$} \f$, if not, this
  function should be equal to \a loglFunc_new.

  \param[in] loglFunc_arg_old A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a loglFunc_old.

  \param[in] fixed_value If \c !NULL, the block-sampling of <em>\b x</em> is done conditionally on fixed values.  The elements
  of this array, of length \c graph->n, should take the value 0 or 1. The conditional mean and covariance matrix of \f$
  \{x_i:\mbox{\small\tt fixed\_value}[i]=0\} \f$ given \f$ \{x_i:\mbox{\small\tt fixed\_value}[i]=1\} \f$ are computed, and
  elements of the GMRF <em>\b x</em> corresponding to <tt>fixed_value = 1</tt>, are kept fixed at the corresponding values
  specified in the argument \a x_old. It is allowed that all values of <tt>fixed_value</tt> equals 1.

  \param[in] graph The graph on which the GMRF <em>\b x</em> is defined.

  \param[in] Qfunc_new A function of type \c GMRFLib_Qfunc_tp(), computing the values of the precision matrix <em>\b Q</em>. If
  the function depends on unknown hyper-parameters, this function computes the precision matrix as a function of their proposed
  values \f$ \mbox{\boldmath $\theta$}^{'} \f$.

  \param[in] Qfunc_arg_new A \em void pointer holding the address of a variable or data structure defining additional arguments
  to the function \a Qfunc_new.

  \param[in] Qfunc_old A function of type \c GMRFLib_Qfunc_tp(), computing the values of the precision matrix <em>\b Q</em>. If
  the function depends on unknown hyper-parameters, this function computes the precision matrix as a function of their current
  (old) values \f$ \mbox{\boldmath $\theta$} \f$. If not, this function should be equal to \a Qfunc_new.

  \param[in] Qfunc_arg_old A \em void pointer holding the address of a variable or data structure defining additional arguments
  to the function \a Qfunc_old.

  \param[in] Qfunc_old2new This function implements the <em>\b Q</em>-matrix used when proposing a new value <em>\b x'</em>
  given the current value <em>\b x</em>. It is needed only in cases where the precision matrix depends on unknown
  hyper-parameters, and is different from the matrix \a Qfunc_new. If \c NULL, \a Qfunc_old2new is set equal to \a Qfunc_new.

  \param[in] Qfunc_arg_old2new A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a Qfunc_old2new.

  \param[in] Qfunc_new2old This function implements the <em>\b Q</em>-matrix for the reverse of the proposal process, going from
  the proposed value <em>\b x'</em> to the the current value <em>\b x</em>. It is needed only in cases where the precision
  matrix depends on unknown hyper-parameters, and is different from the matrix \a Qfunc_old. If \c NULL, \a Qfunc_new2old is set
  equal to \a Qfunc_old.

  \param[in] Qfunc_arg_new2old A \em void pointer holding the address of a variable or data structure defining additional
  arguments to the function \a Qfunc_new2old.

  \param[in] constr_new A pointer to a \c GMRFLib_constr_tp -object holding the information on the type of linear constraint, in
  the case of constrained sampling. If the parameters of the constraint depend on unknown hyper-parameters, \a constr_new should
  define the constraint corresponding to the proposed values \f$ \mbox{\boldmath $\theta$}^{'} \f$.

  \param[in] constr_old A pointer to a \c GMRFLib_constr_tp -object holding the information on the type of linear constraint, in
  the case of constrained sampling. If the parameters of the constraint depend on unknown hyper-parameters, \a constr_old should
  define the constraint corresponding to the current values \f$ \mbox{\boldmath $\theta$} \f$. If the constraint does not depend
  on the hyper-parameters, \a constr_old and \a constr_new should be equal.

  \param[in] optpar The options to the optimizer. If \c NULL, default options are used.

  \param[in] blockupdate_par Some specifications for the block-sampler, as a \c GMRFLib_blockupdate_param_tp -object.

  \param[in,out] store A pointer to a \c GMRFLib_store_tp object for which temporary calculations will be stored and retrieved
  to increase the speed compared to the \c GMRFLib_blockupdate() routine.
  
  
  \remarks All parameters in <b>(GMRF-30)</b> in \ref block might depend on unknown hyper-parameters \f$ \mbox{\boldmath
  $\theta$} \f$, such that \f$ \mbox{\boldmath $b=b(\theta)$} \f$ and so on. These hyper-parameters are also to be updated by
  the MCMC algorithm, and the contributions to the acceptance rate from these parameters are to be added to \a laccept after
  invoking GMRFLib_blockupdate(). If the parameters in <b>(GMRF-30)</b> in \ref block, depend on \f$ \mbox{\boldmath $\theta$}
  \f$, two sets of parameters have to be provided, one depending on the current (old) value of \f$ \mbox{\boldmath $\theta$}
  \f$, and one depending on the proposed values \f$ \mbox{\boldmath $\theta$}^{'} \f$, that are assumed to be generated prior to
  calling GMRFLib_blockupdate(). The two sets of values take subscripts \c new (corresponding to the proposals \f$
  \mbox{\boldmath $\theta$}^{'} \f$) and \c old (corresponding to the current, or old, values \f$ \mbox{\boldmath $\theta$}
  \f$). The same comment applies to the set of function defining the precision matrix <em>\b Q</em>, these functions might also
  depend on hyper-parameters.\n\n For the \em Q-functions, two additional functions are provided. These are needed for
  generating the proposals from the Gaussian proposal distribution in cases where the precision matrix depend on unknown
  hyper-parameters, and the precision matrix of the proposal distribution is different from the precision matrix <em>\b Q</em>
  of the GMRF at input. This might be the case when \f$ \mbox{\boldmath $Q(\theta)$} + \mbox{diag}(\mbox{\boldmath $c$}) \f$ is
  singular. The function \a GMRFLib_Qfunc_old2new is the <em>\b Q</em>-matrix for the distribution generating a proposal <em>\b
  x'</em> given <em>\b x</em>, and \a GMRFLib_Qfunc_new2old is the corresponding function, implementing the <em>\b Q</em>-matrix
  used in the reverse process, going from <em>\b x'</em> to <em>\b x</em>.

  \sa GMRFLib_blockupdate(), GMRFLib_free_store()
  
  This function provide a tool for reusing calculations when \c GMRFLib_blockupdate() is used repeatedly on the same problem,
  over and over again. The gain is a significant increase in speed.

  Calculations can be reused at two levels, depending on the setting which this is used.

  - The first level reuse the reordering, the sub_graph and the symbolic factorization of the precision matrix. This is the
    default option.

  - The second level, also reuse \c GMRFLib_problem_tp objects computed. This is possible for some, but not all, cases where \c
    GMRFLib_blockupdate_store() can be used. This level must be activated by the user by setting \c store->store_problems to 1
    or #GMRFLib_TRUE. Further, information if the proposal was accepted or rejected must be provided, setting \c store->decision
    to #GMRFLib_STORE_ACCEPT or #GMRFLib_STORE_REJECT.

  The following example will illustrate the use.
    
  \par Example:
  
  This is the third example from Appendix 2 in the GMRF-book, analysing the simple Tokyo rainfall data.
  
  \verbinclude doxygen-example-3.txt
  
  The changes to use \c store at level 1 is simple.
  
  \verbinclude doxygen-example-3-level-1.txt
  
  Going to level 2 require a little bit more, first it must be activated, then also the information
  about the decision must be given. Be aware the assuptions needed for level 2 to give correct
  results. If unsure, then check either with level 1 or no store, the result should be the same.
  
  \verbinclude doxygen-example-3-level-2.txt

*/
int GMRFLib_blockupdate_store(double *laccept,
			      double *x_new, double *x_old,
			      double *b_new, double *b_old,
			      double *c_new, double *c_old,
			      double *mean_new, double *mean_old,
			      double *d_new, double *d_old,
			      GMRFLib_logl_tp * loglFunc_new, void *loglFunc_arg_new,
			      GMRFLib_logl_tp * loglFunc_old, void *loglFunc_arg_old,
			      char *fixed_value,
			      GMRFLib_graph_tp * graph,
			      GMRFLib_Qfunc_tp * Qfunc_new, void *Qfunc_arg_new,
			      GMRFLib_Qfunc_tp * Qfunc_old, void *Qfunc_arg_old,
			      GMRFLib_Qfunc_tp * Qfunc_old2new, void *Qfunc_arg_old2new,
			      GMRFLib_Qfunc_tp * Qfunc_new2old, void *Qfunc_arg_new2old,
			      GMRFLib_constr_tp * constr_new, GMRFLib_constr_tp * constr_old,
			      GMRFLib_optimize_param_tp * optpar, GMRFLib_blockupdate_param_tp * blockupdate_par, GMRFLib_store_tp * store)
{
	/*
	 * do a blockupdate, and return the proposed new state in 'x' and the corresponding log-acceptrate in 'laccept'
	 * 
	 * the density is
	 * 
	 * exp[ -1/2 (x-mean)'(Q+diag(c))(x-mean) + b'x + \sum d_i f(x_i) ]
	 * 
	 * where values are fixed if fixed_value[i] are true, and where a constraint, Ax=b can be spesified in 'constr' with
	 * optional noise
	 * 
	 * it's now ok that all values in fixed are 1, then none are updated, just the acceptrate is computed.
	 * 
	 */

	int n, i, free_block, id;
	double *mode = NULL, *bb = NULL, *cc = NULL, old2new, new2old, old, neww, *xx = NULL, *yy = NULL, logll;
	GMRFLib_problem_tp *problem = NULL;
	GMRFLib_blockupdate_param_tp *blockpar = NULL;

	GMRFLib_ASSERT(laccept, GMRFLib_EINVARG);
	GMRFLib_ASSERT(x_new, GMRFLib_EINVARG);
	GMRFLib_ASSERT(graph, GMRFLib_EINVARG);
	GMRFLib_ASSERT(Qfunc_new, GMRFLib_EINVARG);
	GMRFLib_ASSERT(Qfunc_old, GMRFLib_EINVARG);

	GMRFLib_ENTER_ROUTINE;

	id = GMRFLib_thread_id;

	if (constr_new) {
		GMRFLib_prepare_constr(constr_new, graph, 0);  /* no scaleing */
	}
	if (constr_old) {
		GMRFLib_prepare_constr(constr_old, graph, 0);  /* no scaleing */
	}

	/*
	 * use default choices if these are not specified. 
	 */
	if (!Qfunc_old2new) {
		Qfunc_old2new = Qfunc_new;
		if (!Qfunc_arg_old2new) {
			Qfunc_arg_old2new = Qfunc_arg_new;
		}
	}
	if (!Qfunc_new2old) {
		Qfunc_new2old = Qfunc_old;
		if (!Qfunc_arg_new2old) {
			Qfunc_arg_new2old = Qfunc_arg_old;
		}
	}

	if (blockupdate_par) {
		blockpar = blockupdate_par;
		free_block = 0;
	} else {
		GMRFLib_default_blockupdate_param(&blockpar);
		free_block = 1;
	}

	n = graph->n;
	mode = Calloc(n, double);
	xx = bb = Calloc(n, double);			       /* two names for the same storage */
	yy = cc = Calloc(n, double);			       /* two names for the same storage */

	/*
	 * fix storage accoring to reject or accept if use_more is ON 
	 */
	if (store && store->store_problems) {
		if (store->fixed_hyperparameters) {
			/*
			 * This is feature experimental for the moment. if the hyperparameters are the same, then keep both
			 * problems. by def, they are the same 
			 */
			if (store->decision == GMRFLib_STORE_ACCEPT) {
				if (store->old_logdens && store->new_logdens) {
					*(store->old_logdens) = *(store->new_logdens);
				}
			}
			if (store->decision == GMRFLib_STORE_REJECT) {
				/*
				 * nothing for the moment 
				 */
			}
		} else {
			if (store->decision == GMRFLib_STORE_ACCEPT) {
				if (store->problem_new2old)
					GMRFLib_free_problem(store->problem_new2old);
				store->problem_new2old = store->problem_old2new;
				store->problem_old2new = NULL;

				if (store->old_logdens && store->new_logdens) {
					*(store->old_logdens) = *(store->new_logdens);
				}
			}
			if (store->decision == GMRFLib_STORE_REJECT) {
				if (store->problem_old2new) {
					GMRFLib_free_problem(store->problem_old2new);
				}
				store->problem_old2new = NULL;
			}
		}
	}

	if (store && store->store_problems && store->fixed_hyperparameters && store->problem_old2new) {
		/*
		 * use copy 
		 */
		problem = store->problem_old2new;
	} else {
		/*
		 * first, find the point to expand around
		 * 
		 * note that i use Qfunc_old2new if we have constraints as the Qfunc_new can then be singular!
		 * 
		 * this step is always performed, not matter store->use_more 
		 */
		memcpy(mode, x_old, n * sizeof(double));
		if (blockpar->modeoption == GMRFLib_MODEOPTION_MODE && d_new) {
			GMRFLib_EWRAP1(GMRFLib_optimize_store(mode, b_new, c_new, mean_new, graph,
							      (constr_new ? Qfunc_old2new : Qfunc_new),
							      (constr_new ? Qfunc_arg_old2new : Qfunc_arg_new),
							      fixed_value, constr_new, d_new, loglFunc_new, loglFunc_arg_new, optpar, store));
		}

		/*
		 * compute the terms from loglFunc 
		 */
		if (d_new) {
#pragma omp parallel for private(i)
			for (i = 0; i < n; i++) {
				GMRFLib_thread_id = id;
				if (d_new[i] && (!fixed_value || !fixed_value[i])) {
					GMRFLib_2order_approx(NULL, &bb[i], &cc[i], d_new[i], mode[i], i,
							      mode, loglFunc_new, loglFunc_arg_new, &(blockpar->step_len), &(blockpar->stencil));
					cc[i] = DMAX(0.0, cc[i]);	/* do not want negative terms on the diagonal */
				}
			}
			GMRFLib_thread_id = id;
		}

		/*
		 * add the linear and quadratic term to the general model. note that we need to correct the b-term due to the mean. 
		 */
		if (b_new) {
			if (mean_new) {
				for (i = 0; i < n; i++) {
					bb[i] += b_new[i] - cc[i] * mean_new[i];
				}
			} else {
				for (i = 0; i < n; i++) {
					bb[i] += b_new[i];
				}
			}
		} else {
			if (mean_new) {
				for (i = 0; i < n; i++) {
					bb[i] -= cc[i] * mean_new[i];
				}
			}
		}

		if (c_new) {
			for (i = 0; i < n; i++) {
				cc[i] += c_new[i];
			}
		}

		GMRFLib_EWRAP1(GMRFLib_init_problem_store(&problem, x_old, bb, cc, mean_new, graph,
							  Qfunc_old2new, Qfunc_arg_old2new, fixed_value, constr_new, GMRFLib_NEW_PROBLEM, store));
	}

	if (problem) {
		GMRFLib_EWRAP1(GMRFLib_sample(problem));
		old2new = problem->sub_logdens;
		memcpy(x_new, problem->sample, n * sizeof(double));

		if (store && store->store_problems) {
			store->problem_old2new = problem;
		} else {
			GMRFLib_free_problem(problem);
		}
		problem = NULL;
	} else {
		/*
		 * nothing to do really, just make sure that the x_new equals x_old 
		 */
		old2new = 0.0;
		memcpy(x_new, x_old, n * sizeof(double));
	}

	/*
	 * now, go backwards
	 * 
	 * note: no need to optimize if there is no data.
	 * 
	 * note that i use Qfunc_new2old we have constraints as then the Qfunc_old can be singular! 
	 */

	if (store && store->store_problems && store->problem_new2old) {
		/*
		 * use copy 
		 */
		problem = store->problem_new2old;
	} else {
		memcpy(mode, x_new, n * sizeof(double));
		if (blockpar->modeoption == GMRFLib_MODEOPTION_MODE && d_old) {
			GMRFLib_EWRAP1(GMRFLib_optimize_store(mode, b_old, c_old, mean_old, graph,
							      (constr_old ? Qfunc_new2old : Qfunc_old),
							      (constr_old ? Qfunc_arg_new2old : Qfunc_arg_old),
							      fixed_value, constr_old, d_old, loglFunc_old, loglFunc_arg_old, optpar, store));
		}

		memset(bb, 0, n * sizeof(double));
		memset(cc, 0, n * sizeof(double));
		if (d_old) {
#pragma omp parallel for private(i)
			for (i = 0; i < n; i++) {
				GMRFLib_thread_id = id;
				if (d_old[i] && (!fixed_value || !fixed_value[i])) {
					GMRFLib_2order_approx(NULL, &bb[i], &cc[i], d_old[i], mode[i], i, mode,
							      loglFunc_old, loglFunc_arg_old, &(blockpar->step_len), &(blockpar->stencil));
					cc[i] = DMAX(0.0, cc[i]);	/* do not want negative terms on the diagonal */
				}
			}
			GMRFLib_thread_id = id;
		}

		/*
		 * add the linear and quadratic term to the general model. note that we need to correct the b-term due to the
		 * mean. 
		 */
		if (b_old) {
			if (mean_old) {
				for (i = 0; i < n; i++) {
					bb[i] += b_old[i] - cc[i] * mean_old[i];
				}
			} else {
				for (i = 0; i < n; i++) {
					bb[i] += b_old[i];
				}
			}
		} else {
			if (mean_old) {
				for (i = 0; i < n; i++) {
					bb[i] -= cc[i] * mean_old[i];
				}
			}
		}
		if (c_old) {
			for (i = 0; i < n; i++) {
				cc[i] += c_old[i];
			}
		}

		GMRFLib_EWRAP1(GMRFLib_init_problem_store
			       (&problem, x_new, bb, cc, mean_old, graph, Qfunc_new2old, Qfunc_arg_new2old, fixed_value, constr_old,
				GMRFLib_NEW_PROBLEM, store));
	}

	if (problem) {
		memcpy(problem->sample, x_old, n * sizeof(double));
		GMRFLib_EWRAP1(GMRFLib_evaluate(problem));
		new2old = problem->sub_logdens;

		if (store && store->store_problems) {
			store->problem_new2old = problem;      /* just set it back [this is OK] */
		} else {
			GMRFLib_free_problem(problem);
		}
		problem = NULL;
	} else {
		/*
		 * nothing to do 
		 */
		new2old = 0.0;
	}

	bb = cc = NULL;					       /* not used anymore */

	/*
	 * compute the density at x and x_old.
	 * 
	 * FIXME: here i do not use subgraph, but that require big tests to see if the results would be the same. is it worth
	 * it really? 
	 */

	neww = 0.0;
	if (mean_new) {
		for (i = 0; i < n; i++) {
			xx[i] = x_new[i] - mean_new[i];
		}
	} else {
		memcpy(xx, x_new, n * sizeof(double));
	}
	GMRFLib_Qx(yy, xx, graph, Qfunc_new, Qfunc_arg_new);
	if (c_new) {
		for (i = 0; i < n; i++) {
			neww += yy[i] * xx[i] + c_new[i] * SQR(xx[i]);
		}
	} else {
		for (i = 0; i < n; i++) {
			neww += yy[i] * xx[i];
		}
	}
	neww *= -0.5;
	if (b_new) {
		for (i = 0; i < n; i++) {
			neww += b_new[i] * x_new[i];
		}
	}
	if (d_new) {
		double sum = 0.0;

#pragma omp parallel for private(i) reduction(+: sum)
		for (i = 0; i < n; i++) {
			GMRFLib_thread_id = id;
			if (d_new[i]) {
				loglFunc_new(&logll, &x_new[i], 1, i, x_new, NULL, loglFunc_arg_new);
				sum += d_new[i] * logll;
			}
		}
		GMRFLib_thread_id = id;
		neww += sum;
	}

	if (STOCHASTIC_CONSTR(constr_new)) {
		double sqr_term;

		GMRFLib_EWRAP1(GMRFLib_eval_constr(NULL, &sqr_term, x_new, constr_new, graph));
		neww += -0.5 * sqr_term;
	}

	/*
	 * store the new value 
	 */
	if (store && store->store_problems) {
		if (!(store->new_logdens)) {
			store->new_logdens = Calloc(1, double);
		}
		*(store->new_logdens) = neww;
	}

	if (store && store->store_problems && store->old_logdens) {
		old = *(store->old_logdens);
	} else {
		old = 0.0;
		if (mean_old) {
			for (i = 0; i < n; i++) {
				xx[i] = x_old[i] - mean_old[i];
			}
		} else {
			memcpy(xx, x_old, n * sizeof(double));
		}
		GMRFLib_Qx(yy, xx, graph, Qfunc_old, Qfunc_arg_old);
		if (c_old) {
			for (i = 0; i < n; i++) {
				old += yy[i] * xx[i] + c_old[i] * SQR(xx[i]);
			}
		} else {
			for (i = 0; i < n; i++) {
				old += yy[i] * xx[i];
			}
		}
		old *= -0.5;
		if (b_old) {
			for (i = 0; i < n; i++) {
				old += b_old[i] * x_old[i];
			}
		}
		if (d_old) {
			double sum = 0.0;

#pragma omp parallel for private(i) reduction(+: sum)
			for (i = 0; i < n; i++) {
				GMRFLib_thread_id = id;
				if (d_old[i]) {
					loglFunc_old(&logll, &x_old[i], 1, i, x_old, NULL, loglFunc_arg_old);
					sum += d_old[i] * logll;
				}
			}
			GMRFLib_thread_id = id;
			old += sum;
		}
		if (STOCHASTIC_CONSTR(constr_old)) {
			double sqr_term;

			GMRFLib_EWRAP1(GMRFLib_eval_constr(NULL, &sqr_term, x_old, constr_old, graph));
			old += -0.5 * sqr_term;
		}
	}

	/*
	 * store the old value 
	 */
	if (store && store->store_problems) {
		if (!(store->old_logdens)) {
			store->old_logdens = Calloc(1, double);
		}
		*(store->old_logdens) = old;
	}

	/*
	 * finally.... 
	 */
	*laccept = neww + new2old - (old + old2new);

	if (blockpar->fp) {
		fprintf(blockpar->fp, "\n%s: laccept %f\n", __GMRFLib_FuncName, *laccept);
		fprintf(blockpar->fp, "\tnew_ldens %12.6f\n", neww);
		fprintf(blockpar->fp, "\told_ldens %12.6f\n", old);
		fprintf(blockpar->fp, "\tnew2old   %12.6f\n", new2old);
		fprintf(blockpar->fp, "\told2new   %12.6f\n", old2new);
	}

	Free(xx);
	Free(yy);
	Free(mode);
	if (free_block) {
		Free(blockpar);
	}

	GMRFLib_LEAVE_ROUTINE;
	return GMRFLib_SUCCESS;
}

/*!
  \brief Generate a GMRF-approximation for a GMRF conditioned on (possible) non-Gaussian
  observations.

  \param[out] problem At output, <em>(*problem)</em> is a pointer to a \c GMRFLib_problem_tp
  -object, initialised and defined according to the problem specification.

  \param[in] x The current value of <em>\b x</em>.

  \param[in] b The value of <em>\b b</em> in <b>(GMRF-30)</b> in \ref block. If \c NULL, <em>\b
  b</em> is assumed to be 0.

  \param[in] c The value of <em>\b c</em> in <b>(GMRF-30)</b> in \ref block. If \c NULL, <em>\b
  c</em> is assumed to be 0.

  \param[in] mean The value of \f$ \mbox{\boldmath $\mu$} \f$ in <b>(GMRF-30)</b> in \ref block. If
  \c NULL, \f$ \mbox{\boldmath $\mu$} \f$ is assumed to be 0.

  \param[in] d The value of <em>\b d</em> in <b>(GMRF-30)</b> in \ref block. If \c NULL, <em>\b
  d</em> is assumed to be 0 and no optimizing is done (or needed).

  \param[in] loglFunc A function of type \c GMRFLib_logl_tp(), returning the value of the function
  \f$ f(x_i) \f$ in <b>(GMRF-30)</b> in \ref block, in many applications equal to the log-likelihood
  of the problem.

  \param[in] loglFunc_arg A \em void pointer holding the address of a variable or data
  structure defining additional arguments to the function \a loglFunc.

  \param[in] fixed_value The elements of this array, of length \c graph->n, should take the value 0
  or 1. The conditional mean and covariance matrix of \f$ \{x_i:\mbox{\small\tt fixed\_value}[i]=0\}
  \f$ given \f$ \{x_i:\mbox{\small\tt fixed\_value}[i]=1\} \f$ are computed, and elements of the
  GMRF <em>\b x</em> corresponding to <tt>fixed_value = 1</tt>, are kept fixed at the corresponding
  values specified in the argument \a x. It is allowed that all values of <tt>fixed_value</tt>
  equals 1.

  \param[in] graph The graph on which the GMRF <em>\b x</em> is defined.

  \param[in] Qfunc A function of type \c GMRFLib_Qfunc_tp(), computing the values of the
  precision matrix <em>\b Q</em>. 

  \param[in] Qfunc_arg A \em void pointer holding the address of a variable or data structure
  defining additional arguments to the function \a Qfunc.

  \param[in] constr A pointer to a \c GMRFLib_constr_tp -object holding the information on the type
  of linear constraint, in the case of constrained sampling.

  \param[in] optpar The options to the optimizer. If \c NULL, default options are used.

  \param[in] blockupdate_par Some specifications for the block-sampler, as a \c
  GMRFLib_blockupdate_param_tp -object.
  
  \sa GMRFLib_blockupdate, GMRFLib_init_problem, GMRFLib_sample, GMRFLib_evaluate
*/
int GMRFLib_init_GMRF_approximation(GMRFLib_problem_tp ** problem, double *x, double *b, double *c, double *mean, double *d,
				    GMRFLib_logl_tp * loglFunc, void *loglFunc_arg,
				    char *fixed_value, GMRFLib_graph_tp * graph, GMRFLib_Qfunc_tp * Qfunc, void *Qfunc_arg,
				    GMRFLib_constr_tp * constr, GMRFLib_optimize_param_tp * optpar, GMRFLib_blockupdate_param_tp * blockupdate_par)
{
	GMRFLib_ENTER_ROUTINE;
	GMRFLib_EWRAP1(GMRFLib_init_GMRF_approximation_store(problem, x, b, c, mean, d, loglFunc, loglFunc_arg, fixed_value,
							     graph, Qfunc, Qfunc_arg, constr, optpar, blockupdate_par, NULL));
	GMRFLib_LEAVE_ROUTINE;
	return GMRFLib_SUCCESS;
}
int GMRFLib_init_GMRF_approximation_store(GMRFLib_problem_tp ** problem, double *x, double *b, double *c, double *mean,
					  double *d, GMRFLib_logl_tp * loglFunc, void *loglFunc_arg, char *fixed_value,
					  GMRFLib_graph_tp * graph, GMRFLib_Qfunc_tp * Qfunc, void *Qfunc_arg,
					  GMRFLib_constr_tp * constr, GMRFLib_optimize_param_tp * optpar,
					  GMRFLib_blockupdate_param_tp * blockupdate_par, GMRFLib_store_tp * store)
{
	int i, j, free_x = 0, free_b = 0, free_c = 0, free_mean = 0, free_d = 0, free_blockpar = 0, n, id;
	double *bb = NULL, *cc = NULL, *mode = NULL;

#define FREE_ALL if (1) { if (free_x) Free(x); if (free_b) Free(b); if (free_c) Free(c); if (free_d) Free(d); \
	if (free_mean) Free(mean); if (free_blockpar) Free(blockupdate_par); Free(bb); Free(cc); Free(mode);}

	id = GMRFLib_thread_id;
	GMRFLib_ASSERT(problem, GMRFLib_EINVARG);
	GMRFLib_ASSERT(graph, GMRFLib_EINVARG);
	GMRFLib_ASSERT(Qfunc, GMRFLib_EINVARG);
	GMRFLib_ENTER_ROUTINE;

	n = graph->n;
	if (n == 0) {
		*problem = NULL;
		GMRFLib_LEAVE_ROUTINE;
		return GMRFLib_SUCCESS;
	}

	if (!x) {
		free_x = 1;
		x = Calloc(n, double);
	}
	if (!b) {
		free_b = 1;
		b = Calloc(n, double);
	}
	if (!c) {
		free_c = 1;
		c = Calloc(n, double);
	}
	if (!d) {
		free_d = 1;
		d = Calloc(n, double);
	}
	if (!mean) {
		free_mean = 1;
		mean = Calloc(n, double);
	}

	bb = Calloc(n, double);
	cc = Calloc(n, double);
	mode = Calloc(n, double);

	if (!blockupdate_par) {
		GMRFLib_default_blockupdate_param(&blockupdate_par);
		free_blockpar = 1;
	}

	memcpy(mode, x, n * sizeof(double));
	if (blockupdate_par->modeoption == GMRFLib_MODEOPTION_MODE && d)
		GMRFLib_EWRAP1(GMRFLib_optimize_store
			       (mode, b, c, mean, graph, Qfunc, Qfunc_arg, fixed_value, constr, d, loglFunc, loglFunc_arg, optpar, store));

	if (!fixed_value || !(store && store->sub_graph)) {
		/*
		 * compute the terms from loglFunc 
		 */
		if (d) {
#pragma omp parallel for private(i)
			for (i = 0; i < n; i++) {
				GMRFLib_thread_id = id;
				if (d[i]) {
					GMRFLib_2order_approx(NULL, &bb[i], &cc[i], d[i], mode[i], i, mode, loglFunc, loglFunc_arg,
							      &(blockupdate_par->step_len), &(blockupdate_par->stencil));
					cc[i] = DMAX(0.0, cc[i]);	/* do not want negative terms on the diagonal */
				}
			}
			GMRFLib_thread_id = id;
		}
		if (b) {
			if (mean) {
				for (i = 0; i < n; i++) {
					bb[i] += b[i] - cc[i] * mean[i];
				}
			} else {
				for (i = 0; i < n; i++) {
					bb[i] += b[i];
				}
			}
		} else {
			if (mean) {
				for (i = 0; i < n; i++) {
					bb[i] -= cc[i] * mean[i];
				}
			}
		}
		if (c) {
			for (i = 0; i < n; i++) {
				cc[i] += c[i];
			}
		}
	} else {
		/*
		 * do the same as above, but only for those 'i' which is not fixed. this is faster if we have fixed values and
		 * the sub_graph is available. 
		 */

		int ns = store->sub_graph->n, *mothergraph_idx = store->sub_graph->mothergraph_idx;

#pragma omp parallel for private(i, j)
		for (j = 0; j < ns; j++) {
			GMRFLib_thread_id = id;
			i = mothergraph_idx[j];
			if (d[i]) {
				GMRFLib_2order_approx(NULL, &bb[i], &cc[i], d[i], mode[i], i, mode, loglFunc, loglFunc_arg,
						      &(blockupdate_par->step_len), &(blockupdate_par->stencil));
				cc[i] = DMAX(0.0, cc[i]);      /* do not want negative terms on the diagonal */
			}
		}
		GMRFLib_thread_id = id;

		if (b) {
			if (mean) {
				for (j = 0; j < ns; j++) {
					i = mothergraph_idx[j];
					bb[i] += b[i] - cc[i] * mean[i];
				}
			} else {
				for (j = 0; j < ns; j++) {
					i = mothergraph_idx[j];
					bb[i] += b[i];
				}
			}
		} else {
			if (mean) {
				for (j = 0; j < ns; j++) {
					i = mothergraph_idx[j];
					bb[i] -= cc[i] * mean[i];
				}
			}
		}

		if (c) {
			for (j = 0; j < ns; j++) {
				i = mothergraph_idx[j];
				cc[i] += c[i];
			}
		}
	}

	GMRFLib_EWRAP1(GMRFLib_init_problem_store
		       (problem, x, bb, cc, mean, graph, Qfunc, Qfunc_arg, fixed_value, constr, GMRFLib_NEW_PROBLEM, store));

	FREE_ALL;
	GMRFLib_LEAVE_ROUTINE;

	return GMRFLib_SUCCESS;

#undef FREE_ALL
}
int GMRFLib_2order_taylor(double *a, double *b, double *c, double d, double x0, int indx,
			  double *x_vec, GMRFLib_logl_tp * loglFunc, void *loglFunc_arg, double *step_len, int *stencil)
{
	/*
	 * compute a,b,c in the taylor expansion around x0 of d*loglFunc(x0,...)
	 * 
	 * a + b*(x-x0) + 0.5*c*(x-x0)^2
	 * 
	 */
	double f0, df, ddf;

	if (ISZERO(d)) {
		f0 = df = ddf = 0.0;
	} else {
		GMRFLib_2order_approx_core(&f0, &df, &ddf, x0, indx, x_vec, loglFunc, loglFunc_arg, step_len, stencil);
	}

	if (a) {
		*a = d * f0;
	}
	if (b) {
		*b = d * df;
	}
	if (c) {
		*c = d * ddf;
	}

	return GMRFLib_SUCCESS;
}
int GMRFLib_2order_approx(double *a, double *b, double *c, double d, double x0, int indx,
			  double *x_vec, GMRFLib_logl_tp * loglFunc, void *loglFunc_arg, double *step_len, int *stencil)
{
	/*
	 * compute a,b,c in the taylor expansion around x0 of d*loglFunc(x0,...)
	 * 
	 * a + b*x) - 0.5*c*x^2
	 * 
	 */
	double f0, df, ddf;

	if (ISZERO(d)) {
		f0 = df = ddf = 0.0;
	} else {
		GMRFLib_2order_approx_core(&f0, &df, &ddf, x0, indx, x_vec, loglFunc, loglFunc_arg, step_len, stencil);
	}

	if (a) {
		*a = d * (f0 - df * x0 + 0.5 * ddf * SQR(x0));
	}
	if (b) {
		*b = d * (df - x0 * ddf);
	}
	if (c) {
		*c = -d * ddf;
	}

	return GMRFLib_SUCCESS;
}
int GMRFLib_2order_approx_core(double *a, double *b, double *c, double x0, int indx,
			       double *x_vec, GMRFLib_logl_tp * loglFunc, void *loglFunc_arg, double *step_len, int *stencil)
{
	double step, df, ddf, xx[9], f[9], f0;
	int code = loglFunc(f, &x0, 0, indx, x_vec, NULL, loglFunc_arg);

	if (step_len && *step_len < 0.0) {
		/*
		 * for internal use only! 
		 */
		step = -(*step_len);

		xx[0] = x0 - step;
		xx[1] = x0;
		xx[2] = x0 + step;

		loglFunc(&f[0], &xx[0], 1, indx, x_vec, NULL, loglFunc_arg);
		loglFunc(&f[1], &xx[1], 1, indx, x_vec, NULL, loglFunc_arg);
		loglFunc(&f[2], &xx[2], 1, indx, x_vec, NULL, loglFunc_arg);

		f0 = f[1];
		df = 0.5 * (f[2] - f[0]) / step;
		ddf = (f[2] - 2.0 * f[1] + f[0]) / (step * step);
	} else if (code == GMRFLib_LOGL_COMPUTE_DERIVATIES || code == GMRFLib_LOGL_COMPUTE_DERIVATIES_AND_CDF) {
		/*
		 * this tells that exact calculations is carried out in loglFunc 
		 */

		/*
		 * this indicate that exact calculations can and are carried out in loglFunc 
		 */
		xx[0] = xx[1] = xx[2] = x0;
		loglFunc(f, xx, 3, indx, x_vec, NULL, loglFunc_arg);

		f0 = f[0];
		df = f[1];
		ddf = f[2];
	} else {
		int num_points = (stencil ? *stencil : 5);
		step = (step_len && *step_len > 0.0 ? *step_len : GMRFLib_eps(1.0 / 3.5));

		switch (num_points) {
			/*
			 * see https://en.wikipedia.org/wiki/Finite_difference_coefficients
			 */
		case 3:
		{
			xx[0] = x0 - step;
			xx[1] = x0;
			xx[2] = x0 + step;

			loglFunc(f, xx, 3, indx, x_vec, NULL, loglFunc_arg);
			f0 = f[1];
			df = 0.5 * (f[2] - f[0]) / step;
			ddf = (f[2] - 2.0 * f[1] + f[0]) / (step * step);
			break;
		}

		case 5:
		{
			double wf[] = { 1.0 / 12.0, -2.0 / 3.0, 0.0, 2.0 / 3.0, -1.0 / 12.0 };
			double wff[] = { -1.0 / 12.0, 4.0 / 3.0, -5.0 / 2.0, 4.0 / 3.0, -1.0 / 12.0 };

			xx[0] = x0 - 2.0 * step;
			xx[1] = x0 - step;
			xx[2] = x0;
			xx[3] = x0 + step;
			xx[4] = x0 + 2.0 * step;

			loglFunc(f, xx, 5, indx, x_vec, NULL, loglFunc_arg);
			f0 = f[2];
			df = (wf[0] * f[0] + wf[1] * f[1] + wf[2] * f[2] + wf[3] * f[3] + wf[4] * f[4]) / step;
			ddf = (wff[0] * f[0] + wff[1] * f[1] + wff[2] * f[2] + wff[3] * f[3] + wff[4] * f[4]) / step / step;
			break;
		}

		case 7:
		{
			double wf[] = { -1.0 / 60.0, 3.0 / 20.0, -3.0 / 4.0, 0.0, 3.0 / 4.0, -3.0 / 20.0, 1.0 / 60.0 };
			double wff[] = { 1.0 / 90.0, -3.0 / 20.0, 3.0 / 2.0, -49.0 / 18.0, 3.0 / 2.0, -3.0 / 20.0, 1.0 / 90.0 };

			xx[0] = x0 - 3.0 * step;
			xx[1] = x0 - 2.0 * step;
			xx[2] = x0 - step;
			xx[3] = x0;
			xx[4] = x0 + step;
			xx[5] = x0 + 2.0 * step;
			xx[6] = x0 + 3.0 * step;

			loglFunc(f, xx, 7, indx, x_vec, NULL, loglFunc_arg);
			f0 = f[3];
			df = (wf[0] * f[0] + wf[1] * f[1] + wf[2] * f[2] + wf[3] * f[3] + wf[4] * f[4] + wf[5] * f[5] + wf[6] * f[6]) / step;
			ddf =
			    (wff[0] * f[0] + wff[1] * f[1] + wff[2] * f[2] + wff[3] * f[3] + wff[4] * f[4] + wff[5] * f[5] +
			     wff[6] * f[6]) / step / step;
			break;
		}

		case 9:
		{
			double wf[] = { 1.0 / 280.0, -4.0 / 105.0, 1.0 / 5.0, -4.0 / 5.0, 0.0, 4.0 / 5.0, -1.0 / 5.0, 4.0 / 105.0, -1.0 / 280.0 };
			double wff[] =
			    { -1.0 / 560.0, 8.0 / 315.0, -1.0 / 5.0, 8.0 / 5.0, -205.0 / 72.0, 8.0 / 5.0, -1.0 / 5.0, 8.0 / 315.0, -1.0 / 560.0 };

			xx[0] = x0 - 4.0 * step;
			xx[1] = x0 - 3.0 * step;
			xx[2] = x0 - 2.0 * step;
			xx[3] = x0 - step;
			xx[4] = x0;
			xx[5] = x0 + step;
			xx[6] = x0 + 2.0 * step;
			xx[7] = x0 + 3.0 * step;
			xx[8] = x0 + 4.0 * step;

			loglFunc(f, xx, 9, indx, x_vec, NULL, loglFunc_arg);
			f0 = f[4];
			df = (wf[0] * f[0] + wf[1] * f[1] + wf[2] * f[2] + wf[3] * f[3] + wf[4] * f[4] + wf[5] * f[5] + wf[6] * f[6] +
			      wf[7] * f[7] + wf[8] * f[8]) / step;
			ddf =
			    (wff[0] * f[0] + wff[1] * f[1] + wff[2] * f[2] + wff[3] * f[3] + wff[4] * f[4] + wff[5] * f[5] + wff[6] * f[6] +
			     wff[7] * f[7] + wff[8] * f[8]) / step / step;
			break;
		}

		default:
			GMRFLib_ASSERT(num_points == 3 || num_points == 5 || num_points == 7 || num_points == 9, GMRFLib_EINVARG);
			abort();
		}
	}
	*a = f0;
	*b = df;
	*c = ddf;

	return GMRFLib_SUCCESS;
}

/*!
  \brief  Generate a blockproposal for a GMRF conditioned on (possible) non-Gaussian
  observations, using non-Gaussian approximations to the hidden GMRF

  This routine is similar to GMRFLib_blockupdate() except for the argument \c hidden_par, which
  control the approximation to be used, see GMRFLib_init_problem_hidden(). 

  \param[out] laccept See GMRFLib_blockupdate()

  \param[out] x_new See GMRFLib_blockupdate()

  \param[in] x_old See GMRFLib_blockupdate()
  
  \param[in] b_new  See GMRFLib_blockupdate()

  \param[in] b_old   See GMRFLib_blockupdate()

  \param[in] c_new  See GMRFLib_blockupdate()

  \param[in] c_old  See GMRFLib_blockupdate()

  \param[in] mean_new  See GMRFLib_blockupdate()

  \param[in] mean_old  See GMRFLib_blockupdate()

  \param[in] d_new  See GMRFLib_blockupdate()

  \param[in] d_old  See GMRFLib_blockupdate()

  \param[in] loglFunc_new  See GMRFLib_blockupdate()

  \param[in] loglFunc_arg_new  See GMRFLib_blockupdate()

  \param[in] loglFunc_old  See GMRFLib_blockupdate()

  \param[in] loglFunc_arg_old  See GMRFLib_blockupdate()

  \param[in] fixed_value  See GMRFLib_blockupdate()

  \param[in] graph   See GMRFLib_blockupdate()

  \param[in] Qfunc_new  See GMRFLib_blockupdate()

  \param[in] Qfunc_arg_new  See GMRFLib_blockupdate()

  \param[in] Qfunc_old  See GMRFLib_blockupdate()

  \param[in] Qfunc_arg_old See GMRFLib_blockupdate()

  \param[in] Qfunc_old2new See GMRFLib_blockupdate()

  \param[in] Qfunc_arg_old2new See GMRFLib_blockupdate()

  \param[in] Qfunc_new2old See GMRFLib_blockupdate()

  \param[in] Qfunc_arg_new2old See GMRFLib_blockupdate()

  \param[in] optpar See GMRFLib_blockupdate()

  \param[in] hidden_par Parameters which controls the construction of the non-Gaussian
  approximation. If \c NULL, then the default values defined in GMRFLib_default_hidden_par() are
  used.

  \note Constraints are not allowed.
  
  \sa GMRFLib_blockupdate, GMRFLib_init_problem_hidden, GMRFLib_default_hidden_par
*/
int GMRFLib_blockupdate_hidden(double *laccept,
			       double *x_new, double *x_old,
			       double *b_new, double *b_old,
			       double *c_new, double *c_old,
			       double *mean_new, double *mean_old,
			       double *d_new, double *d_old,
			       GMRFLib_logl_tp * loglFunc_new, void *loglFunc_arg_new,
			       GMRFLib_logl_tp * loglFunc_old, void *loglFunc_arg_old,
			       char *fixed_value,
			       GMRFLib_graph_tp * graph,
			       GMRFLib_Qfunc_tp * Qfunc_new, void *Qfunc_arg_new,
			       GMRFLib_Qfunc_tp * Qfunc_old, void *Qfunc_arg_old,
			       GMRFLib_Qfunc_tp * Qfunc_old2new, void *Qfunc_arg_old2new,
			       GMRFLib_Qfunc_tp * Qfunc_new2old, void *Qfunc_arg_new2old, GMRFLib_optimize_param_tp * optpar,
			       GMRFLib_hidden_param_tp * hidden_par)
{
	GMRFLib_ENTER_ROUTINE;
	GMRFLib_EWRAP1(GMRFLib_blockupdate_hidden_store(laccept, x_new, x_old, b_new, b_old, c_new, c_old, mean_new, mean_old,
							d_new, d_old, loglFunc_new, loglFunc_arg_new, loglFunc_old,
							loglFunc_arg_old, fixed_value, graph, Qfunc_new, Qfunc_arg_new,
							Qfunc_old, Qfunc_arg_old, Qfunc_old2new, Qfunc_arg_old2new,
							Qfunc_new2old, Qfunc_arg_new2old, optpar, hidden_par, NULL));
	GMRFLib_LEAVE_ROUTINE;
	return GMRFLib_SUCCESS;
}
int GMRFLib_blockupdate_hidden_store(double *laccept,
				     double *x_new, double *x_old,
				     double *b_new, double *b_old,
				     double *c_new, double *c_old,
				     double *mean_new, double *mean_old,
				     double *d_new, double *d_old,
				     GMRFLib_logl_tp * loglFunc_new, void *loglFunc_arg_new,
				     GMRFLib_logl_tp * loglFunc_old, void *loglFunc_arg_old,
				     char *fixed_value,
				     GMRFLib_graph_tp * graph,
				     GMRFLib_Qfunc_tp * Qfunc_new, void *Qfunc_arg_new,
				     GMRFLib_Qfunc_tp * Qfunc_old, void *Qfunc_arg_old,
				     GMRFLib_Qfunc_tp * Qfunc_old2new, void *Qfunc_arg_old2new,
				     GMRFLib_Qfunc_tp * Qfunc_new2old, void *Qfunc_arg_new2old,
				     GMRFLib_optimize_param_tp * optpar, GMRFLib_hidden_param_tp * hidden_par, GMRFLib_store_tp * store)
{
	/*
	 * do a blockupdate, and return the proposed new state in 'x' and the corresponding log-acceptrate in 'laccept'
	 * 
	 * the density is
	 * 
	 * exp[ -1/2 (x-mean)'(Q+diag(c))(x-mean) + b'x + \sum d_i f(x_i) ]
	 * 
	 * where values are fixed if fixed_value[i] are true, and where a constraint, Ax=b can be spesified in 'constr'
	 * 
	 */

	int n, i;
	double *mode = NULL, old2new, new2old, old, neww, *xx = NULL, *yy = NULL, logll;
	GMRFLib_hidden_problem_tp *hidden_problem = NULL;

	GMRFLib_ASSERT(laccept, GMRFLib_EINVARG);
	GMRFLib_ASSERT(x_new, GMRFLib_EINVARG);
	GMRFLib_ASSERT(graph, GMRFLib_EINVARG);
	GMRFLib_ASSERT(Qfunc_new, GMRFLib_EINVARG);
	GMRFLib_ASSERT(Qfunc_old, GMRFLib_EINVARG);

	GMRFLib_ENTER_ROUTINE;

	if (!Qfunc_old2new) {
		Qfunc_old2new = Qfunc_new;
	}
	if (!Qfunc_arg_old2new) {
		Qfunc_arg_old2new = Qfunc_arg_new;
	}
	if (!Qfunc_new2old) {
		Qfunc_new2old = Qfunc_old;
	}
	if (!Qfunc_arg_new2old) {
		Qfunc_arg_new2old = Qfunc_arg_old;
	}

	n = graph->n;
	mode = Calloc(n, double);
	xx = Calloc(n, double);				       /* two names for the same storage */
	yy = Calloc(n, double);				       /* two names for the same storage */

	GMRFLib_EWRAP1(GMRFLib_init_problem_hidden_store(&hidden_problem,
							 x_old, b_new, c_new, mean_new, graph, Qfunc_old2new, Qfunc_arg_old2new,
							 fixed_value, d_new, loglFunc_new, loglFunc_arg_new, optpar, hidden_par, store));
	GMRFLib_EWRAP1(GMRFLib_sample_hidden(hidden_problem));
	old2new = hidden_problem->sub_logdens;
	memcpy(x_new, hidden_problem->sample, n * sizeof(double));

	GMRFLib_free_hidden(hidden_problem);
	hidden_problem = NULL;

	GMRFLib_EWRAP1(GMRFLib_init_problem_hidden_store(&hidden_problem,
							 x_new, b_old, c_old, mean_old, graph, Qfunc_new2old, Qfunc_arg_new2old,
							 fixed_value, d_old, loglFunc_old, loglFunc_arg_old, optpar, hidden_par, store));
	memcpy(hidden_problem->sample, x_old, n * sizeof(double));
	GMRFLib_EWRAP1(GMRFLib_evaluate_hidden(hidden_problem));
	new2old = hidden_problem->sub_logdens;
	GMRFLib_free_hidden(hidden_problem);
	hidden_problem = NULL;

	/*
	 * compute the density at x and x_old.
	 * 
	 * FIXME: here i do not use subgraph, but that require big tests to see if the results would be the same. is it worth
	 * it really? 
	 */
	neww = 0.0;
	if (mean_new) {
		for (i = 0; i < n; i++) {
			xx[i] = x_new[i] - mean_new[i];
		}
	} else {
		memcpy(xx, x_new, n * sizeof(double));
	}
	GMRFLib_Qx(yy, xx, graph, Qfunc_new, Qfunc_arg_new);
	if (c_new) {
		for (i = 0; i < n; i++) {
			neww += yy[i] * xx[i] + c_new[i] * SQR(xx[i]);
		}
	} else {
		for (i = 0; i < n; i++) {
			neww += yy[i] * xx[i];
		}
	}
	neww *= -0.5;
	if (b_new) {
		for (i = 0; i < n; i++) {
			neww += b_new[i] * x_new[i];
		}
	}
	if (d_new) {
		for (i = 0; i < n; i++) {
			if (d_new[i]) {
				loglFunc_new(&logll, &x_new[i], 1, i, x_new, NULL, loglFunc_arg_new);
				neww += d_new[i] * logll;
			}
		}
	}

	old = 0.0;
	if (mean_old) {
		for (i = 0; i < n; i++) {
			xx[i] = x_old[i] - mean_old[i];
		}
	} else {
		memcpy(xx, x_old, n * sizeof(double));
	}
	GMRFLib_Qx(yy, xx, graph, Qfunc_old, Qfunc_arg_old);
	if (c_old) {
		for (i = 0; i < n; i++) {
			old += yy[i] * xx[i] + c_old[i] * SQR(xx[i]);
		}
	} else {
		for (i = 0; i < n; i++) {
			old += yy[i] * xx[i];
		}
	}
	old *= -0.5;
	if (b_old) {
		for (i = 0; i < n; i++) {
			old += b_old[i] * x_old[i];
		}
	}
	if (d_old) {
		for (i = 0; i < n; i++) {
			if (d_old[i]) {
				loglFunc_old(&logll, &x_old[i], 1, i, x_old, NULL, loglFunc_arg_old);
				old += d_old[i] * logll;
			}
		}
	}

	*laccept = neww + new2old - (old + old2new);

	if (0) {					       /* FIXME */
		fprintf(stdout, "\n%s: laccept %f\n", __GMRFLib_FuncName, *laccept);
		fprintf(stdout, "\tnew_ldens %12.6f\n", neww);
		fprintf(stdout, "\told_ldens %12.6f\n", old);
		fprintf(stdout, "\tnew2old   %12.6f\n", new2old);
		fprintf(stdout, "\told2new   %12.6f\n", old2new);
	}

	Free(xx);
	Free(yy);
	Free(mode);

	GMRFLib_LEAVE_ROUTINE;
	return GMRFLib_SUCCESS;
}

/*
  Example for manual
 */

/*! \page ex_blockupdate A worked out example in spatial disease mapping, using block-updating

The spatial mapping of risk for a particular disease, based on the observed number of incidences or
the mortality in counties or other administrative zones, is of importance for the formulation and
validation of aetiological hypotheses. We will present a basic model used to describe such a
problem, and how this can be implemented in \em GMRFLib.

Suppose that the area of interest is divided into \em n regions, as shown in Figure a.  Let \f$ y_1,
\ldots, y_n \f$ be the number of deaths from the disease of interest in each of the \em n regions
during the study period. A common assumption is that \f$ y_i \f$ is Poisson distributed with mean
\f$ E_ir_i \f$ where \f$ \mbox{\boldmath $E$} = (E_1, \ldots, E_n)^T \f$ are known constants
accounting for the number of inhabitants etc. The relative risks <em>\b r</em> are assumed to be of
the form
\f$ \log r_i = x_i \f$, where <em>\b x</em> is an improper GMRF with density
  \f[
     \pi(x_1,\ldots, x_n\mid \kappa) \; \propto
     \kappa^{(n-1)/2}\exp\left(-\frac{\kappa}{2}\sum_{i\sim j} (x_i-x_j)^2
     \right). \hspace{2cm}(block-1)
  \f]
The parameter \f$ \kappa \f$ is unknown and to be estimated, and is given 
a Gamma(<em>a,b</em>) prior. Hence, the conditional distribution of
\f$ y_i \f$ given the GMRF <em>\b x</em> and the parameter \f$ \kappa \f$ is

   \f[ y_i\mid x_1, \ldots, x_n, \kappa \;\sim\; 
   \mbox{Poisson}(E_i \exp(x_i)).\hspace{2cm}(block-1) \f]
   
\htmlonly
<table>
<tr><td><img src="figs/germany.gif" width="500" height="600"></td></tr> 
<tr><td align="center">(a) </td></tr>
<tr><td><img src="figs/germany-graph.gif" width="500"> </td></tr>
<tr><td align="center">
  <table>
  <tr><td width="250" align="center">(b)</td>
  <td width="250" align="center">(c)</td></tr>
  </table></td></tr>
</table>
\endhtmlonly
Figure: (a) shows the map of Germany with 544 regions, (b) shows the non-zero entries in the
precision matrix <em>\b Q</em> for the GMRF using the numbering of the regions as in the definition
of the map, (c) shows the same precision matrix after a permutation of the nodes to minimize the
bandwidth.

We will now illustrate how the block-update routine in \em GMRFLib, GMRFLib_blockupdate(), can be
used to construct an efficient MCMC algorithm that updates \f$ (\kappa, \mbox{\boldmath $x$}) \f$
jointly.  One joint update of \f$ (\kappa, \mbox{\boldmath $x$}) \f$ is generated by the following
steps.

- First, a new value of \f$ \kappa, \;\kappa', \f$ is proposed by
  \f[ \kappa' = f \kappa \hspace{2cm}(block-3) \f]
  where \em f has density
  \f[ \pi(f) \propto 1+1/f \hspace{2cm}(block-4) \f]
  on the interval <em>[1/F, F]</em>, where <em>F > 1</em>. The role of 
  \em F is as a "step-length" for the proposal for \f$ \kappa \f$. The 
  reason for using <b>(block-4)</b> is that
  \f[ \frac{\pi(\kappa' \mid \kappa)}{\pi(\kappa \mid \kappa')} 
  = 1.\hspace{2cm}(block-5) \f]

- Next, conditionally on \f$ \kappa' \f$, a new value of the spatial
  field <em>\b x</em>, denoted by <em>\b x'</em>, is proposed from a GMRF
  approximation to the conditional posterior distribution of
  <em>\b x</em> given \f$ \kappa \f$, given by
  \f[ \pi(\mbox{\boldmath $x$}'\mid \kappa', 
  \mbox{\boldmath $y$},\mbox{\boldmath $E$}) \propto
  (\kappa')^{(n-1)/2}\exp\left(-\frac{\kappa'}{2}\sum_{i\sim j}
  (x'_i-x'_j)^2 + \sum_i y_ix'_i - \sum_i E_i\exp(x'_i) \right).
  \hspace{2cm}(block-6) \f]
  This distribution is of the form <b>(GMRF-30)</b> in \ref block, with
  \f$ f(x_i;\theta) = \exp(x_i) \f$.  The approximation is given by
  computing a second order approximation to \f$ \exp(x_i') \f$ around a
  point <em>\b x*</em>, which may depend on \f$ \kappa' \f$ and/or the current
  state <em>\b x</em>. The default option is to let 
  \f$ \mbox{\boldmath $x$}^* = \mbox{\boldmath $x$}^*(\kappa') \f$ 
  be the mode of 
  \f$ \pi(\mbox{\boldmath $x$}'\mid \kappa',\mbox{\boldmath $y$},
  \mbox{\boldmath $E$}) \f$.
  Another option is to expand around the current state, such that
  \f$ \mbox{\boldmath $x$}^* = \mbox{\boldmath $x$}^*(\mbox{\boldmath $x$},
  \kappa) \f$.

- Finally, the acceptance rate is computed, and the joint proposal
  accepted or rejected. Let
  \f[ \widetilde{\pi}(\mbox{\boldmath $x$}'\mid \kappa', 
  \mbox{\boldmath $y$},\mbox{\boldmath $E$},\mbox{\boldmath $x$}^*(\kappa', 
  \mbox{\boldmath $x$})) \hspace{2cm}(block-7) \f]
  denote the GMRF approximation.  Then, the acceptance probability
  is min{1,\em R }, where
  \f[ R = \frac{\pi(\mbox{\boldmath $x$}', \kappa'\mid 
  \mbox{\boldmath $y$},\mbox{\boldmath $E$})}{\pi(\mbox{\boldmath $x$},
  \kappa\mid \mbox{\boldmath $y$},\mbox{\boldmath $E$})} \times
  \frac{\widetilde{\pi}(\mbox{\boldmath $x$}\mid \kappa, 
  \mbox{\boldmath $y$},\mbox{\boldmath $E$},\mbox{\boldmath $x$}^*(\kappa', 
  \mbox{\boldmath $x$}'))}{\widetilde{\pi}(\mbox{\boldmath $x$}'\mid \kappa', 
  \mbox{\boldmath $y$},\mbox{\boldmath $E$}, \mbox{\boldmath $x$}^*(\kappa, 
  \mbox{\boldmath $x$}'))}. \hspace{2cm}(block-8) \f]
  The block-update routine returns the log of the contribution to
  the acceptance probability from the GMRF proposal. However, this
  is based on the unnormalized posterior distribution, and the
  contributions from the normalizing constant and from the
  \f$ \kappa \f$-proposal has to be added explicitly. Observe how this is
  done in the example program code below.
  
The efficiency of the sampling algorithm relies on a re-ordering of the graph such that the
bandwidth corresponding precision matrix <em>\b Q</em> is small. In Figure (b) and (c) the effect of
this re-ordering on the precision matrix is illustrated.

One refinement of the procedure described above is to constrain <em>\b x</em> to sum to 0. This
seems reasonable, as the constants <em>\b E</em> usually account for the overall level. The
constraint is easy to incorporate using \em GMRFLib, as illustrated by the example code shown below.

The following program, <tt>example-blockupdate.c</tt>, implements this scheme using the \em GMRFLib
library. Note how the \em void* argument to various functions is used to transfer arguments.

The program runs on a 650MHz-laptop, doing about 11 iterations per second on the graph in Figure
(c), using \f$ \mbox{\boldmath $x$}^*(\kappa) \f$ as the mode, and including the constraint that
<em>\b x</em> should sum to 0.

\par Program code:

\verbinclude example-doxygen-blockupdate.txt

\par Here is yet another example,here using the tools in \file hgmrfm.c together with the blockupdate routine with storage. 

\verbinclude example-doxygen-blockupdate-2.txt


*/
