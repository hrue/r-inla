%%
%% WARNING! DO NOT EDIT!
%% This file is automatically generated from set.default.arguments.R
%%
\name{control.inla}
\alias{control.inla}
\alias{inla.control.inla}
\alias{inla.set.control.inla.default}
\alias{set.control.inla.default}
\alias{control.inla.default}
\title{Control variables in control.inla}
\description{Control variables in \code{control.inla} for use in \code{inla}}
\usage{
inla.set.control.inla.default(...)
control.inla(adapt.hessian.max.trials, adapt.hessian.mode, adapt.hessian.scale, adjust.weights, cmin, correct, correct.factor, correct.strategy, correct.verbose, cpo.diff, cutoff, diagonal, diff.logdens, dz, fast, force.diagonal, global.node.degree, global.node.factor, h, huge, int.strategy, interpolator, lincomb.derived.correlation.matrix, lincomb.derived.only, linear.correction, mode.known, npoints, numint.abserr, numint.maxfeval, numint.relerr, optimiser, print.joint.hyper, reordering, restart, skip.configurations, stencil, step.factor, step.len, strategy, stupid.search, stupid.search.factor, stupid.search.max.iter, tolerance, tolerance.f, tolerance.g, tolerance.x, verbose)
}
\arguments{
\item{...}{Possible arguments}
\item{strategy}{  The strategy to use for the approximations; one of 'gaussian', 'simplified.laplace' (default) or 'laplace'}
\item{int.strategy}{  The integration strategy to use; one of 'ccd' (default), 'grid' or 'eb' (empirical bayes)}
\item{interpolator}{  The interpolator used to compute the marginals for the hyperparameters. One of 'auto', 'nearest', 'quadratic', 'weighted.distance', 'ccd', 'ccdintegrate', 'gridsum', 'gaussian'. Default is 'auto'.}
\item{fast}{  Fast mode? If on, then replace conditional modes in the Laplace approximation with conditional expectation (default TRUE)}
\item{linear.correction}{  Default TRUE for the 'strategy = laplace' option.}
\item{h}{  The step-length for the gradient calculations for the hyperparameters. Default 0.01.}
\item{dz}{  The step-length in the standarised scale for the integration of the hyperparameters. Default 1.0.}
\item{diff.logdens}{  The difference of the log.density for the hyperpameters to stop numerical integration using int.strategy='grid'. Default 2.5.}
\item{print.joint.hyper}{  If TRUE, the store also the joint distribution of the hyperparameters (without any costs). Default TRUE.}
\item{force.diagonal}{  A boolean variable, if TRUE, then force the Hessian to be diagonal. (Default FALSE.)}
\item{skip.configurations}{  A boolean variable; skip configurations if the values at the main axis are to small. (Default TRUE.)}
\item{mode.known}{  A boolean variable: If TRUE then no optimisation is done. (Default FALSE.)}
\item{adjust.weights}{  A boolean variable; If TRUE then just more accurate integration weights. (Default TRUE.)}
\item{tolerance}{  The tolerance for the optimisation of the hyperparameters. If set, this is the default value for for 'tolerance.f^(2/3)', 'tolerance.g' and 'tolerance.x'; see below.}
\item{tolerance.f}{  The tolerance for the absolute change in the log posterior in the optimisation of the hyperparameters.}
\item{tolerance.g}{  The tolerance for the absolute change in the gradient of the log posterior in the optimisation of the hyperparameters.}
\item{tolerance.x}{  The tolerance for the change in the hyperparameters (root-mean-square) in the optimisation of the hyperparameters.}
\item{restart}{  To improve the optimisation, the optimiser is restarted at the found optimum 'restart' number of times.}
\item{optimiser}{  The optimiser to use; one of 'gsl', 'domin' or 'default'.}
\item{verbose}{  A boolean variable; run in verbose mode? (Default FALSE)}
\item{reordering}{  Type of reordering to use. (EXPERT OPTION; one of "AUTO", "DEFAULT", "IDENTITY", "REVERSEIDENTITY", "BAND", "METIS", "GENMMD", "AMD", "MD", "MMD", "AMDBAR", "AMDC", "AMDBARC", or the output from \code{inla.qreordering}.)}
\item{cpo.diff}{  Threshold to define when the cpo-calculations are inaccurate. (EXPERT OPTION.)}
\item{npoints}{  Number of points to use in the 'stratey=laplace' approximation}
\item{cutoff}{  The cutoff used in the 'stratey=laplace' approximation. (Smaller value is more accurate and more slow.)}
\item{adapt.hessian.mode}{  A boolean variable; should optimisation be continued if the Hessian estimate is void? (Default TRUE)}
\item{adapt.hessian.max.trials}{  Number of steps in the adaptive Hessian optimisation}
\item{adapt.hessian.scale}{  The scaling of the 'h' after each trial.}
\item{huge}{  A boolean variable; if TRUE then try to do some of the internal parallisations differently. Hopefully this will be of benefite for 'HUGE' models. (Default FALSE.) [THIS OPTION IS OBSOLETE AND NOT USED!]}
\item{step.len}{  The step-length used to compute numerical derivaties of the log-likelihood}
\item{stencil}{  Number of points in the stencil used to compute the numerical derivaties of the log-likelihood (3, 5 or 7).}
\item{lincomb.derived.only}{  A boolean variable: if TRUE the only compute the marginals for the derived linear combinations and if FALSE, the and also the linear combinations to the graph (Default TRUE)}
\item{lincomb.derived.correlation.matrix}{  A boolean variable: if TRUE compute also the correlations for the derived linear combinations, if FALSE do not (Default FALSE)}
\item{diagonal}{  Expert use only! Add a this value on the diagonal of the joint precision matrix.}
\item{numint.maxfeval}{  Maximum number of function evaluations in the the numerical integration for the hyperparameters. (Default 10000.)}
\item{numint.relerr}{  Relative error requirement in the the numerical integration for the hyperparameters. (Default 1e-5)}
\item{numint.abserr}{  Absolute error requirement in the the numerical integration for the hyperparameters. (Default 1e-6)}
\item{cmin}{  The minimum value for the negative Hessian from the likelihood. Increasing this value will stabalise the optimisation. (Default 0.0)}
\item{step.factor}{  The step factor in the Newton-Raphson algorithm saying how large step to take (Default 1.0)}
\item{global.node.factor}{  The factor which defines the degree required (how many neighbors), as a fraction of n-1, that is required to be classified as a global node and numbered last (whatever the reordering routine says). Here, n, is the size of the graph. (Disabled if larger than 1.)}
\item{global.node.degree}{  The degree required (number of neighbors) to be classified as a global node and numbered last (whatever the reordering routine says).}
\item{stupid.search}{  Enable or disable the stupid-search-algorithm, if the Hessian calculations reveals that the mode is not found. (Default \code{TRUE}.)}
\item{stupid.search.max.iter}{  Maximum number of iterations allowed for the stupid-search-algorithm.}
\item{stupid.search.factor}{  Factor (>=1) to increase the step-length with after each new interation.}
\item{correct}{  Add correction for the Laplace approximation.}
\item{correct.factor}{  Factor used in adjusting the correction factor (default=10) if correct=TRUE}
\item{correct.strategy}{  The strategy used to compute the correction; one of 'simplified.laplace' (default) or 'laplace'}
\item{correct.verbose}{  Be verbose when computing the correction?}
}
\value{
 
The function \code{control.inla} is used to TAB-complete arguments and returns a list of given arguments.
The function \code{inla.set.control.inla.default} returns a list with all the default values of all parameters within this control statement.
}
\seealso{
\code{\link{control.update}}, \code{\link{control.lincomb}}, \code{\link{control.group}}, \code{\link{control.mix}}, \code{\link{control.link}}, \code{\link{control.expert}}, \code{\link{control.compute}}, \code{\link{control.family}}, \code{\link{control.fixed}}, \code{\link{control.inla}}, \code{\link{control.predictor}}, \code{\link{control.results}}, \code{\link{control.mode}}, \code{\link{control.hazard}}, 
\code{\link{inla}}
}
