% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/set.default.arguments.R
\name{control.inla}
\alias{control.inla}
\alias{inla.set.control.inla.default}
\title{control.inla}
\usage{
control.inla(
  strategy = "auto",
  int.strategy = "auto",
  int.design = NULL,
  interpolator = "auto",
  fast = TRUE,
  linear.correction = NULL,
  h = 0.005,
  dz = 0.75,
  diff.logdens = 6,
  print.joint.hyper = TRUE,
  force.diagonal = FALSE,
  skip.configurations = TRUE,
  adjust.weights = TRUE,
  tolerance = 0.005,
  tolerance.f = NULL,
  tolerance.g = NULL,
  tolerance.x = NULL,
  tolerance.step = NULL,
  restart = 0L,
  optimiser = "default",
  verbose = NULL,
  reordering = "auto",
  cpo.diff = NULL,
  npoints = 9,
  cutoff = 1e-04,
  adapt.hessian.mode = NULL,
  adapt.hessian.max.trials = NULL,
  adapt.hessian.scale = NULL,
  adaptive.max = 25L,
  huge = FALSE,
  step.len = 0,
  stencil = 5L,
  lincomb.derived.correlation.matrix = FALSE,
  diagonal = 0,
  numint.maxfeval = 1e+05,
  numint.relerr = 1e-05,
  numint.abserr = 1e-06,
  cmin = -Inf,
  b.strategy = "keep",
  step.factor = -0.1,
  global.node.factor = 2,
  global.node.degree = .Machine$integer.max,
  stupid.search = TRUE,
  stupid.search.max.iter = 1000L,
  stupid.search.factor = 1.05,
  control.vb = INLA::control.vb(),
  num.gradient = "central",
  num.hessian = "central",
  optimise.strategy = "smart",
  use.directions = TRUE,
  constr.marginal.diagonal = sqrt(.Machine$double.eps),
  improved.simplified.laplace = FALSE,
  parallel.linesearch = FALSE,
  compute.initial.values = TRUE,
  hessian.correct.skewness.only = TRUE
)

inla.set.control.inla.default(...)
}
\arguments{
\item{strategy}{Character The strategy to use for the approximations; one
of 'auto' (default), 'gaussian', 'simplified.laplace', 'laplace' or 'adaptive'.}

\item{int.strategy}{Character The integration strategy to use; one of
'auto' (default),  'ccd', 'grid', 'eb' (empirical bayes),  'user' or 'user.std'.
For the experimental mode,  then 'grid' equal 'ccd' for more than two
hyperparameters.}

\item{int.design}{Matrix Matrix of user-defined integration points and
weights. Each row consists theta values and the integration weight.
(EXPERIMENTAL!).}

\item{interpolator}{Character The interpolator used to compute the
marginals for the hyperparameters. One of 'auto', 'nearest', 'quadratic',
'weighted.distance', 'ccd', 'ccdintegrate', 'gridsum', 'gaussian'. Default is
'auto'.}

\item{fast}{Logical If TRUE, then replace conditional modes in the Laplace
approximation with conditional expectation (default TRUE).}

\item{linear.correction}{Logical Default TRUE for the 'strategy = laplace'
option.}

\item{h}{Numerical The step-length for the gradient calculations for the
hyperparameters. Default 0.005.}

\item{dz}{Numerical The step-length in the standarised scale for the
integration of the hyperparameters. Default 0.75.}

\item{diff.logdens}{Numerical The difference of the log.density for the
hyperpameters to stop numerical integration using int.strategy='grid'. Default 6.}

\item{print.joint.hyper}{Logical If TRUE, the store also the joint
distribution of the hyperparameters (without any costs). Default TRUE.}

\item{force.diagonal}{Logical If TRUE, then force the Hessian to be
diagonal. (Default \code{FALSE})}

\item{skip.configurations}{Logical Skip configurations if the values at the
main axis are to small. (Default \code{TRUE})}

\item{adjust.weights}{Logical If TRUE then just more accurate integration
weights. (Default TRUE.)}

\item{tolerance}{Numerical The tolerance for the optimisation of the
hyperparameters. If set, this is the default value for for '2.5\emph{tolerance.f',
'tolerance.g',  '5}tolerance.x' and '1000*tolerance.step'; see below.}

\item{tolerance.f}{Numerical The tolerance for the absolute change in the
log posterior in the optimisation of the hyperparameters.}

\item{tolerance.g}{Numerical The tolerance for the absolute change in the
gradient of the log posterior in the optimisation of the hyperparameters.}

\item{tolerance.x}{Numerical The tolerance for the change in the
hyperparameters (root-mean-square) in the optimisation of the hyperparameters.}

\item{tolerance.step}{Numerical The tolerance for the change in
root-mean_squre in the inner Newton-like optimisation of the latent field.}

\item{restart}{Numerical To improve the optimisation, the optimiser is
restarted at the found optimum 'restart' number of times.}

\item{optimiser}{Character The optimiser to use; one of 'gsl' or 'default'.}

\item{verbose}{Logical Run in verbose mode? (Default FALSE)}

\item{reordering}{Character Type of reordering to use. (EXPERT OPTION; one
of "AUTO", "DEFAULT", "IDENTITY", "REVERSEIDENTITY",  "BAND", "METIS", "GENMMD",
"AMD", "MD", "MMD", "AMDBAR", "AMDC", "AMDBARC",  or the output from
\code{inla.qreordering}. Default is 'auto'.)}

\item{cpo.diff}{Numerical Threshold to define when the cpo-calculations are
inaccurate. (EXPERT OPTION.)}

\item{npoints}{Numerical Number of points to use in the 'stratey=laplace'
approximation (default 9)}

\item{cutoff}{Numerical The cutoff used in the 'stratey=laplace'
approximation. (Smaller value is more accurate and more slow.) (default 1e-4)}

\item{adapt.hessian.mode}{Logical Should optimisation be continued if the
Hessian estimate is void? (Default TRUE)}

\item{adapt.hessian.max.trials}{Numerical Number of steps in the adaptive
Hessian optimisation}

\item{adapt.hessian.scale}{Numerical The scaling of the 'h' after each
trial.}

\item{adaptive.max}{Selecting \code{strategy="adaptive"} will chose the
default strategy for all fixed effects and model components with length less or
equal to \code{adaptive.max}, for others, the gaussian strategy will be applied.}

\item{huge}{Logical If TRUE then try to do some of the internal
parallelisations differently. Hopefully this will be of benefit for 'HUGE' models.
(Default FALSE.) THIS OPTION IS OBSOLETE AND NOT USED!}

\item{step.len}{Numerical The step-length used to compute numerical
derivaties of the log-likelihood (0 means \code{default} which
depends on \code{stencil})}

\item{stencil}{Numerical Number of points in the stencil used to compute the
numerical derivaties of the log-likelihood (5, 7 or 9). (default 5)}

\item{lincomb.derived.correlation.matrix}{Logical If TRUE compute also the
correlations for the derived linear combinations, if FALSE do not (Default FALSE)}

\item{diagonal}{Numerical Expert use only! Add a this value on the diagonal
of the joint precision matrix. (default 0.0)}

\item{numint.maxfeval}{Numerical Maximum number of function evaluations in
the the numerical integration for the hyperparameters. (Default 100000.)}

\item{numint.relerr}{Numerical Relative error requirement in the the
numerical integration for the hyperparameters. (Default 1e-5)}

\item{numint.abserr}{Numerical Absolute error requirement in the the
numerical integration for the hyperparameters. (Default 1e-6)}

\item{cmin}{Numerical The minimum value for the negative Hessian from the
likelihood. Increasing this value will stabalise the optimisation but can
introduce bias.  (Default -Inf)}

\item{b.strategy}{Character If \code{cmin} is used, either keep the linear
term (with \code{b.strategy="keep"}) or skip the contribution by
setting the linear term to zero (\code{b.strategy="skip"}). The
default value is \code{"keep"}}

\item{step.factor}{Numerical The step factor in the Newton-Raphson algorithm
saying how large step to take (Default 1.0) YES! setting this to a
negative values means = 1,  EXCEPT the first time (for each thread)
where |step.factor| is used.}

\item{global.node.factor}{Numerical The factor which defines the degree
required (how many neighbors), as a fraction of \code{n-1},
that is required to be classified as a global node and numbered
last (whatever the reordering routine says). Here, \code{n},
is the size of the graph. (Disabled if larger than 1,  default 2)}

\item{global.node.degree}{Numerical The degree required (number of
neighbors) to be classified as a global node and numbered
last (whatever the reordering routine says).
(default \code{.Machine$integer.max})}

\item{stupid.search}{Logical Enable or disable the stupid-search-algorithm,
if the Hessian calculations reveals that the mode is not found.
(Default \code{TRUE}.)}

\item{stupid.search.max.iter}{Numerical Maximum number of iterations allowed
for the stupid-search-algorithm. (default 1000)}

\item{stupid.search.factor}{Numerical Factor (>=1) to increase the
step-length with after each new iteration. (default 1.05)}

\item{control.vb}{list of arguments for various VB corrections.
See \code{\link[=control.vb]{control.vb()}} for details.}

\item{num.gradient}{Character Set the numerical scheme to compute the
gradient,  one of \code{"forward"} or \code{"central"} (default).}

\item{num.hessian}{Character Set the numerical scheme to compute the
Hessian,  one of \code{"forward"} or \code{"central"} (default).}

\item{optimise.strategy}{Character THIS OPTION IS EXPERIMENTAL. Chose the
optimiser strategy,  one of \code{"plain"} or \code{"smart"} (default)}

\item{use.directions}{THIS OPTION IS EXPERIMENTAL. Unless \code{FALSE} or
\code{NULL},  use directions for computing gradient and Hessian, initialised with
\code{use.directions} if a matrix.}

\item{constr.marginal.diagonal}{Add stability to \verb{AQ^-1A^T} by adding a
small diagonal term. (default \code{epsilon^0.5})}

\item{improved.simplified.laplace}{If \code{TRUE} use an experimental
improved variant, otherwise, use the standard one.}

\item{parallel.linesearch}{Use serial (default) or parallel line-search
(highly experimental for the moment)}

\item{compute.initial.values}{Compute initial values for the latent field or not.
(experimental-mode only)}

\item{hessian.correct.skewness.only}{If TRUE (default) correct only
skewness in the Hessian, for the hyperparameters. If FALSE,
correct also variance. (This option is for experimental-mode only)}

\item{...}{Named arguments passed on to the main function}
}
\description{
Control variables in \verb{control.*} for use with \code{\link[=inla]{inla()}}.
The functions can be used to TAB-complete arguments, and
returns a list of the default control arguments, unless overridden by
specific input arguments.
}
\seealso{
Other control: 
\code{\link{control.bgev}()},
\code{\link{control.compute}()},
\code{\link{control.expert}()},
\code{\link{control.family}()},
\code{\link{control.fixed}()},
\code{\link{control.gcpo}()},
\code{\link{control.group}()},
\code{\link{control.hazard}()},
\code{\link{control.lincomb}()},
\code{\link{control.link}()},
\code{\link{control.lp.scale}()},
\code{\link{control.mix}()},
\code{\link{control.mode}()},
\code{\link{control.pardiso}()},
\code{\link{control.pom}()},
\code{\link{control.predictor}()},
\code{\link{control.scopy}()},
\code{\link{control.sem}()},
\code{\link{control.update}()},
\code{\link{control.vb}()}
}
\concept{control}
