\documentclass[a4paper,11pt]{article} 

\usepackage[margin={2cm,2cm}]{geometry} 
\usepackage{multicol,hyperref}

\title{\vspace{-2cm}
  A short introduction on how to fit a \textbf{SPDE} model 
  with \textbf{\textsf{INLA}}}
\author{Elias T. Krainski and H{\aa}vard Rue} 

%\VignetteEngine{knitr::knitr} 
%\VignetteIndexEntry{SPDEhowto}
\begin{document} 

\maketitle 

\vspace{-1cm}
\begin{center}\begin{minipage}[c]{0.9\textwidth}\centering
This document ilustrates how to do a 
geostatistical fully Bayesian analysis
through the \textbf{S}tochastic \textbf{P}artial 
\textbf{D}iferential \textbf{E}quation 
approach, \cite{lindgrenRL:2011}, 
with \textbf{I}ntegrated \textbf{N}ested 
\textbf{L}aplace \textbf{A}proximation, 
\cite{rueMC:2009}, 
using the \textbf{\textsf{INLA}} package, 
\texttt{http://www.r-inla.org}.
\end{minipage}\end{center}

<<setting,include=FALSE>>= 
set.seed(1) 
require(knitr)
knit_hooks$set(pars = function(before, options, envir) {
    if (before) graphics::par(options$pars)
}) 
library(lattice);   library(gridExtra);  library(INLA);  library(plyr) 
lcall <- inla.getOption('inla.call')
##inla.setOption(inla.call='remote') 
@ 

\begin{multicols}{2} 

\section{Data simulation} 

\textbf{Locations} and the Random 
Field (RF) \textbf{covariance} matrix, 
exponential correlation function 

<<locations,tidy=FALSE>>=
n = 200; coo = matrix(runif(2*n), n) 
k <- 10;   s2s <- 0.7 ## RF params.
R <- s2s*exp(-k*as.matrix(dist(coo))) 
@ 

\textbf{RF} sample, a multivariate Normal realization 
  
<<rmvnorm,tidy=FALSE>>=
s <- drop(rnorm(n)%*%chol(R)) 
@ 

A \textbf{covariate} effect and a noise can be added

<<noise,tidy=FALSE>>=
x <- runif(n);  beta <- 1:2;  s2e <- 0.3
lin.pred <- beta[1] + beta[2]*x + s 
y <- lin.pred + rnorm(n, 0, sqrt(s2e)) 
@ 

\section{Model fitting: steps} 

1. \textbf{Mesh:} 
a triangulation to discretize the 
random field (RF) at $m$ nodes. 

<<fmesh, tidy=FALSE, pars=list(mar=c(0,0,0.7,0)), out.width='0.45\\textwidth', fig.align='center'>>= 
mesh <- inla.mesh.2d(
    coo, ## provide locations or domain
    max.edge=c(0.5/k, 1/k), ## mandatory 
    cutoff=0.1/k) ## good to have >0
plot(mesh, asp=1);  points(coo, col='red')
@ 

A little warning about the mesh. 
The additional triangles outer domain 
is to avoid boundary effects. 
Is good to have aproximately 
isosceles triangles. 
And, to avoid tiny triangles. 
We need to have edges lengths 
of the inner mesh triangles 
less than the range of the process. 
Of course, if it is too small, there 
might not be any spatial effect. 

2. \textbf{Define the $n\times m$ projector matrix} to project 
 the process at the mesh nodes to locations 
<<projector, tidy=FALSE>>=
dim(A <- inla.spde.make.A(
    mesh=mesh, loc=coo)) ## 'n' by 'm'
@ 

3. \textbf{Build the SPDE model} on the mesh.
Exponential correlation function, $\alpha=3/2$ 

<<spde,tidy=FALSE>>=
spde <- inla.spde2.matern(
    mesh=mesh, alpha=1.5) 
@ 

4. \textbf{Create a stack data} for the estimation. 
This is a way to allow models with complex 
linear predictors. In our case, we have a SPDE 
model defined on $m$ nodes. It must be combined 
with the covariate (and the intercept) 
effect at $n$ locations. 
We do it using different projector matrices. 

<<stack-estimation,tidy=FALSE>>=
stk.e <- inla.stack(tag='est', ## tag
    data=list(y=y),  ## response
    A=list(A, 1), ## two projector matrix
    effects=list(## two elements:
        s=1:spde$n.spde, ## RF index
        data.frame(b0=1, x=x)))
@ 

5. \textbf{Fit} the posterior marginal distributions
  for all model parameters 

<<fitting>>= 
formula <- y ~ 0 + b0 + x + ## fixed part
    f(s, model=spde) ## RF term
res <- inla(formula, 
            data=inla.stack.data(stk.e), 
    control.predictor=list(A = 
        inla.stack.A(stk.e)))# projector
@ 

\end{multicols} 

\section{Posterior marginal distributions - PMDs} 

Summary of the regression coefficients PMDs

<<fixed-summary>>=
round(res$summary.fixed, 4) 
@ 

\hrulefill

\begin{multicols}{2} 

\textbf{\textsf{INLA}} works with precisions. 
We have to transform the precision PMD to have 
the variance PMD. It can be done and visialized by

<<fvar, tidy=FALSE, pars=list(mar=c(2.5,2.5,0.1,0.1), mgp=c(1.7,0.5,0)), fig.width=3.5, fig.height=3.5, out.width='0.35\\textwidth', fig.align='center', fig.pos='h'>>=
post.s2e <- 
  inla.tmarginal(# tranformation function
  function(x) 1/x, ## inverse transf. 
  res$marginals.hyperpar$
'Precision for the Gaussian observations')
plot(post.s2e, type='l', ylab='Density', 
     xlab=expression(sigma[e]^2))
abline(v=s2e, col=2) ## add true value
@ 

\end{multicols} 

\hrulefill

\begin{multicols}{2} 

The SPDE approach uses a local variance, $\tau^2$, 
such that $\sigma_{s}^2=1/(2\pi\kappa^2\tau^2)$. 
On \textbf{\textsf{INLA}} we work log($\tau^2$)
and log($\kappa$). So, especially for 
$\sigma_{s}^2$, we have to do 
an additional computation. 
The PMDs for all RF parameters on 
user scale are computed by
<<rf>>=
rf <- inla.spde.result(
    inla=res, ## the inla() output
    name='s', ## name of RF index set
    spde=spde, ## SPDE model object
    do.transf=TRUE) ## to user scale
@ 
\end{multicols} 

These posterior marginals can be visualized by 
<<rfpars, pars=list(mfrow=c(1,3), mar=c(3,3,0.3,0.3), mgp=c(2,0.5,0)), fig.width=7.5, fig.height=2.5, out.width='0.99\\textwidth', out.height='0.33\\textwidth', fig.align='center', fig.pos='h', fig.keep='last'>>=
plot(rf$marginals.var[[1]], type='l', xlab=expression(sigma[s]^2), yla='Density')
abline(v=s2s, col=2) ## add the true value
plot(rf$marginals.kap[[1]], type='l', xlab=expression(kappa), ylab='Density')
abline(v=k, col=2) ## add the true value
plot(rf$marginals.range[[1]], type='l', xlab='range nominal', ylab='Density')
abline(v=sqrt(4)/k, col=2) ## add the 'true' value
@

\section{Projection on a grid}

An interesting result is the map of the RF on a grid. 
The simplest way to have it is by projection. 
We just have to define the projector matrix 
and project, for example, the posterior 
mean and posterior standard deviation on the grid. 

<<project-grid>>=
nxy <- c(300, 300)
gproj <- inla.mesh.projector(mesh,  xlim=0:1, ylim=0:1, dims=nxy)
g.mean <- inla.mesh.project(gproj, res$summary.random$s$mean)
g.sd <- inla.mesh.project(gproj, res$summary.random$s$sd)
@ 

We can visualize it by 

<<fgrid, tidy=FALSE, fig.width=9.7, fig.height=4.5, out.width='0.97\\textwidth', out.height='0.45\\textwidth', fig.pos='h'>>=
library(lattice);     library(gridExtra) 
trellis.par.set(regions=list(col=terrain.colors(16))) 
grid.arrange(levelplot(g.mean, scales=list(draw=F), xlab='', ylab='', main='mean'), 
             levelplot(g.sd, scal=list(draw=F), xla='', yla='', main='sd'), nrow=1)
@ 

\section{Prediction} 

The prediction is usually needed when one wants to know the distribution the 
expected value for the outcome given the data. 
It consider each model component, not only the random field, 
which is only one component in the model, showed in the previous section. 

First, one has to define the scenario for the prediction, 
that is the locationas and value for the covariates. 
We show an example with only three locations, 
predictions over a fine grid can also be considered, 
and covariate values set in its the mean value
<<target-loc>>=
tcoo <- rbind(c(0.3,0.9), c(0.5,0.5), c(0.7,0.3))
dim(Ap <- inla.spde.make.A(mesh=mesh, loc=tcoo)) 
x0 <- c(0.5, 0.5, 0.5)
@ 

There is more than one ways to compute the posterior marginals for 
the linear predictor. 
When predictions over a fine grid is needed, 
it will be preferable a computationally cheaper way.

\subsection{Expensive way: NA's in the response vector}

An usual way is to build a scenario, 
for fixed and random effects, 
and assign NA for the outcome. 
In this case, the linear predictor for 
such missing observations is also 
part of the model graph, \cite{Rueetal:2016},
and is treated in the entire model fitting process. 

Defining a prediction stack, join and use the full stack in \texttt{inla()}
<<prediction-stack>>=
stk.pred <- inla.stack(tag='pred', A=list(Ap, 1), data=list(y=NA), ## response as NA
                       effects=list(s=1:spde$n.spde, data.frame(x=x0, b0=1)))
stk.full <- inla.stack(stk.e, stk.pred) 
p.res <- inla(formula, data=inla.stack.data(stk.full), ## full stack
              control.predictor=list(compute=TRUE, ## compute the predictor
                       A=inla.stack.A(stk.full))) ## using full stack data
@ 

Get the prediction data index and have a look into the summary
<<prdind>>=
pred.ind <- inla.stack.index(stk.full, tag='pred')$data
round(p.res$summary.fitted.val[pred.ind,], 4)
@ 

Collect the linear predictor PMDs to work with, 
and isualize with commands bellow
<<ppred, tidy=FALSE, fig.width=9.9, fig.height=3.5, out.width='0.99\\textwidth', out.height='0.35\\textwidth', fig.pos='h', fig.keep='last'>>=
ypost <- p.res$marginals.fitted.values[pred.ind]
names(ypost) <- paste('y', seq_along(ypost), sep='_');     library(plyr) 
xyplot(y~x | .id, ldply(ypost), panel='llines', xlab='y', ylab='Density')
@ 

\begin{multicols}{2} 
%\addtolength{\linewidth}{2in}
In \textbf{\textsf{INLA}} we have some functions to work 
with marginals distributions 

<<echo=FALSE>>=
options(width=43)
@ 

<<marginals-funcs, comment=NA>>=
apropos('marginal')
@ 

<<marginals-examples>>=
## inla.mmarginal(ypost[[1]]) ## mode
inla.qmarginal(c(0.15, 0.7), 
               ypost[[1]]) ## quantiles
inla.pmarginal(inla.qmarginal(
    0.3, ypost[[1]]), ypost[[1]]) 
@ 
\end{multicols} 

\subsection{Cheaper way: Monte Carlo samples}

The way we show here is cheaper if the number of locations 
to be predicted is not small. 
The idea is to drawn samples from the joint posterior distribution. 
As any functional of interest can be considered, we will consider 
the linear predictor at a set of target locations. 
We start with the three locations previously considered and 
at the end we consider a grid of location. 

Monte Carlo saples from the joint posterior marginal distribution 
can be drawn from the result of from \texttt{inla()} function when 
the precision matrix of the entire latent field, 
\cite{Rueetal:2016}, is stored for each hyperparameter configuration. 
It can be asked setting \texttt{control.compute=list(cofig=TRUE)} 
in the \texttt{inla()} call. 

We can just rerun the model asking for the configurations with
<<configs, warning=FALSE, message=FALSE>>=
res$.args$control.compute$config <- TRUE
res <- inla.rerun(res)
@ 
<<echo=FALSE,results=FALSE>>=
inla.setOption(inla.call=lcall) 
@ 

Monte Carlo samples can be drawn using the 
\texttt{inla.posterior.sample()} function. 
<<samples>>=
samples <- inla.posterior.sample(
    n=1000, result=res, add.names=FALSE)
@ 

We have to find the index set for the elements we need samples, 
the fixed effecs ('b0' and 'x') and the random effect ('s'). 
The names were stored for the first sample as rownames of the latent field
<<xnames>>=
xnames <- rownames(samples[[1]]$latent) ### collect the names
idx <- lapply(c('b0', 'x', 's'), function(nam) ## for each effect
    which(substr(xnames, 1, nchar(nam))==nam)) ## find the index
@ 

These indexes are used to collect the desired part of the latent field 
and organize it into a matrix
<<samplesmat>>=
mat.samples <- sapply(samples, function(spl) 
    c(bo=spl$latent[idx[[1]]], x=spl$latent[idx[[2]]], s=spl$latent[idx[[3]]]))
@ 

The next step is to compute the linear predictor 
for the scenario needed for each sample.  
<<y3sample>>=
lin.pred.3.sample <- as.matrix(cBind(b0=1, x=0.5, s=Ap)%*%mat.samples)
@ 
We can visualize it comparing wit the previous result with
<<comparey3,fig.width=9.9, fig.height=3.5, out.width='0.99\\textwidth', out.height='0.35\\textwidth', fig.pos='h', fig.keep='last'>>=
par(mfrow=c(1,3), mar=c(3,3,1,1), mgp=c(2,1,0))
for (j in 1:3) {
    hist(lin.pred.3.sample[j,], freq=FALSE, xlab=paste0('y',j), main='')
    lines(ypost[[j]], lwd=2)
}
@ 

\subsubsection{Considering a grid}

We can use the projector matrix for the grid used previously with 
<<linpredsample>>=
lin.pred.sample <- as.matrix(cBind(b0=1, x=0.5, s=gproj$proj$A)%*%mat.samples)
@ 

Any summary statistics can be computed. 
As an example, we compute the mean and standard deviation
<<meansdgrid,warning=FALSE,message=FALSE>>=
eta.mean <- rowMeans(lin.pred.sample)
require(matrixStats)
eta.sd <- rowSds(lin.pred.sample)
@ 

It can be visualized with the commands bellow. 
The sampled locations is added on top of the standard deviation map. 
<<responsemaps, fig.width=10, fig.height=4, out.width='0.99\\textwidth', fig.pos='h', fig.align='center'>>=
require(fields)
par(mfrow=c(1,2), mar=c(2,2,1,5), mgp=c(1,0.5,0))
image.plot(list(x=gproj$x, y=gproj$y, z=matrix(eta.mean, nxy[1])), legend.mar=3)
image.plot(list(x=gproj$x, y=gproj$y, z=matrix(eta.sd, nxy[2])), legend.mar=3)
points(coo, pch=19, cex=1)
@ 

\bibliographystyle{apalike}
\bibliography{spde-tutorial}

\end{document} 
